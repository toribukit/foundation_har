{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import copy\n",
    "from scipy.interpolate import CubicSpline\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy.stats import mode\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import datetime\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 32  # Set your batch size\n",
    "learning_rate_client = 0.001\n",
    "local_epochs = 1\n",
    "subject_dir = 'FL_Data/windowed_data_refused_5aug/subject_'  # Set your directory to the subject data\n",
    "numclients = 54\n",
    "num_classes = 9\n",
    "\n",
    "#current timestamp\n",
    "current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "torch.manual_seed(420)\n",
    "np.random.seed(420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_client(id, batch_size=batch_size, type='labelled_train'):\n",
    "    # Load the data\n",
    "    data = np.load(subject_dir + str(id) + '/windowed_' + type + '_x.npy')\n",
    "    labels = np.load(subject_dir + str(id) + '/windowed_' + type + '_y.npy')\n",
    "\n",
    "    # print shape of data\n",
    "    # print(data.shape)\n",
    "    # print(labels.shape)\n",
    "\n",
    "    # Convert to torch tensor\n",
    "    data = torch.from_numpy(data).float()\n",
    "    labels = torch.from_numpy(labels).long()\n",
    "\n",
    "    # Create a dataset\n",
    "    dataset = torch.utils.data.TensorDataset(data, labels)\n",
    "\n",
    "    # Create a dataloader\n",
    "    if type == 'labelled_train' or type == 'unlabelled_train':\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    else:\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(54):\n",
    "#     data_label_train = load_data_client(i, batch_size, 'labelled_train')\n",
    "#     data_unlabel_train = load_data_client(i, batch_size, 'unlabelled_train')\n",
    "#     data_test = load_data_client(i, batch_size, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256 * 12, 128)  # Adjust the input features according to your final conv layer output\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_autoencoder(model, train_loader, device, learning_rate=0.01, epochs=5):\n",
    "#     model.to(device)\n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for epoch in range(epochs):\n",
    "#         for data, target in train_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             # print(data.shape)\n",
    "#             data = data.permute(0, 2, 1)\n",
    "#             optimizer.zero_grad()\n",
    "#             output = model(data)\n",
    "#             # print(output.shape)\n",
    "#             loss = criterion(output, data)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()\n",
    "        \n",
    "#         epoch_loss = total_loss / len(train_loader)\n",
    "#         # print(f'Epoch {epoch+1}, Loss: {epoch_loss}')\n",
    "#         total_loss = 0  # Reset total loss for the next epoch\n",
    "\n",
    "#     results = {\n",
    "#         'train_loss': epoch_loss\n",
    "#     }\n",
    "    \n",
    "#     return results  # Returns the average loss of the last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_autoencoder(model, test_loader, device):\n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "    \n",
    "#     criterion = nn.MSELoss()\n",
    "#     total_loss = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for data, target in test_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             data = data.permute(0, 2, 1)\n",
    "#             output = model(data)\n",
    "#             loss = criterion(output, data)\n",
    "#             total_loss += loss.item()\n",
    "    \n",
    "#     avg_loss = total_loss / len(test_loader)\n",
    "#     # print(f'Test Loss: {avg_loss}')\n",
    "    \n",
    "#     return avg_loss  # Returns the average loss for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train_model(model, train_loader, device, learning_rate=0.001, epochs=1):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.permute(0, 2, 1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = total_loss / len(train_loader)\n",
    "        total_loss = 0  # Reset total loss for the next epoch\n",
    "\n",
    "    results = {\n",
    "        'train_loss': epoch_loss\n",
    "    }\n",
    "    \n",
    "    return results  # Returns the average loss of the last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test the model\n",
    "# method to test the model and get the accuracy and f1 score\n",
    "def test_model(model, test_loader):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.permute(0, 2, 1)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    # print(f'Accuracy: {accuracy}, F1 Score: {f1}')\n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client():\n",
    "  def __init__(self, client_config:dict):\n",
    "    # client config as dict to make configuration dynamic\n",
    "    self.id = client_config[\"id\"]\n",
    "    self.config = client_config\n",
    "    self.__model = None\n",
    "\n",
    "    self.labelled_loader = self.config[\"labelled\"]\n",
    "    self.unlabelled_loader = self.config[\"unlabelled\"]\n",
    "    self.test_loader = self.config[\"test\"]\n",
    "\n",
    "  @property\n",
    "  def model(self):\n",
    "    return self.__model\n",
    "\n",
    "  @model.setter\n",
    "  def model(self, model):\n",
    "    self.__model = model\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"Return a total size of the client's local data.\"\"\"\n",
    "    return len(self.unlabelled_loader.sampler)\n",
    "\n",
    "  def train_ssl(self):\n",
    "    results = train_model(model = self.model,\n",
    "                    train_loader = self.unlabelled_loader,\n",
    "                    device=device,\n",
    "                    learning_rate=learning_rate_client,\n",
    "                    epochs=local_epochs)\n",
    "    print(f\"Train result client {self.id}: {results}\")\n",
    "\n",
    "  def test_ssl(self):\n",
    "    loss = test_model(model = self.model,\n",
    "                    test_loader = self.unlabelled_loader)\n",
    "    print(f\"Test result client {self.id}: {loss}\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvg():\n",
    "  def __init__(self):\n",
    "    self.globalmodel = CNNFeatureExtractor(num_classes=5) # number for augmentations\n",
    "    self.rounds = 0\n",
    "    self.params = {}\n",
    "\n",
    "  def aggregate(self, round):\n",
    "    #v1:update the aggregate to save the model with round and date indicator\n",
    "    modelparams = []\n",
    "    for i in self.params.keys():\n",
    "      modelparams.append(self.params[i])\n",
    "\n",
    "    avg_weights = {}\n",
    "    for name in modelparams[0].keys():\n",
    "      avg_weights[name] = torch.mean(torch.stack([w[name] for w in modelparams]), dim = 0)\n",
    "\n",
    "    self.globalmodel.load_state_dict(avg_weights)\n",
    "\n",
    "    #save the model\n",
    "    # name_path = f'Refused_FL/Model_Global/{current_time}' #v1: only 4 augmentation\n",
    "    name_path = f'Refused_FL/Model_Global_5Aug/{current_time}'\n",
    "    if not os.path.exists(name_path):\n",
    "      os.makedirs(name_path)\n",
    "\n",
    "    torch.save(self.globalmodel.state_dict(), f\"{name_path}/global_model_round_{round}.pth\")\n",
    "    \n",
    "    # filename = f\"{path_glob_m}/global_model_round_{round}_{current_time}.pth\"\n",
    "    # torch.save(self.globalmodel.state_dict(), filename)\n",
    "\n",
    "  def clientstrain(self, clientconfig):\n",
    "    clients = clientconfig\n",
    "    for i in clients.keys():\n",
    "      test_client = Client(clients[i])\n",
    "      test_client.model = copy.deepcopy(self.globalmodel)\n",
    "      test_client.train_ssl()\n",
    "      test_client.test_ssl()\n",
    "      self.params[i] = test_client.model.state_dict()\n",
    "\n",
    "  def initiate_FL(self, clientconfig, serverdata):\n",
    "    clients = clientconfig\n",
    "    print(\"Round: {}\".format(self.rounds))\n",
    "\n",
    "    print(\"Obtaining Weights!!\")\n",
    "    self.clientstrain(clients)\n",
    "\n",
    "    #### Aggregate model\n",
    "    print(\"Aggregating Model!!\")\n",
    "    self.aggregate(self.rounds)\n",
    "\n",
    "    #### Replace parameters with global model parameters\n",
    "    for i in self.params.keys():\n",
    "        self.params[i] = self.globalmodel.state_dict()\n",
    "\n",
    "\n",
    "    servertest = serverdata\n",
    "    result = test_model(model = self.globalmodel,\n",
    "                    test_loader = servertest)\n",
    "    print(\"Round {} metrics:\".format(self.rounds))\n",
    "    print(\"Server Result = {}\".format(result))\n",
    "    print(\"Round {} finished!\".format(self.rounds))\n",
    "    self.rounds += 1\n",
    "    return clients, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client: 0\n",
      "labelled: 12\n",
      "unlabelled: 45\n",
      "test: 14\n",
      "client: 1\n",
      "labelled: 11\n",
      "unlabelled: 43\n",
      "test: 14\n",
      "client: 2\n",
      "labelled: 12\n",
      "unlabelled: 45\n",
      "test: 15\n",
      "client: 3\n",
      "labelled: 10\n",
      "unlabelled: 41\n",
      "test: 13\n",
      "client: 4\n",
      "labelled: 13\n",
      "unlabelled: 51\n",
      "test: 16\n",
      "client: 5\n",
      "labelled: 12\n",
      "unlabelled: 49\n",
      "test: 16\n",
      "client: 6\n",
      "labelled: 3\n",
      "unlabelled: 12\n",
      "test: 4\n",
      "client: 7\n",
      "labelled: 4\n",
      "unlabelled: 13\n",
      "test: 4\n",
      "client: 8\n",
      "labelled: 2\n",
      "unlabelled: 8\n",
      "test: 3\n",
      "client: 9\n",
      "labelled: 11\n",
      "unlabelled: 43\n",
      "test: 14\n",
      "client: 10\n",
      "labelled: 9\n",
      "unlabelled: 34\n",
      "test: 11\n",
      "client: 11\n",
      "labelled: 12\n",
      "unlabelled: 46\n",
      "test: 15\n",
      "client: 12\n",
      "labelled: 11\n",
      "unlabelled: 42\n",
      "test: 13\n",
      "client: 13\n",
      "labelled: 13\n",
      "unlabelled: 50\n",
      "test: 16\n",
      "client: 14\n",
      "labelled: 11\n",
      "unlabelled: 44\n",
      "test: 14\n",
      "client: 15\n",
      "labelled: 10\n",
      "unlabelled: 38\n",
      "test: 12\n",
      "client: 16\n",
      "labelled: 13\n",
      "unlabelled: 49\n",
      "test: 16\n",
      "client: 17\n",
      "labelled: 12\n",
      "unlabelled: 45\n",
      "test: 14\n",
      "client: 18\n",
      "labelled: 11\n",
      "unlabelled: 43\n",
      "test: 14\n",
      "client: 19\n",
      "labelled: 11\n",
      "unlabelled: 45\n",
      "test: 14\n",
      "client: 20\n",
      "labelled: 11\n",
      "unlabelled: 43\n",
      "test: 14\n",
      "client: 21\n",
      "labelled: 11\n",
      "unlabelled: 44\n",
      "test: 14\n",
      "client: 22\n",
      "labelled: 9\n",
      "unlabelled: 36\n",
      "test: 12\n",
      "client: 23\n",
      "labelled: 12\n",
      "unlabelled: 45\n",
      "test: 14\n",
      "client: 24\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 25\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 26\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 27\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 28\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 29\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 30\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 31\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 32\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 33\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 34\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 35\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 36\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 37\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 38\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 39\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 40\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 41\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 42\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 43\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 44\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 45\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 46\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 47\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 48\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 49\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 50\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 51\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 52\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 53\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "combined test: 341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined unlabelled: 1092\n"
     ]
    }
   ],
   "source": [
    "clients = {}\n",
    "\n",
    "for i in range(numclients):\n",
    "    clients[i] = {\"id\": i, \"batch_size\": batch_size, \"local_epoch\": 1}\n",
    "    clients[i]['labelled'] = load_data_client(i, batch_size, 'labelled_train')\n",
    "    clients[i]['unlabelled'] = load_data_client(i, batch_size, 'unlabelled_train')\n",
    "    clients[i]['test'] = load_data_client(i, batch_size, 'test')\n",
    "\n",
    "    print(f\"client: {i}\")\n",
    "    print(f\"labelled: {len(clients[i]['labelled'])}\")\n",
    "    print(f\"unlabelled: {len(clients[i]['unlabelled'])}\")\n",
    "    print(f\"test: {len(clients[i]['test'])}\")\n",
    "\n",
    "# combine all client test data into one\n",
    "combined_test_data = []\n",
    "combined_test_labels = []\n",
    "for i in range(numclients):\n",
    "    for data, labels in clients[i]['test']:\n",
    "        combined_test_data.append(data)\n",
    "        combined_test_labels.append(labels)\n",
    "combined_test_data = torch.cat(combined_test_data, dim=0)\n",
    "combined_test_labels = torch.cat(combined_test_labels, dim=0)\n",
    "# create dataset and dataloader\n",
    "combined_test_dataset = torch.utils.data.TensorDataset(combined_test_data, combined_test_labels)\n",
    "combined_test_dataloader = torch.utils.data.DataLoader(combined_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"combined test: {len(combined_test_dataloader)}\")\n",
    "\n",
    "# combine all client unlabelled data into one\n",
    "combined_unlabelled_data = []\n",
    "combined_unlabelled_labels = []\n",
    "for i in range(numclients):\n",
    "    for data, labels in clients[i]['unlabelled']:\n",
    "        combined_unlabelled_data.append(data)\n",
    "        combined_unlabelled_labels.append(labels)\n",
    "combined_unlabelled_data = torch.cat(combined_unlabelled_data, dim=0)\n",
    "combined_unlabelled_labels = torch.cat(combined_unlabelled_labels, dim=0)\n",
    "# create dataset and dataloader\n",
    "combined_unlabelled_dataset = torch.utils.data.TensorDataset(combined_unlabelled_data, combined_unlabelled_labels)\n",
    "combined_unlabelled_dataloader = torch.utils.data.DataLoader(combined_unlabelled_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"combined unlabelled: {len(combined_unlabelled_dataloader)}\")\n",
    "\n",
    "# # server test_data\n",
    "# server_test_data = combined_unlabelled_dataloader\n",
    "\n",
    "# server = FedAvg()\n",
    "\n",
    "# loss_rounds = []\n",
    "# for i in range(num_epochs):\n",
    "#     clients, loss = server.initiate_FL(clientconfig=clients, serverdata=server_test_data)\n",
    "#     loss_rounds.append(loss)\n",
    "\n",
    "# print(\"\\n\")\n",
    "# print(\"-\" * 50)\n",
    "# print(\"Loss values all rounds: \", loss_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuned Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256 * 12, 128)  # Adjust the input features according to your final conv layer output\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fine-Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined labelled: 273\n"
     ]
    }
   ],
   "source": [
    "# combine all client labelled data into one\n",
    "combined_labelled_data = []\n",
    "combined_labelled_labels = []\n",
    "for i in range(numclients):\n",
    "    for data, labels in clients[i]['labelled']:\n",
    "        combined_labelled_data.append(data)\n",
    "        combined_labelled_labels.append(labels)\n",
    "combined_labelled_data = torch.cat(combined_labelled_data, dim=0)\n",
    "combined_labelled_labels = torch.cat(combined_labelled_labels, dim=0)\n",
    "# create dataset and dataloader\n",
    "combined_labelled_dataset = torch.utils.data.TensorDataset(combined_labelled_data, combined_labelled_labels)\n",
    "combined_labelled_dataloader = torch.utils.data.DataLoader(combined_labelled_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"combined labelled: {len(combined_labelled_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each class\n",
    "class_counts = torch.zeros(num_classes)  # num_classes should be defined based on your dataset\n",
    "for _, target in combined_labelled_dataloader:\n",
    "    class_counts += torch.bincount(target, minlength=num_classes)\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts += 1  # Add 1 to each class count to avoid division by zero\n",
    "c_weight = 1. / class_counts\n",
    "c_weight = c_weight / c_weight.sum() * num_classes\n",
    "c_weight = c_weight.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0120e+03, 1.2410e+03, 1.3840e+03, 1.5050e+03, 8.8300e+02, 3.7800e+02,\n",
       "        1.0000e+00, 9.6700e+02, 1.3440e+03])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.8163e-03, 7.1894e-03, 6.4466e-03, 5.9283e-03, 1.0104e-02, 2.3603e-02,\n",
       "        8.9220e+00, 9.2265e-03, 6.6384e-03], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNFeatureExtractor(\n",
       "  (conv1): Conv1d(3, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=3072, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_path = 'Refused_FL/Model_Global/2024-02-11_22-01-36/global_model_round_199.pth' # model with 200 epochs, 1 local epoch\n",
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# # Freezing layers up to conv3\n",
    "# for name, param in model.named_parameters():\n",
    "#     if 'conv3' in name:\n",
    "#         break\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Unfreeze layers from conv3 onwards\n",
    "# unfreeze = False\n",
    "# for name, param in model.named_parameters():\n",
    "#     if 'conv3' in name:\n",
    "#         unfreeze = True\n",
    "#     if unfreeze:\n",
    "#         param.requires_grad = True\n",
    "\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CNNFeatureExtractor(num_classes=num_classes)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to test the model and get the accuracy and f1 score\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.permute(0, 2, 1)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f'Accuracy: {accuracy}, F1 Score: {f1}')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(model, train_loader, test_loader, num_epochs=200):\n",
    "    # Assuming class weights are calculated and provided as `class_weights`\n",
    "    class_weights = torch.tensor(c_weight).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # optimizer = torch.optim.Adam(model.fc2.parameters(), lr=0.001)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.permute(0, 2, 1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        acc, f1 = test_model(model, test_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, Accuracy: {acc}, F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IME-LAB\\AppData\\Local\\Temp\\ipykernel_4124\\3333203605.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  class_weights = torch.tensor(c_weight).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36311874368628894, F1 Score: 0.29767210780061143\n",
      "Epoch 1/100, Loss: 1.7901926040649414, Accuracy: 0.36311874368628894, F1 Score: 0.29767210780061143\n",
      "Accuracy: 0.35604738727155844, F1 Score: 0.3275876791609527\n",
      "Epoch 2/100, Loss: 1.73380446434021, Accuracy: 0.35604738727155844, F1 Score: 0.3275876791609527\n",
      "Accuracy: 0.4026999724492607, F1 Score: 0.3826029707574641\n",
      "Epoch 3/100, Loss: 0.48517096042633057, Accuracy: 0.4026999724492607, F1 Score: 0.3826029707574641\n",
      "Accuracy: 0.3923225273211498, F1 Score: 0.3521286690119721\n",
      "Epoch 4/100, Loss: 1.517432689666748, Accuracy: 0.3923225273211498, F1 Score: 0.3521286690119721\n",
      "Accuracy: 0.3926898705115254, F1 Score: 0.3674115808226789\n",
      "Epoch 5/100, Loss: 1.3255494832992554, Accuracy: 0.3926898705115254, F1 Score: 0.3674115808226789\n",
      "Accuracy: 0.3944347506658095, F1 Score: 0.3644853870661453\n",
      "Epoch 6/100, Loss: 1.067397952079773, Accuracy: 0.3944347506658095, F1 Score: 0.3644853870661453\n",
      "Accuracy: 0.3726696666360547, F1 Score: 0.3493268705154914\n",
      "Epoch 7/100, Loss: 0.36474084854125977, Accuracy: 0.3726696666360547, F1 Score: 0.3493268705154914\n",
      "Accuracy: 0.36091468454403525, F1 Score: 0.3616179922357928\n",
      "Epoch 8/100, Loss: 1.312806487083435, Accuracy: 0.36091468454403525, F1 Score: 0.3616179922357928\n",
      "Accuracy: 0.3668840113876389, F1 Score: 0.359535645943592\n",
      "Epoch 9/100, Loss: 0.2860260605812073, Accuracy: 0.3668840113876389, F1 Score: 0.359535645943592\n",
      "Accuracy: 0.36174120672238036, F1 Score: 0.3526828481001199\n",
      "Epoch 10/100, Loss: 0.0015008794143795967, Accuracy: 0.36174120672238036, F1 Score: 0.3526828481001199\n",
      "Accuracy: 0.3531086417485536, F1 Score: 0.3478721845135434\n",
      "Epoch 11/100, Loss: 0.5370393991470337, Accuracy: 0.3531086417485536, F1 Score: 0.3478721845135434\n",
      "Accuracy: 0.3616493709247865, F1 Score: 0.3606224918863604\n",
      "Epoch 12/100, Loss: 0.424580842256546, Accuracy: 0.3616493709247865, F1 Score: 0.3606224918863604\n",
      "Accuracy: 0.34741482229773163, F1 Score: 0.34890426482014125\n",
      "Epoch 13/100, Loss: 0.00301823066547513, Accuracy: 0.34741482229773163, F1 Score: 0.34890426482014125\n",
      "Accuracy: 0.35632289466434014, F1 Score: 0.3548773348123433\n",
      "Epoch 14/100, Loss: 0.0028938218019902706, Accuracy: 0.35632289466434014, F1 Score: 0.3548773348123433\n",
      "Accuracy: 0.33960877950225, F1 Score: 0.33665732781078805\n",
      "Epoch 15/100, Loss: 0.11177084594964981, Accuracy: 0.33960877950225, F1 Score: 0.33665732781078805\n",
      "Accuracy: 0.35081274680870606, F1 Score: 0.34806344950268897\n",
      "Epoch 16/100, Loss: 0.014774228446185589, Accuracy: 0.35081274680870606, F1 Score: 0.34806344950268897\n",
      "Accuracy: 0.349894388832767, F1 Score: 0.33978674417824056\n",
      "Epoch 17/100, Loss: 0.05089329183101654, Accuracy: 0.349894388832767, F1 Score: 0.33978674417824056\n",
      "Accuracy: 0.341445495454128, F1 Score: 0.33986302632534016\n",
      "Epoch 18/100, Loss: 0.019276708364486694, Accuracy: 0.341445495454128, F1 Score: 0.33986302632534016\n",
      "Accuracy: 0.3484250160712646, F1 Score: 0.3486173411311063\n",
      "Epoch 19/100, Loss: 0.24215982854366302, Accuracy: 0.3484250160712646, F1 Score: 0.3486173411311063\n",
      "Accuracy: 0.3479658370832951, F1 Score: 0.34987716062167323\n",
      "Epoch 20/100, Loss: 0.007457629311829805, Accuracy: 0.3479658370832951, F1 Score: 0.34987716062167323\n",
      "Accuracy: 0.3562310588667463, F1 Score: 0.35435866158529405\n",
      "Epoch 21/100, Loss: 0.0007305797189474106, Accuracy: 0.3562310588667463, F1 Score: 0.35435866158529405\n",
      "Accuracy: 0.3450270915602902, F1 Score: 0.33696251478478445\n",
      "Epoch 22/100, Loss: 8.344646289515367e-07, Accuracy: 0.3450270915602902, F1 Score: 0.33696251478478445\n",
      "Accuracy: 0.3428230324180366, F1 Score: 0.34003801069123635\n",
      "Epoch 23/100, Loss: 0.0065045407973229885, Accuracy: 0.3428230324180366, F1 Score: 0.34003801069123635\n",
      "Accuracy: 0.3393332721094683, F1 Score: 0.33247670703090565\n",
      "Epoch 24/100, Loss: 0.0, Accuracy: 0.3393332721094683, F1 Score: 0.33247670703090565\n",
      "Accuracy: 0.33758839195518414, F1 Score: 0.33919971928764936\n",
      "Epoch 25/100, Loss: 0.003209230024367571, Accuracy: 0.33758839195518414, F1 Score: 0.33919971928764936\n",
      "Accuracy: 0.35154743318945725, F1 Score: 0.3437693852323887\n",
      "Epoch 26/100, Loss: 0.0003391896025277674, Accuracy: 0.35154743318945725, F1 Score: 0.3437693852323887\n",
      "Accuracy: 0.33731288456240244, F1 Score: 0.3296606525330895\n",
      "Epoch 27/100, Loss: 6.7352812038734555e-06, Accuracy: 0.33731288456240244, F1 Score: 0.3296606525330895\n",
      "Accuracy: 0.348976030856828, F1 Score: 0.3447317609739894\n",
      "Epoch 28/100, Loss: 6.901741289766505e-05, Accuracy: 0.348976030856828, F1 Score: 0.3447317609739894\n",
      "Accuracy: 0.3406189732757829, F1 Score: 0.33818213524091806\n",
      "Epoch 29/100, Loss: 0.012939910404384136, Accuracy: 0.3406189732757829, F1 Score: 0.33818213524091806\n",
      "Accuracy: 0.3359353475984939, F1 Score: 0.33645796136037354\n",
      "Epoch 30/100, Loss: 0.002255890052765608, Accuracy: 0.3359353475984939, F1 Score: 0.33645796136037354\n",
      "Accuracy: 0.3500780604279548, F1 Score: 0.34505237723185894\n",
      "Epoch 31/100, Loss: 0.00814518891274929, Accuracy: 0.3500780604279548, F1 Score: 0.34505237723185894\n",
      "Accuracy: 0.3531086417485536, F1 Score: 0.34582667572214526\n",
      "Epoch 32/100, Loss: 5.6621207477292046e-05, Accuracy: 0.3531086417485536, F1 Score: 0.34582667572214526\n",
      "Accuracy: 0.3525576269629902, F1 Score: 0.3503007106541579\n",
      "Epoch 33/100, Loss: 0.005694974213838577, Accuracy: 0.3525576269629902, F1 Score: 0.3503007106541579\n",
      "Accuracy: 0.3438332261915695, F1 Score: 0.3401280777924341\n",
      "Epoch 34/100, Loss: 0.0046600596979260445, Accuracy: 0.3438332261915695, F1 Score: 0.3401280777924341\n",
      "Accuracy: 0.33299660207548903, F1 Score: 0.3304652209498995\n",
      "Epoch 35/100, Loss: 2.169561957998667e-05, Accuracy: 0.33299660207548903, F1 Score: 0.3304652209498995\n",
      "Accuracy: 0.33970061529984386, F1 Score: 0.3373969974797588\n",
      "Epoch 36/100, Loss: 0.0013267712201923132, Accuracy: 0.33970061529984386, F1 Score: 0.3373969974797588\n",
      "Accuracy: 0.33795573514555977, F1 Score: 0.3339911252112696\n",
      "Epoch 37/100, Loss: 9.333216439699754e-05, Accuracy: 0.33795573514555977, F1 Score: 0.3339911252112696\n",
      "Accuracy: 0.3404353016805951, F1 Score: 0.3319659435747757\n",
      "Epoch 38/100, Loss: 1.7064658403396606, Accuracy: 0.3404353016805951, F1 Score: 0.3319659435747757\n",
      "Accuracy: 0.34566994214344754, F1 Score: 0.34630326915797216\n",
      "Epoch 39/100, Loss: 0.057148344814777374, Accuracy: 0.34566994214344754, F1 Score: 0.34630326915797216\n",
      "Accuracy: 0.3433740472036, F1 Score: 0.34551775579814825\n",
      "Epoch 40/100, Loss: 0.00024443850270472467, Accuracy: 0.3433740472036, F1 Score: 0.34551775579814825\n",
      "Accuracy: 0.3524657911653963, F1 Score: 0.34504373692838436\n",
      "Epoch 41/100, Loss: 0.08259444683790207, Accuracy: 0.3524657911653963, F1 Score: 0.34504373692838436\n",
      "Accuracy: 0.34612912113141703, F1 Score: 0.33786397973549476\n",
      "Epoch 42/100, Loss: 2.0861582470388385e-06, Accuracy: 0.34612912113141703, F1 Score: 0.33786397973549476\n",
      "Accuracy: 0.3525576269629902, F1 Score: 0.34735308100275436\n",
      "Epoch 43/100, Loss: 0.0, Accuracy: 0.3525576269629902, F1 Score: 0.34735308100275436\n",
      "Accuracy: 0.33924143631187437, F1 Score: 0.336995339703008\n",
      "Epoch 44/100, Loss: 0.00011556004756130278, Accuracy: 0.33924143631187437, F1 Score: 0.336995339703008\n",
      "Accuracy: 0.3304251997428598, F1 Score: 0.3311098771020217\n",
      "Epoch 45/100, Loss: 0.12061025202274323, Accuracy: 0.3304251997428598, F1 Score: 0.3311098771020217\n",
      "Accuracy: 0.34374139039397555, F1 Score: 0.3352919400735561\n",
      "Epoch 46/100, Loss: 1.7881390590446244e-07, Accuracy: 0.34374139039397555, F1 Score: 0.3352919400735561\n",
      "Accuracy: 0.35604738727155844, F1 Score: 0.34677751220404945\n",
      "Epoch 47/100, Loss: 1.9788350982707925e-05, Accuracy: 0.35604738727155844, F1 Score: 0.34677751220404945\n",
      "Accuracy: 0.35127192579667554, F1 Score: 0.3459828266178238\n",
      "Epoch 48/100, Loss: 0.006755759473890066, Accuracy: 0.35127192579667554, F1 Score: 0.3459828266178238\n",
      "Accuracy: 0.3411699880613463, F1 Score: 0.3364125103342841\n",
      "Epoch 49/100, Loss: 5.9604641222676946e-08, Accuracy: 0.3411699880613463, F1 Score: 0.3364125103342841\n",
      "Accuracy: 0.3398842868950317, F1 Score: 0.3401411157577278\n",
      "Epoch 50/100, Loss: 5.9601094108074903e-05, Accuracy: 0.3398842868950317, F1 Score: 0.3401411157577278\n",
      "Accuracy: 0.33437413903939756, F1 Score: 0.3299792062939742\n",
      "Epoch 51/100, Loss: 3.174875020980835, Accuracy: 0.33437413903939756, F1 Score: 0.3299792062939742\n",
      "Accuracy: 0.32656809624391586, F1 Score: 0.326948518029075\n",
      "Epoch 52/100, Loss: 0.00045457674423232675, Accuracy: 0.32656809624391586, F1 Score: 0.326948518029075\n",
      "Accuracy: 0.34732298650013776, F1 Score: 0.3394309026169416\n",
      "Epoch 53/100, Loss: 0.005198300816118717, Accuracy: 0.34732298650013776, F1 Score: 0.3394309026169416\n",
      "Accuracy: 0.34539443475066584, F1 Score: 0.339328181716289\n",
      "Epoch 54/100, Loss: 1.1920927533992653e-07, Accuracy: 0.34539443475066584, F1 Score: 0.339328181716289\n",
      "Accuracy: 0.3521902837726146, F1 Score: 0.3466135603851342\n",
      "Epoch 55/100, Loss: 5.9604641222676946e-08, Accuracy: 0.3521902837726146, F1 Score: 0.3466135603851342\n",
      "Accuracy: 0.34695564330976214, F1 Score: 0.3434547514071454\n",
      "Epoch 56/100, Loss: 0.0027605840004980564, Accuracy: 0.34695564330976214, F1 Score: 0.3434547514071454\n",
      "Accuracy: 0.3528331343557719, F1 Score: 0.347707944885411\n",
      "Epoch 57/100, Loss: 2.1457626644405536e-06, Accuracy: 0.3528331343557719, F1 Score: 0.347707944885411\n",
      "Accuracy: 0.3404353016805951, F1 Score: 0.3428451409304213\n",
      "Epoch 58/100, Loss: 1.4901145277690375e-06, Accuracy: 0.3404353016805951, F1 Score: 0.3428451409304213\n",
      "Accuracy: 0.31646615850858667, F1 Score: 0.3109127987028865\n",
      "Epoch 59/100, Loss: 0.4071955680847168, Accuracy: 0.31646615850858667, F1 Score: 0.3109127987028865\n",
      "Accuracy: 0.34805767288088896, F1 Score: 0.3375015114327962\n",
      "Epoch 60/100, Loss: 0.01037342008203268, Accuracy: 0.34805767288088896, F1 Score: 0.3375015114327962\n",
      "Accuracy: 0.3401597942878134, F1 Score: 0.3381006704862411\n",
      "Epoch 61/100, Loss: 0.00020994308579247445, Accuracy: 0.3401597942878134, F1 Score: 0.3381006704862411\n",
      "Accuracy: 0.3433740472036, F1 Score: 0.3396823688468404\n",
      "Epoch 62/100, Loss: 5.602805231319508e-06, Accuracy: 0.3433740472036, F1 Score: 0.3396823688468404\n",
      "Accuracy: 0.35182294058223895, F1 Score: 0.3466980657390771\n",
      "Epoch 63/100, Loss: 8.2009268226102e-05, Accuracy: 0.35182294058223895, F1 Score: 0.3466980657390771\n",
      "Accuracy: 0.352741298558178, F1 Score: 0.3494792136940661\n",
      "Epoch 64/100, Loss: 0.002414111280813813, Accuracy: 0.352741298558178, F1 Score: 0.3494792136940661\n",
      "Accuracy: 0.360271833960878, F1 Score: 0.3531794748607575\n",
      "Epoch 65/100, Loss: 0.0011646164348348975, Accuracy: 0.360271833960878, F1 Score: 0.3531794748607575\n",
      "Accuracy: 0.3562310588667463, F1 Score: 0.35204111157741647\n",
      "Epoch 66/100, Loss: 0.00063974445220083, Accuracy: 0.3562310588667463, F1 Score: 0.35204111157741647\n",
      "Accuracy: 0.35669023785471576, F1 Score: 0.3520957321344014\n",
      "Epoch 67/100, Loss: 0.0, Accuracy: 0.35669023785471576, F1 Score: 0.3520957321344014\n",
      "Accuracy: 0.3570575810450914, F1 Score: 0.35212211530333387\n",
      "Epoch 68/100, Loss: 3.385429590707645e-05, Accuracy: 0.3570575810450914, F1 Score: 0.35212211530333387\n",
      "Accuracy: 0.3577004316282487, F1 Score: 0.3526289529624374\n",
      "Epoch 69/100, Loss: 0.0, Accuracy: 0.3577004316282487, F1 Score: 0.3526289529624374\n",
      "Accuracy: 0.35724125264027917, F1 Score: 0.3519853411561065\n",
      "Epoch 70/100, Loss: 0.0, Accuracy: 0.35724125264027917, F1 Score: 0.3519853411561065\n",
      "Accuracy: 0.35724125264027917, F1 Score: 0.3518252672088963\n",
      "Epoch 71/100, Loss: 0.0, Accuracy: 0.35724125264027917, F1 Score: 0.3518252672088963\n",
      "Accuracy: 0.3580677748186243, F1 Score: 0.3526238288784807\n",
      "Epoch 72/100, Loss: 0.0, Accuracy: 0.3580677748186243, F1 Score: 0.3526238288784807\n",
      "Accuracy: 0.3579759390210304, F1 Score: 0.3523969989910378\n",
      "Epoch 73/100, Loss: 0.0, Accuracy: 0.3579759390210304, F1 Score: 0.3523969989910378\n",
      "Accuracy: 0.3582514464138121, F1 Score: 0.35268226981555395\n",
      "Epoch 74/100, Loss: 0.0, Accuracy: 0.3582514464138121, F1 Score: 0.35268226981555395\n",
      "Accuracy: 0.35880246119937553, F1 Score: 0.35318323895364795\n",
      "Epoch 75/100, Loss: 2.9802313861182483e-07, Accuracy: 0.35880246119937553, F1 Score: 0.35318323895364795\n",
      "Accuracy: 0.3594453117825328, F1 Score: 0.35389647272526914\n",
      "Epoch 76/100, Loss: 0.0006039679865352809, Accuracy: 0.3594453117825328, F1 Score: 0.35389647272526914\n",
      "Accuracy: 0.35999632656809627, F1 Score: 0.35429350752329114\n",
      "Epoch 77/100, Loss: 3.158946492476389e-05, Accuracy: 0.35999632656809627, F1 Score: 0.35429350752329114\n",
      "Accuracy: 0.36073101294884746, F1 Score: 0.3549387942173244\n",
      "Epoch 78/100, Loss: 3.5762775496550603e-07, Accuracy: 0.36073101294884746, F1 Score: 0.3549387942173244\n",
      "Accuracy: 0.36036366975847184, F1 Score: 0.35471146149098975\n",
      "Epoch 79/100, Loss: 0.0, Accuracy: 0.36036366975847184, F1 Score: 0.35471146149098975\n",
      "Accuracy: 0.36036366975847184, F1 Score: 0.35458981439638776\n",
      "Epoch 80/100, Loss: 0.0, Accuracy: 0.36036366975847184, F1 Score: 0.35458981439638776\n",
      "Accuracy: 0.360271833960878, F1 Score: 0.3544948303409872\n",
      "Epoch 81/100, Loss: 0.0, Accuracy: 0.360271833960878, F1 Score: 0.3544948303409872\n",
      "Accuracy: 0.36073101294884746, F1 Score: 0.3547544416414724\n",
      "Epoch 82/100, Loss: 0.000284650333924219, Accuracy: 0.36073101294884746, F1 Score: 0.3547544416414724\n",
      "Accuracy: 0.36100652034162917, F1 Score: 0.35499341814306373\n",
      "Epoch 83/100, Loss: 1.1920927533992653e-07, Accuracy: 0.36100652034162917, F1 Score: 0.35499341814306373\n",
      "Accuracy: 0.36100652034162917, F1 Score: 0.35493009602283465\n",
      "Epoch 84/100, Loss: 1.7881390590446244e-07, Accuracy: 0.36100652034162917, F1 Score: 0.35493009602283465\n",
      "Accuracy: 0.3608228487464414, F1 Score: 0.3548095261470728\n",
      "Epoch 85/100, Loss: 5.447569856187329e-05, Accuracy: 0.3608228487464414, F1 Score: 0.3548095261470728\n",
      "Accuracy: 0.36119019193681695, F1 Score: 0.35510462304472873\n",
      "Epoch 86/100, Loss: 0.0, Accuracy: 0.36119019193681695, F1 Score: 0.35510462304472873\n",
      "Accuracy: 0.3619248783175682, F1 Score: 0.35587018730163433\n",
      "Epoch 87/100, Loss: 0.0, Accuracy: 0.3619248783175682, F1 Score: 0.35587018730163433\n",
      "Accuracy: 0.36091468454403525, F1 Score: 0.3547896470648695\n",
      "Epoch 88/100, Loss: 1.1920927533992653e-07, Accuracy: 0.36091468454403525, F1 Score: 0.3547896470648695\n",
      "Accuracy: 0.36174120672238036, F1 Score: 0.3556173826538328\n",
      "Epoch 89/100, Loss: 4.351119969214778e-06, Accuracy: 0.36174120672238036, F1 Score: 0.3556173826538328\n",
      "Accuracy: 0.36174120672238036, F1 Score: 0.35555380267630693\n",
      "Epoch 90/100, Loss: 4.887556769972434e-06, Accuracy: 0.36174120672238036, F1 Score: 0.35555380267630693\n",
      "Accuracy: 0.36201671411516206, F1 Score: 0.3557948752530856\n",
      "Epoch 91/100, Loss: 0.0, Accuracy: 0.36201671411516206, F1 Score: 0.3557948752530856\n",
      "Accuracy: 0.362108549912756, F1 Score: 0.3558269138365449\n",
      "Epoch 92/100, Loss: 0.0, Accuracy: 0.362108549912756, F1 Score: 0.3558269138365449\n",
      "Accuracy: 0.3624758931031316, F1 Score: 0.3562354079050224\n",
      "Epoch 93/100, Loss: 0.0, Accuracy: 0.3624758931031316, F1 Score: 0.3562354079050224\n",
      "Accuracy: 0.3623840573055377, F1 Score: 0.35623071394539657\n",
      "Epoch 94/100, Loss: 6.55650637781946e-07, Accuracy: 0.3623840573055377, F1 Score: 0.35623071394539657\n",
      "Accuracy: 0.3626595646983194, F1 Score: 0.3564843540079704\n",
      "Epoch 95/100, Loss: 0.0, Accuracy: 0.3626595646983194, F1 Score: 0.3564843540079704\n",
      "Accuracy: 0.3632105794838828, F1 Score: 0.3568804830198724\n",
      "Epoch 96/100, Loss: 1.5914187315502204e-05, Accuracy: 0.3632105794838828, F1 Score: 0.3568804830198724\n",
      "Accuracy: 0.362108549912756, F1 Score: 0.35580413080243806\n",
      "Epoch 97/100, Loss: 0.0, Accuracy: 0.362108549912756, F1 Score: 0.35580413080243806\n",
      "Accuracy: 0.3626595646983194, F1 Score: 0.35638553815836665\n",
      "Epoch 98/100, Loss: 4.708744654635666e-06, Accuracy: 0.3626595646983194, F1 Score: 0.35638553815836665\n",
      "Accuracy: 0.3633024152814767, F1 Score: 0.35689031540746635\n",
      "Epoch 99/100, Loss: 1.9192331819795072e-05, Accuracy: 0.3633024152814767, F1 Score: 0.35689031540746635\n",
      "Accuracy: 0.3629350720911011, F1 Score: 0.35672745069023415\n",
      "Epoch 100/100, Loss: 8.940688758229953e-07, Accuracy: 0.3629350720911011, F1 Score: 0.35672745069023415\n"
     ]
    }
   ],
   "source": [
    "fine_tune_model(model.to(device), combined_labelled_dataloader, combined_test_dataloader,num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3629350720911011, F1 Score: 0.35672745069023415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3629350720911011, 0.35672745069023415)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, combined_test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
