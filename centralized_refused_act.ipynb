{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import copy\n",
    "from scipy.interpolate import CubicSpline\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy.stats import mode\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import datetime\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 32  # Set your batch size\n",
    "learning_rate_client = 0.001\n",
    "local_epochs = 1\n",
    "subject_dir = 'FL_Data/windowed_data_refused/subject_'  # Set your directory to the subject data\n",
    "numclients = 54\n",
    "num_classes = 9\n",
    "\n",
    "#current timestamp\n",
    "current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "torch.manual_seed(420)\n",
    "np.random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_client(id, batch_size=batch_size, type='labelled_train'):\n",
    "    # Load the data\n",
    "    data = np.load(subject_dir + str(id) + '/windowed_' + type + '_x.npy')\n",
    "    labels = np.load(subject_dir + str(id) + '/windowed_' + type + '_y.npy')\n",
    "\n",
    "    # print shape of data\n",
    "    # print(data.shape)\n",
    "    # print(labels.shape)\n",
    "\n",
    "    # Convert to torch tensor\n",
    "    data = torch.from_numpy(data).float()\n",
    "    labels = torch.from_numpy(labels).long()\n",
    "\n",
    "    # Create a dataset\n",
    "    dataset = torch.utils.data.TensorDataset(data, labels)\n",
    "\n",
    "    # Create a dataloader\n",
    "    if type == 'labelled_train' or type == 'unlabelled_train':\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    else:\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject id: 0, len: 12\n",
      "subject id: 1, len: 11\n",
      "subject id: 2, len: 12\n",
      "subject id: 3, len: 10\n",
      "subject id: 4, len: 13\n",
      "subject id: 5, len: 12\n",
      "subject id: 6, len: 3\n",
      "subject id: 7, len: 4\n",
      "subject id: 8, len: 2\n",
      "subject id: 9, len: 11\n",
      "subject id: 10, len: 9\n",
      "subject id: 11, len: 12\n",
      "subject id: 12, len: 11\n",
      "subject id: 13, len: 13\n",
      "subject id: 14, len: 11\n",
      "subject id: 15, len: 10\n",
      "subject id: 16, len: 13\n",
      "subject id: 17, len: 12\n",
      "subject id: 18, len: 11\n",
      "subject id: 19, len: 11\n",
      "subject id: 20, len: 11\n",
      "subject id: 21, len: 11\n",
      "subject id: 22, len: 9\n",
      "subject id: 23, len: 12\n",
      "subject id: 24, len: 2\n",
      "subject id: 25, len: 2\n",
      "subject id: 26, len: 2\n",
      "subject id: 27, len: 2\n",
      "subject id: 28, len: 2\n",
      "subject id: 29, len: 2\n",
      "subject id: 30, len: 2\n",
      "subject id: 31, len: 2\n",
      "subject id: 32, len: 2\n",
      "subject id: 33, len: 2\n",
      "subject id: 34, len: 2\n",
      "subject id: 35, len: 2\n",
      "subject id: 36, len: 2\n",
      "subject id: 37, len: 2\n",
      "subject id: 38, len: 2\n",
      "subject id: 39, len: 2\n",
      "subject id: 40, len: 2\n",
      "subject id: 41, len: 2\n",
      "subject id: 42, len: 2\n",
      "subject id: 43, len: 2\n",
      "subject id: 44, len: 2\n",
      "subject id: 45, len: 2\n",
      "subject id: 46, len: 2\n",
      "subject id: 47, len: 2\n",
      "subject id: 48, len: 2\n",
      "subject id: 49, len: 2\n",
      "subject id: 50, len: 2\n",
      "subject id: 51, len: 2\n",
      "subject id: 52, len: 2\n",
      "subject id: 53, len: 2\n"
     ]
    }
   ],
   "source": [
    "labelled_data = []\n",
    "\n",
    "for i in range(numclients):\n",
    "    data_label = load_data_client(id= i, batch_size=batch_size, type='labelled_train')\n",
    "    print(f\"subject id: {i}, len: {len(data_label)}\")\n",
    "    labelled_data.append(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined labelled: 273\n"
     ]
    }
   ],
   "source": [
    "# combine all client labelled data into one\n",
    "combined_labelled_data = []\n",
    "combined_labelled_labels = []\n",
    "for i in range(numclients):\n",
    "    for data, labels in labelled_data[i]:\n",
    "        combined_labelled_data.append(data)\n",
    "        combined_labelled_labels.append(labels)\n",
    "combined_labelled_data = torch.cat(combined_labelled_data, dim=0)\n",
    "combined_labelled_labels = torch.cat(combined_labelled_labels, dim=0)\n",
    "# create dataset and dataloader\n",
    "combined_labelled_dataset = torch.utils.data.TensorDataset(combined_labelled_data, combined_labelled_labels)\n",
    "combined_labelled_dataloader = torch.utils.data.DataLoader(combined_labelled_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"combined labelled: {len(combined_labelled_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined unlabelled: 1092\n"
     ]
    }
   ],
   "source": [
    "# combine all unlabelled data into one\n",
    "unlabelled_data = []\n",
    "for i in range(numclients):\n",
    "    data = load_data_client(id= i, batch_size=batch_size, type='unlabelled_train')\n",
    "    unlabelled_data.append(data)\n",
    "\n",
    "combined_unlabelled_data = []\n",
    "combined_unlabelled_labels = []\n",
    "for i in range(numclients):\n",
    "    for data, labels in unlabelled_data[i]:\n",
    "        combined_unlabelled_data.append(data)\n",
    "        combined_unlabelled_labels.append(labels)\n",
    "combined_unlabelled_data = torch.cat(combined_unlabelled_data, dim=0)\n",
    "combined_unlabelled_labels = torch.cat(combined_unlabelled_labels, dim=0)\n",
    "# create dataset and dataloader\n",
    "combined_unlabelled_dataset = torch.utils.data.TensorDataset(combined_unlabelled_data, combined_unlabelled_labels)\n",
    "combined_unlabelled_dataloader = torch.utils.data.DataLoader(combined_unlabelled_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"combined unlabelled: {len(combined_unlabelled_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined test: 341\n"
     ]
    }
   ],
   "source": [
    "# combine all test data into one\n",
    "test_data = []\n",
    "for i in range(numclients):\n",
    "    data = load_data_client(id= i, batch_size=batch_size, type='test')\n",
    "    test_data.append(data)\n",
    "\n",
    "combined_test_data = []\n",
    "combined_test_labels = []\n",
    "for i in range(numclients):\n",
    "    for data, labels in test_data[i]:\n",
    "        combined_test_data.append(data)\n",
    "        combined_test_labels.append(labels)\n",
    "combined_test_data = torch.cat(combined_test_data, dim=0)\n",
    "combined_test_labels = torch.cat(combined_test_labels, dim=0)\n",
    "# create dataset and dataloader\n",
    "combined_test_dataset = torch.utils.data.TensorDataset(combined_test_data, combined_test_labels)\n",
    "combined_test_dataloader = torch.utils.data.DataLoader(combined_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"combined test: {len(combined_test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256 * 12, 128)  # Adjust the input features according to your final conv layer output\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training function\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.transpose(1, 2)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testing function\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    #calculate accuracy\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs = inputs.transpose(1, 2)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            #calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return running_loss / len(test_loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to train and test model\n",
    "def train_and_test(model, train_loader, test_loader, criterion, optimizer, device, num_epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "        test_loss, test_accuracy = test(model, test_loader, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        print(f\"Epoch: {epoch + 1}/{num_epochs}.. Train Loss: {train_loss:.3f}.. Test Loss: {test_loss:.3f}.. Test Accuracy: {test_accuracy:.3f}\")\n",
    "    return train_losses, test_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100.. Train Loss: 1.389.. Test Loss: 1.387.. Test Accuracy: 0.255\n",
      "Epoch: 2/100.. Train Loss: 1.387.. Test Loss: 1.387.. Test Accuracy: 0.256\n",
      "Epoch: 3/100.. Train Loss: 1.386.. Test Loss: 1.385.. Test Accuracy: 0.263\n",
      "Epoch: 4/100.. Train Loss: 1.386.. Test Loss: 1.385.. Test Accuracy: 0.268\n",
      "Epoch: 5/100.. Train Loss: 1.385.. Test Loss: 1.386.. Test Accuracy: 0.256\n",
      "Epoch: 6/100.. Train Loss: 1.384.. Test Loss: 1.385.. Test Accuracy: 0.261\n",
      "Epoch: 7/100.. Train Loss: 1.384.. Test Loss: 1.383.. Test Accuracy: 0.269\n",
      "Epoch: 8/100.. Train Loss: 1.383.. Test Loss: 1.382.. Test Accuracy: 0.286\n",
      "Epoch: 9/100.. Train Loss: 1.383.. Test Loss: 1.381.. Test Accuracy: 0.281\n",
      "Epoch: 10/100.. Train Loss: 1.382.. Test Loss: 1.381.. Test Accuracy: 0.287\n",
      "Epoch: 11/100.. Train Loss: 1.381.. Test Loss: 1.381.. Test Accuracy: 0.271\n",
      "Epoch: 12/100.. Train Loss: 1.381.. Test Loss: 1.382.. Test Accuracy: 0.259\n",
      "Epoch: 13/100.. Train Loss: 1.380.. Test Loss: 1.382.. Test Accuracy: 0.278\n",
      "Epoch: 14/100.. Train Loss: 1.380.. Test Loss: 1.379.. Test Accuracy: 0.291\n",
      "Epoch: 15/100.. Train Loss: 1.379.. Test Loss: 1.380.. Test Accuracy: 0.265\n",
      "Epoch: 16/100.. Train Loss: 1.378.. Test Loss: 1.377.. Test Accuracy: 0.291\n",
      "Epoch: 17/100.. Train Loss: 1.378.. Test Loss: 1.377.. Test Accuracy: 0.290\n",
      "Epoch: 18/100.. Train Loss: 1.377.. Test Loss: 1.375.. Test Accuracy: 0.314\n",
      "Epoch: 19/100.. Train Loss: 1.376.. Test Loss: 1.375.. Test Accuracy: 0.297\n",
      "Epoch: 20/100.. Train Loss: 1.375.. Test Loss: 1.373.. Test Accuracy: 0.304\n",
      "Epoch: 21/100.. Train Loss: 1.374.. Test Loss: 1.377.. Test Accuracy: 0.277\n",
      "Epoch: 22/100.. Train Loss: 1.373.. Test Loss: 1.372.. Test Accuracy: 0.313\n",
      "Epoch: 23/100.. Train Loss: 1.372.. Test Loss: 1.370.. Test Accuracy: 0.312\n",
      "Epoch: 24/100.. Train Loss: 1.371.. Test Loss: 1.369.. Test Accuracy: 0.325\n",
      "Epoch: 25/100.. Train Loss: 1.370.. Test Loss: 1.373.. Test Accuracy: 0.296\n",
      "Epoch: 26/100.. Train Loss: 1.369.. Test Loss: 1.371.. Test Accuracy: 0.314\n",
      "Epoch: 27/100.. Train Loss: 1.368.. Test Loss: 1.372.. Test Accuracy: 0.294\n",
      "Epoch: 28/100.. Train Loss: 1.366.. Test Loss: 1.367.. Test Accuracy: 0.311\n",
      "Epoch: 29/100.. Train Loss: 1.365.. Test Loss: 1.363.. Test Accuracy: 0.331\n",
      "Epoch: 30/100.. Train Loss: 1.363.. Test Loss: 1.361.. Test Accuracy: 0.333\n",
      "Epoch: 31/100.. Train Loss: 1.362.. Test Loss: 1.365.. Test Accuracy: 0.288\n",
      "Epoch: 32/100.. Train Loss: 1.360.. Test Loss: 1.362.. Test Accuracy: 0.318\n",
      "Epoch: 33/100.. Train Loss: 1.358.. Test Loss: 1.357.. Test Accuracy: 0.339\n",
      "Epoch: 34/100.. Train Loss: 1.357.. Test Loss: 1.355.. Test Accuracy: 0.346\n",
      "Epoch: 35/100.. Train Loss: 1.354.. Test Loss: 1.370.. Test Accuracy: 0.310\n",
      "Epoch: 36/100.. Train Loss: 1.353.. Test Loss: 1.350.. Test Accuracy: 0.348\n",
      "Epoch: 37/100.. Train Loss: 1.350.. Test Loss: 1.353.. Test Accuracy: 0.329\n",
      "Epoch: 38/100.. Train Loss: 1.348.. Test Loss: 1.355.. Test Accuracy: 0.328\n",
      "Epoch: 39/100.. Train Loss: 1.345.. Test Loss: 1.343.. Test Accuracy: 0.353\n",
      "Epoch: 40/100.. Train Loss: 1.342.. Test Loss: 1.338.. Test Accuracy: 0.369\n",
      "Epoch: 41/100.. Train Loss: 1.340.. Test Loss: 1.342.. Test Accuracy: 0.343\n",
      "Epoch: 42/100.. Train Loss: 1.337.. Test Loss: 1.332.. Test Accuracy: 0.373\n",
      "Epoch: 43/100.. Train Loss: 1.333.. Test Loss: 1.341.. Test Accuracy: 0.339\n",
      "Epoch: 44/100.. Train Loss: 1.330.. Test Loss: 1.387.. Test Accuracy: 0.262\n",
      "Epoch: 45/100.. Train Loss: 1.326.. Test Loss: 1.330.. Test Accuracy: 0.357\n",
      "Epoch: 46/100.. Train Loss: 1.322.. Test Loss: 1.315.. Test Accuracy: 0.392\n",
      "Epoch: 47/100.. Train Loss: 1.319.. Test Loss: 1.317.. Test Accuracy: 0.376\n",
      "Epoch: 48/100.. Train Loss: 1.314.. Test Loss: 1.317.. Test Accuracy: 0.373\n",
      "Epoch: 49/100.. Train Loss: 1.308.. Test Loss: 1.322.. Test Accuracy: 0.348\n",
      "Epoch: 50/100.. Train Loss: 1.305.. Test Loss: 1.340.. Test Accuracy: 0.305\n",
      "Epoch: 51/100.. Train Loss: 1.300.. Test Loss: 1.355.. Test Accuracy: 0.293\n",
      "Epoch: 52/100.. Train Loss: 1.295.. Test Loss: 1.298.. Test Accuracy: 0.379\n",
      "Epoch: 53/100.. Train Loss: 1.289.. Test Loss: 1.303.. Test Accuracy: 0.377\n",
      "Epoch: 54/100.. Train Loss: 1.283.. Test Loss: 1.304.. Test Accuracy: 0.373\n",
      "Epoch: 55/100.. Train Loss: 1.277.. Test Loss: 1.299.. Test Accuracy: 0.371\n",
      "Epoch: 56/100.. Train Loss: 1.269.. Test Loss: 1.281.. Test Accuracy: 0.394\n",
      "Epoch: 57/100.. Train Loss: 1.263.. Test Loss: 1.270.. Test Accuracy: 0.411\n",
      "Epoch: 58/100.. Train Loss: 1.256.. Test Loss: 1.293.. Test Accuracy: 0.377\n",
      "Epoch: 59/100.. Train Loss: 1.250.. Test Loss: 1.299.. Test Accuracy: 0.367\n",
      "Epoch: 60/100.. Train Loss: 1.241.. Test Loss: 1.264.. Test Accuracy: 0.410\n",
      "Epoch: 61/100.. Train Loss: 1.233.. Test Loss: 1.230.. Test Accuracy: 0.440\n",
      "Epoch: 62/100.. Train Loss: 1.225.. Test Loss: 1.231.. Test Accuracy: 0.438\n",
      "Epoch: 63/100.. Train Loss: 1.216.. Test Loss: 1.253.. Test Accuracy: 0.399\n",
      "Epoch: 64/100.. Train Loss: 1.206.. Test Loss: 1.281.. Test Accuracy: 0.388\n",
      "Epoch: 65/100.. Train Loss: 1.197.. Test Loss: 1.213.. Test Accuracy: 0.451\n",
      "Epoch: 66/100.. Train Loss: 1.188.. Test Loss: 1.265.. Test Accuracy: 0.403\n",
      "Epoch: 67/100.. Train Loss: 1.179.. Test Loss: 1.187.. Test Accuracy: 0.462\n",
      "Epoch: 68/100.. Train Loss: 1.167.. Test Loss: 1.442.. Test Accuracy: 0.283\n",
      "Epoch: 69/100.. Train Loss: 1.157.. Test Loss: 1.320.. Test Accuracy: 0.363\n",
      "Epoch: 70/100.. Train Loss: 1.146.. Test Loss: 1.246.. Test Accuracy: 0.388\n",
      "Epoch: 71/100.. Train Loss: 1.133.. Test Loss: 1.136.. Test Accuracy: 0.491\n",
      "Epoch: 72/100.. Train Loss: 1.120.. Test Loss: 1.439.. Test Accuracy: 0.302\n",
      "Epoch: 73/100.. Train Loss: 1.111.. Test Loss: 1.327.. Test Accuracy: 0.353\n",
      "Epoch: 74/100.. Train Loss: 1.098.. Test Loss: 1.130.. Test Accuracy: 0.488\n",
      "Epoch: 75/100.. Train Loss: 1.084.. Test Loss: 1.395.. Test Accuracy: 0.368\n",
      "Epoch: 76/100.. Train Loss: 1.070.. Test Loss: 1.118.. Test Accuracy: 0.493\n",
      "Epoch: 77/100.. Train Loss: 1.058.. Test Loss: 1.899.. Test Accuracy: 0.269\n",
      "Epoch: 78/100.. Train Loss: 1.045.. Test Loss: 1.034.. Test Accuracy: 0.553\n",
      "Epoch: 79/100.. Train Loss: 1.028.. Test Loss: 1.104.. Test Accuracy: 0.499\n",
      "Epoch: 80/100.. Train Loss: 1.012.. Test Loss: 1.083.. Test Accuracy: 0.502\n",
      "Epoch: 81/100.. Train Loss: 0.999.. Test Loss: 1.139.. Test Accuracy: 0.492\n",
      "Epoch: 82/100.. Train Loss: 0.981.. Test Loss: 0.979.. Test Accuracy: 0.580\n",
      "Epoch: 83/100.. Train Loss: 0.967.. Test Loss: 1.068.. Test Accuracy: 0.498\n",
      "Epoch: 84/100.. Train Loss: 0.950.. Test Loss: 1.274.. Test Accuracy: 0.396\n",
      "Epoch: 85/100.. Train Loss: 0.934.. Test Loss: 1.089.. Test Accuracy: 0.488\n",
      "Epoch: 86/100.. Train Loss: 0.917.. Test Loss: 0.973.. Test Accuracy: 0.570\n",
      "Epoch: 87/100.. Train Loss: 0.898.. Test Loss: 1.018.. Test Accuracy: 0.522\n",
      "Epoch: 88/100.. Train Loss: 0.884.. Test Loss: 1.364.. Test Accuracy: 0.422\n",
      "Epoch: 89/100.. Train Loss: 0.865.. Test Loss: 1.485.. Test Accuracy: 0.359\n",
      "Epoch: 90/100.. Train Loss: 0.847.. Test Loss: 1.362.. Test Accuracy: 0.444\n",
      "Epoch: 91/100.. Train Loss: 0.829.. Test Loss: 1.010.. Test Accuracy: 0.523\n",
      "Epoch: 92/100.. Train Loss: 0.812.. Test Loss: 1.334.. Test Accuracy: 0.437\n",
      "Epoch: 93/100.. Train Loss: 0.795.. Test Loss: 0.951.. Test Accuracy: 0.567\n",
      "Epoch: 94/100.. Train Loss: 0.773.. Test Loss: 1.080.. Test Accuracy: 0.500\n",
      "Epoch: 95/100.. Train Loss: 0.752.. Test Loss: 0.754.. Test Accuracy: 0.682\n",
      "Epoch: 96/100.. Train Loss: 0.736.. Test Loss: 1.293.. Test Accuracy: 0.447\n",
      "Epoch: 97/100.. Train Loss: 0.716.. Test Loss: 1.162.. Test Accuracy: 0.474\n",
      "Epoch: 98/100.. Train Loss: 0.698.. Test Loss: 0.633.. Test Accuracy: 0.766\n",
      "Epoch: 99/100.. Train Loss: 0.676.. Test Loss: 1.230.. Test Accuracy: 0.433\n",
      "Epoch: 100/100.. Train Loss: 0.657.. Test Loss: 1.677.. Test Accuracy: 0.409\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4\n",
    "\n",
    "model = CNNFeatureExtractor(num_classes=num_classes)\n",
    "\n",
    "# move model to GPU if available\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 100\n",
    "train_losses, test_losses, test_accuracies = train_and_test(model, combined_unlabelled_dataloader, combined_unlabelled_dataloader, criterion, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to test the model and get the accuracy and f1 score\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.permute(0, 2, 1)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f'Accuracy: {accuracy}, F1 Score: {f1}')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(model, train_loader, test_loader, num_epochs=200):\n",
    "    # Assuming class weights are calculated and provided as `class_weights`\n",
    "    # class_weights = torch.tensor(c_weight).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # optimizer = torch.optim.Adam(model.fc2.parameters(), lr=0.001)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.permute(0, 2, 1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        acc, f1 = test_model(model, test_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, Accuracy: {acc}, F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNFeatureExtractor(\n",
      "  (conv1): Conv1d(3, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=3072, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=9, bias=True)\n",
      ")\n",
      "Accuracy: 0.34355771879878777, F1 Score: 0.2850249148646848\n",
      "Epoch 1/50, Loss: 1.8627986907958984, Accuracy: 0.34355771879878777, F1 Score: 0.2850249148646848\n",
      "Accuracy: 0.35981265497290843, F1 Score: 0.3075872788934069\n",
      "Epoch 2/50, Loss: 2.348477840423584, Accuracy: 0.35981265497290843, F1 Score: 0.3075872788934069\n",
      "Accuracy: 0.36816971255395353, F1 Score: 0.3201810610845825\n",
      "Epoch 3/50, Loss: 1.1873211860656738, Accuracy: 0.36816971255395353, F1 Score: 0.3201810610845825\n",
      "Accuracy: 0.3825879327761962, F1 Score: 0.3345372083619573\n",
      "Epoch 4/50, Loss: 1.2316997051239014, Accuracy: 0.3825879327761962, F1 Score: 0.3345372083619573\n",
      "Accuracy: 0.37367986040958767, F1 Score: 0.35980169480355817\n",
      "Epoch 5/50, Loss: 1.12241530418396, Accuracy: 0.37367986040958767, F1 Score: 0.35980169480355817\n",
      "Accuracy: 0.37781247130131324, F1 Score: 0.3511862133767205\n",
      "Epoch 6/50, Loss: 1.134645700454712, Accuracy: 0.37781247130131324, F1 Score: 0.3511862133767205\n",
      "Accuracy: 0.3838736339425108, F1 Score: 0.36824417741398874\n",
      "Epoch 7/50, Loss: 1.2086639404296875, Accuracy: 0.3838736339425108, F1 Score: 0.36824417741398874\n",
      "Accuracy: 0.3699145927082377, F1 Score: 0.3534884844381801\n",
      "Epoch 8/50, Loss: 3.362246036529541, Accuracy: 0.3699145927082377, F1 Score: 0.3534884844381801\n",
      "Accuracy: 0.35659840205712184, F1 Score: 0.34219439874514984\n",
      "Epoch 9/50, Loss: 0.5457718372344971, Accuracy: 0.35659840205712184, F1 Score: 0.34219439874514984\n",
      "Accuracy: 0.36927174212508035, F1 Score: 0.3615066617355979\n",
      "Epoch 10/50, Loss: 1.4433950185775757, Accuracy: 0.36927174212508035, F1 Score: 0.3615066617355979\n",
      "Accuracy: 0.36073101294884746, F1 Score: 0.34885944776526134\n",
      "Epoch 11/50, Loss: 1.4873297214508057, Accuracy: 0.36073101294884746, F1 Score: 0.34885944776526134\n",
      "Accuracy: 0.3634860868766645, F1 Score: 0.363582137019968\n",
      "Epoch 12/50, Loss: 2.3151702880859375, Accuracy: 0.3634860868766645, F1 Score: 0.363582137019968\n",
      "Accuracy: 0.35659840205712184, F1 Score: 0.3453908486325857\n",
      "Epoch 13/50, Loss: 0.10427011549472809, Accuracy: 0.35659840205712184, F1 Score: 0.3453908486325857\n",
      "Accuracy: 0.32445587289925615, F1 Score: 0.3246448065880937\n",
      "Epoch 14/50, Loss: 1.2437360286712646, Accuracy: 0.32445587289925615, F1 Score: 0.3246448065880937\n",
      "Accuracy: 0.3487005234640463, F1 Score: 0.3419923380485923\n",
      "Epoch 15/50, Loss: 0.08505640178918839, Accuracy: 0.3487005234640463, F1 Score: 0.3419923380485923\n",
      "Accuracy: 0.3503535678207365, F1 Score: 0.3460187381494233\n",
      "Epoch 16/50, Loss: 1.0531996488571167, Accuracy: 0.3503535678207365, F1 Score: 0.3460187381494233\n",
      "Accuracy: 0.34741482229773163, F1 Score: 0.3387037325364305\n",
      "Epoch 17/50, Loss: 0.42718741297721863, Accuracy: 0.34741482229773163, F1 Score: 0.3387037325364305\n",
      "Accuracy: 0.3283129763982, F1 Score: 0.3228004845582595\n",
      "Epoch 18/50, Loss: 0.03807832673192024, Accuracy: 0.3283129763982, F1 Score: 0.3228004845582595\n",
      "Accuracy: 0.3312517219212049, F1 Score: 0.3299668343567858\n",
      "Epoch 19/50, Loss: 0.41545018553733826, Accuracy: 0.3312517219212049, F1 Score: 0.3299668343567858\n",
      "Accuracy: 0.3331802736706768, F1 Score: 0.33087560581929726\n",
      "Epoch 20/50, Loss: 0.6310400366783142, Accuracy: 0.3331802736706768, F1 Score: 0.33087560581929726\n",
      "Accuracy: 0.3331802736706768, F1 Score: 0.3326173321228025\n",
      "Epoch 21/50, Loss: 0.46749991178512573, Accuracy: 0.3331802736706768, F1 Score: 0.3326173321228025\n",
      "Accuracy: 0.337680227752778, F1 Score: 0.3327109626571081\n",
      "Epoch 22/50, Loss: 0.24067232012748718, Accuracy: 0.337680227752778, F1 Score: 0.3327109626571081\n",
      "Accuracy: 0.3401597942878134, F1 Score: 0.33153206925946316\n",
      "Epoch 23/50, Loss: 0.6614887118339539, Accuracy: 0.3401597942878134, F1 Score: 0.33153206925946316\n",
      "Accuracy: 0.3288639911837634, F1 Score: 0.32655931348366546\n",
      "Epoch 24/50, Loss: 0.01225706934928894, Accuracy: 0.3288639911837634, F1 Score: 0.32655931348366546\n",
      "Accuracy: 0.3192212324364037, F1 Score: 0.3162336422257169\n",
      "Epoch 25/50, Loss: 0.912361741065979, Accuracy: 0.3192212324364037, F1 Score: 0.3162336422257169\n",
      "Accuracy: 0.3238130223160988, F1 Score: 0.3262641105470006\n",
      "Epoch 26/50, Loss: 0.6036192774772644, Accuracy: 0.3238130223160988, F1 Score: 0.3262641105470006\n",
      "Accuracy: 0.3210579483882818, F1 Score: 0.31458329105979427\n",
      "Epoch 27/50, Loss: 0.28663814067840576, Accuracy: 0.3210579483882818, F1 Score: 0.31458329105979427\n",
      "Accuracy: 0.3266599320415098, F1 Score: 0.32783183447244346\n",
      "Epoch 28/50, Loss: 0.11605717986822128, Accuracy: 0.3266599320415098, F1 Score: 0.32783183447244346\n",
      "Accuracy: 0.33492515382496096, F1 Score: 0.3320930024289342\n",
      "Epoch 29/50, Loss: 0.522503137588501, Accuracy: 0.33492515382496096, F1 Score: 0.3320930024289342\n",
      "Accuracy: 0.3175681880797135, F1 Score: 0.3197152238932185\n",
      "Epoch 30/50, Loss: 1.0330719947814941, Accuracy: 0.3175681880797135, F1 Score: 0.3197152238932185\n",
      "Accuracy: 0.3313435577187988, F1 Score: 0.33077083015877345\n",
      "Epoch 31/50, Loss: 0.0003259907243773341, Accuracy: 0.3313435577187988, F1 Score: 0.33077083015877345\n",
      "Accuracy: 0.3103131600697952, F1 Score: 0.30598948728673137\n",
      "Epoch 32/50, Loss: 1.0019358396530151, Accuracy: 0.3103131600697952, F1 Score: 0.30598948728673137\n",
      "Accuracy: 0.33024152814767194, F1 Score: 0.3254373928176377\n",
      "Epoch 33/50, Loss: 2.0651681423187256, Accuracy: 0.33024152814767194, F1 Score: 0.3254373928176377\n",
      "Accuracy: 0.32087427679309394, F1 Score: 0.3210386567418266\n",
      "Epoch 34/50, Loss: 0.023262614384293556, Accuracy: 0.32087427679309394, F1 Score: 0.3210386567418266\n",
      "Accuracy: 0.32583340986316467, F1 Score: 0.32388403262816373\n",
      "Epoch 35/50, Loss: 0.000730517553165555, Accuracy: 0.32583340986316467, F1 Score: 0.32388403262816373\n",
      "Accuracy: 0.326476260446322, F1 Score: 0.3253108322308776\n",
      "Epoch 36/50, Loss: 0.0210662130266428, Accuracy: 0.326476260446322, F1 Score: 0.3253108322308776\n",
      "Accuracy: 0.32868031958857563, F1 Score: 0.3262513885841046\n",
      "Epoch 37/50, Loss: 0.6123465299606323, Accuracy: 0.32868031958857563, F1 Score: 0.3262513885841046\n",
      "Accuracy: 0.3261089172559464, F1 Score: 0.3235998752255166\n",
      "Epoch 38/50, Loss: 0.00032000444480217993, Accuracy: 0.3261089172559464, F1 Score: 0.3235998752255166\n",
      "Accuracy: 0.3272109468270732, F1 Score: 0.3256906273987955\n",
      "Epoch 39/50, Loss: 0.3877953588962555, Accuracy: 0.3272109468270732, F1 Score: 0.3256906273987955\n",
      "Accuracy: 0.3250987234824134, F1 Score: 0.32270566938108286\n",
      "Epoch 40/50, Loss: 0.007971568033099174, Accuracy: 0.3250987234824134, F1 Score: 0.32270566938108286\n",
      "Accuracy: 0.32454770869685, F1 Score: 0.3215324097155655\n",
      "Epoch 41/50, Loss: 0.00010501235374249518, Accuracy: 0.32454770869685, F1 Score: 0.3215324097155655\n",
      "Accuracy: 0.315180457342272, F1 Score: 0.3098952540076533\n",
      "Epoch 42/50, Loss: 0.00017860323714558035, Accuracy: 0.315180457342272, F1 Score: 0.3098952540076533\n",
      "Accuracy: 0.31903756084121593, F1 Score: 0.3151496615175704\n",
      "Epoch 43/50, Loss: 0.00411826791241765, Accuracy: 0.31903756084121593, F1 Score: 0.3151496615175704\n",
      "Accuracy: 0.31233354761686105, F1 Score: 0.3118203532040457\n",
      "Epoch 44/50, Loss: 0.544317901134491, Accuracy: 0.31233354761686105, F1 Score: 0.3118203532040457\n",
      "Accuracy: 0.314262099366333, F1 Score: 0.31492358874036896\n",
      "Epoch 45/50, Loss: 0.0016371095553040504, Accuracy: 0.314262099366333, F1 Score: 0.31492358874036896\n",
      "Accuracy: 0.3278537974102305, F1 Score: 0.3251858502802714\n",
      "Epoch 46/50, Loss: 1.180162053060485e-05, Accuracy: 0.3278537974102305, F1 Score: 0.3251858502802714\n",
      "Accuracy: 0.3175681880797135, F1 Score: 0.3143201689327608\n",
      "Epoch 47/50, Loss: 0.0015670045977458358, Accuracy: 0.3175681880797135, F1 Score: 0.3143201689327608\n",
      "Accuracy: 0.318945725043622, F1 Score: 0.3187706174847454\n",
      "Epoch 48/50, Loss: 0.011490754783153534, Accuracy: 0.318945725043622, F1 Score: 0.3187706174847454\n",
      "Accuracy: 0.29415005969326846, F1 Score: 0.291685231755002\n",
      "Epoch 49/50, Loss: 0.9524307250976562, Accuracy: 0.29415005969326846, F1 Score: 0.291685231755002\n",
      "Accuracy: 0.3199559188171549, F1 Score: 0.3166586532973304\n",
      "Epoch 50/50, Loss: 8.761806384427473e-06, Accuracy: 0.3199559188171549, F1 Score: 0.3166586532973304\n"
     ]
    }
   ],
   "source": [
    "# create model fine tuning\n",
    "model_tuned = copy.deepcopy(model)\n",
    "\n",
    " # Freezing layers up to conv3\n",
    "for name, param in model_tuned.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        break\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layers from conv3 onwards\n",
    "unfreeze = False\n",
    "for name, param in model_tuned.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        unfreeze = True\n",
    "    if unfreeze:\n",
    "        param.requires_grad = True\n",
    "\n",
    "model_tuned.fc2 = nn.Linear(in_features=model_tuned.fc2.in_features, out_features=9)\n",
    "model_tuned.to(device)\n",
    "print(model_tuned)\n",
    "\n",
    "fine_tune_model(model_tuned.to(device), combined_labelled_dataloader, combined_test_dataloader,num_epochs=50)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
