{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "train_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.378284</td>\n",
       "      <td>10.168175</td>\n",
       "      <td>0.847547</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.383671</td>\n",
       "      <td>10.172364</td>\n",
       "      <td>0.849942</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.372298</td>\n",
       "      <td>10.181941</td>\n",
       "      <td>0.859518</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.342969</td>\n",
       "      <td>10.170568</td>\n",
       "      <td>0.834379</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.319626</td>\n",
       "      <td>10.159795</td>\n",
       "      <td>0.818817</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject         x          y         z     activity\n",
       "0        0  0.378284  10.168175  0.847547  climbing_up\n",
       "1        0  0.383671  10.172364  0.849942  climbing_up\n",
       "2        0  0.372298  10.181941  0.859518  climbing_up\n",
       "3        0  0.342969  10.170568  0.834379  climbing_up\n",
       "4        0  0.319626  10.159795  0.818817  climbing_up"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data without header\n",
    "data = pd.read_csv('./ISWC21_data_plus_raw/rwhar_3sbjs_data.csv', header=None)\n",
    "# add header\n",
    "data.columns = ['subject', 'x', 'y', 'z', 'activity']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659260, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(data['activity'])\n",
    "data['encoded_activity'] = encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>activity</th>\n",
       "      <th>encoded_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.378284</td>\n",
       "      <td>10.168175</td>\n",
       "      <td>0.847547</td>\n",
       "      <td>climbing_up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.383671</td>\n",
       "      <td>10.172364</td>\n",
       "      <td>0.849942</td>\n",
       "      <td>climbing_up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.372298</td>\n",
       "      <td>10.181941</td>\n",
       "      <td>0.859518</td>\n",
       "      <td>climbing_up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.342969</td>\n",
       "      <td>10.170568</td>\n",
       "      <td>0.834379</td>\n",
       "      <td>climbing_up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.319626</td>\n",
       "      <td>10.159795</td>\n",
       "      <td>0.818817</td>\n",
       "      <td>climbing_up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject         x          y         z     activity  encoded_activity\n",
       "0        0  0.378284  10.168175  0.847547  climbing_up                 1\n",
       "1        0  0.383671  10.172364  0.849942  climbing_up                 1\n",
       "2        0  0.372298  10.181941  0.859518  climbing_up                 1\n",
       "3        0  0.342969  10.170568  0.834379  climbing_up                 1\n",
       "4        0  0.319626  10.159795  0.818817  climbing_up                 1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_samples(data, samples_per_window, overlap_ratio):\n",
    "    \"\"\"\n",
    "    Return a sliding window measured in number of samples over a data array along with the mode label for each window.\n",
    "\n",
    "    :param data: input array, can be numpy or pandas dataframe\n",
    "    :param samples_per_window: window length as number of samples\n",
    "    :param overlap_ratio: overlap is meant as percentage and should be an integer value\n",
    "    :return: tuple of windows, indices, and labels\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    indices = []\n",
    "    labels = []\n",
    "    curr = 0\n",
    "    win_len = int(samples_per_window)\n",
    "    if overlap_ratio is not None:\n",
    "        overlapping_elements = int((overlap_ratio / 100) * win_len)\n",
    "        if overlapping_elements >= win_len:\n",
    "            print('Number of overlapping elements exceeds window size.')\n",
    "            return\n",
    "    while curr < len(data) - win_len:\n",
    "        window = data[curr:curr + win_len]\n",
    "        windows.append(window.iloc[:, :-2])  # Exclude the last two columns (original and encoded labels)\n",
    "        indices.append([curr, curr + win_len])\n",
    "        \n",
    "        # Extract and compute the mode of the encoded labels for the current window\n",
    "        window_labels = window['encoded_activity']\n",
    "        mode_result = mode(window_labels)\n",
    "        window_label = mode_result[0] if mode_result[0].size > 0 else mode_result\n",
    "        labels.append(window_label)\n",
    "\n",
    "        curr += win_len - overlapping_elements\n",
    "\n",
    "    result_windows = np.array(windows)\n",
    "    result_indices = np.array(indices)\n",
    "    result_labels = np.array(labels)\n",
    "    return result_windows, result_indices, result_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of window dataset (2 sec with 0% overlap): (6592, 100, 4)\n",
      "shape of window label (2 sec with 0% overlap): (6592,)\n"
     ]
    }
   ],
   "source": [
    "sampling_rate = 50\n",
    "time_window = 2\n",
    "window_size = sampling_rate * time_window\n",
    "overlap_ratio = 0\n",
    "\n",
    "window_data, _, window_label = sliding_window_samples(data, window_size, overlap_ratio)\n",
    "print(f\"shape of window dataset (2 sec with 0% overlap): {window_data.shape}\")\n",
    "print(f\"shape of window label (2 sec with 0% overlap): {window_label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the subject column\n",
    "window_data = window_data[:, :, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "window_data = window_data.astype(np.float32)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "window_data_tensor = torch.from_numpy(window_data)\n",
    "window_label_tensor = torch.from_numpy(window_label)\n",
    "#convert labels to long\n",
    "window_label_tensor = window_label_tensor.long()\n",
    "\n",
    "# split data into train and test sets\n",
    "train_size = int(train_rate * len(window_data_tensor))\n",
    "test_size = len(window_data_tensor) - train_size\n",
    "\n",
    "# Creating datasets\n",
    "dataset = TensorDataset(window_data_tensor, window_label_tensor)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Function to extract tensors from Subset\n",
    "def extract_subset_data(subset, dataset):\n",
    "    return dataset.tensors[0][subset.indices], dataset.tensors[1][subset.indices]\n",
    "\n",
    "# Extract data and labels from train and test sets\n",
    "train_data, train_labels = extract_subset_data(train_dataset, dataset)\n",
    "test_data, test_labels = extract_subset_data(test_dataset, dataset)\n",
    "\n",
    "# create train and test TensorDataset\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "# create DataLoader for train and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train_loader: 3\n",
      "shape of test_loader: 24\n"
     ]
    }
   ],
   "source": [
    "#  print the shape of train_loader and test_loader\n",
    "print(f\"shape of train_loader: {len(train_loader)}\")\n",
    "print(f\"shape of test_loader: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256 * 12, 128)  # Adjust the input features according to your final conv layer output\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, padding):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                               stride=stride, padding=0, dilation=dilation)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
    "                               stride=stride, padding=0, dilation=dilation)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "\n",
    "        # Adjusting the length of the residual to match the output\n",
    "        if out.size(2) != res.size(2):\n",
    "            desired_length = out.size(2)\n",
    "            res = res[:, :, :desired_length]\n",
    "\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size, dropout=0.2, num_classes=4):\n",
    "        super(TCN, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size + (dilation_size - 1))]\n",
    "\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(num_channels[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tcn(x)\n",
    "        x = F.avg_pool1d(x, x.size(2)).squeeze(2)  # Global Average Pooling\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training function\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.transpose(1, 2)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testing function\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    #calculate accuracy\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs = inputs.transpose(1, 2)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            #calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return running_loss / len(test_loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to train and test model\n",
    "def train_and_test(model, train_loader, test_loader, criterion, optimizer, device, num_epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "        test_loss, test_accuracy = test(model, test_loader, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        print(f\"Epoch: {epoch + 1}/{num_epochs}.. Train Loss: {train_loss:.3f}.. Test Loss: {test_loss:.3f}.. Test Accuracy: {test_accuracy:.3f}\")\n",
    "    return train_losses, test_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 8\n"
     ]
    }
   ],
   "source": [
    "# get number of classes\n",
    "num_classes = len(np.unique(window_label))\n",
    "print(f\"number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50.. Train Loss: 1.893.. Test Loss: 1.551.. Test Accuracy: 0.366\n",
      "Epoch: 2/50.. Train Loss: 1.402.. Test Loss: 1.148.. Test Accuracy: 0.593\n",
      "Epoch: 3/50.. Train Loss: 1.104.. Test Loss: 0.945.. Test Accuracy: 0.634\n",
      "Epoch: 4/50.. Train Loss: 0.932.. Test Loss: 0.858.. Test Accuracy: 0.642\n",
      "Epoch: 5/50.. Train Loss: 0.867.. Test Loss: 0.802.. Test Accuracy: 0.708\n",
      "Epoch: 6/50.. Train Loss: 0.747.. Test Loss: 0.739.. Test Accuracy: 0.746\n",
      "Epoch: 7/50.. Train Loss: 0.704.. Test Loss: 0.689.. Test Accuracy: 0.768\n",
      "Epoch: 8/50.. Train Loss: 0.638.. Test Loss: 0.717.. Test Accuracy: 0.738\n",
      "Epoch: 9/50.. Train Loss: 0.658.. Test Loss: 0.672.. Test Accuracy: 0.742\n",
      "Epoch: 10/50.. Train Loss: 0.590.. Test Loss: 0.662.. Test Accuracy: 0.775\n",
      "Epoch: 11/50.. Train Loss: 0.594.. Test Loss: 0.644.. Test Accuracy: 0.787\n",
      "Epoch: 12/50.. Train Loss: 0.544.. Test Loss: 0.603.. Test Accuracy: 0.810\n",
      "Epoch: 13/50.. Train Loss: 0.502.. Test Loss: 0.622.. Test Accuracy: 0.786\n",
      "Epoch: 14/50.. Train Loss: 0.492.. Test Loss: 0.610.. Test Accuracy: 0.799\n",
      "Epoch: 15/50.. Train Loss: 0.432.. Test Loss: 0.595.. Test Accuracy: 0.813\n",
      "Epoch: 16/50.. Train Loss: 0.416.. Test Loss: 0.592.. Test Accuracy: 0.803\n",
      "Epoch: 17/50.. Train Loss: 0.389.. Test Loss: 0.600.. Test Accuracy: 0.816\n",
      "Epoch: 18/50.. Train Loss: 0.385.. Test Loss: 0.544.. Test Accuracy: 0.841\n",
      "Epoch: 19/50.. Train Loss: 0.360.. Test Loss: 0.534.. Test Accuracy: 0.842\n",
      "Epoch: 20/50.. Train Loss: 0.322.. Test Loss: 0.572.. Test Accuracy: 0.826\n",
      "Epoch: 21/50.. Train Loss: 0.292.. Test Loss: 0.578.. Test Accuracy: 0.832\n",
      "Epoch: 22/50.. Train Loss: 0.298.. Test Loss: 0.550.. Test Accuracy: 0.837\n",
      "Epoch: 23/50.. Train Loss: 0.288.. Test Loss: 0.542.. Test Accuracy: 0.848\n",
      "Epoch: 24/50.. Train Loss: 0.261.. Test Loss: 0.565.. Test Accuracy: 0.844\n",
      "Epoch: 25/50.. Train Loss: 0.248.. Test Loss: 0.560.. Test Accuracy: 0.845\n",
      "Epoch: 26/50.. Train Loss: 0.228.. Test Loss: 0.537.. Test Accuracy: 0.853\n",
      "Epoch: 27/50.. Train Loss: 0.243.. Test Loss: 0.548.. Test Accuracy: 0.843\n",
      "Epoch: 28/50.. Train Loss: 0.224.. Test Loss: 0.544.. Test Accuracy: 0.849\n",
      "Epoch: 29/50.. Train Loss: 0.204.. Test Loss: 0.562.. Test Accuracy: 0.842\n",
      "Epoch: 30/50.. Train Loss: 0.197.. Test Loss: 0.559.. Test Accuracy: 0.848\n",
      "Epoch: 31/50.. Train Loss: 0.181.. Test Loss: 0.581.. Test Accuracy: 0.837\n",
      "Epoch: 32/50.. Train Loss: 0.174.. Test Loss: 0.587.. Test Accuracy: 0.852\n",
      "Epoch: 33/50.. Train Loss: 0.166.. Test Loss: 0.630.. Test Accuracy: 0.824\n",
      "Epoch: 34/50.. Train Loss: 0.162.. Test Loss: 0.568.. Test Accuracy: 0.852\n",
      "Epoch: 35/50.. Train Loss: 0.147.. Test Loss: 0.619.. Test Accuracy: 0.836\n",
      "Epoch: 36/50.. Train Loss: 0.147.. Test Loss: 0.600.. Test Accuracy: 0.841\n",
      "Epoch: 37/50.. Train Loss: 0.132.. Test Loss: 0.674.. Test Accuracy: 0.828\n",
      "Epoch: 38/50.. Train Loss: 0.126.. Test Loss: 0.601.. Test Accuracy: 0.845\n",
      "Epoch: 39/50.. Train Loss: 0.117.. Test Loss: 0.615.. Test Accuracy: 0.848\n",
      "Epoch: 40/50.. Train Loss: 0.121.. Test Loss: 0.606.. Test Accuracy: 0.848\n",
      "Epoch: 41/50.. Train Loss: 0.113.. Test Loss: 0.625.. Test Accuracy: 0.850\n",
      "Epoch: 42/50.. Train Loss: 0.105.. Test Loss: 0.627.. Test Accuracy: 0.848\n",
      "Epoch: 43/50.. Train Loss: 0.091.. Test Loss: 0.635.. Test Accuracy: 0.851\n",
      "Epoch: 44/50.. Train Loss: 0.096.. Test Loss: 0.638.. Test Accuracy: 0.852\n",
      "Epoch: 45/50.. Train Loss: 0.084.. Test Loss: 0.627.. Test Accuracy: 0.856\n",
      "Epoch: 46/50.. Train Loss: 0.104.. Test Loss: 0.653.. Test Accuracy: 0.845\n",
      "Epoch: 47/50.. Train Loss: 0.095.. Test Loss: 0.659.. Test Accuracy: 0.849\n",
      "Epoch: 48/50.. Train Loss: 0.097.. Test Loss: 0.654.. Test Accuracy: 0.848\n",
      "Epoch: 49/50.. Train Loss: 0.078.. Test Loss: 0.652.. Test Accuracy: 0.853\n",
      "Epoch: 50/50.. Train Loss: 0.086.. Test Loss: 0.684.. Test Accuracy: 0.849\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 50\n",
    "train_losses, test_losses, test_accuracies = train_and_test(model, train_loader, test_loader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50.. Train Loss: 2.325.. Test Loss: 2.162.. Test Accuracy: 0.231\n",
      "Epoch: 2/50.. Train Loss: 2.123.. Test Loss: 2.080.. Test Accuracy: 0.163\n",
      "Epoch: 3/50.. Train Loss: 2.059.. Test Loss: 2.036.. Test Accuracy: 0.160\n",
      "Epoch: 4/50.. Train Loss: 2.036.. Test Loss: 2.006.. Test Accuracy: 0.161\n",
      "Epoch: 5/50.. Train Loss: 2.005.. Test Loss: 1.999.. Test Accuracy: 0.158\n",
      "Epoch: 6/50.. Train Loss: 1.992.. Test Loss: 1.993.. Test Accuracy: 0.145\n",
      "Epoch: 7/50.. Train Loss: 1.985.. Test Loss: 1.974.. Test Accuracy: 0.141\n",
      "Epoch: 8/50.. Train Loss: 1.958.. Test Loss: 1.956.. Test Accuracy: 0.149\n",
      "Epoch: 9/50.. Train Loss: 1.939.. Test Loss: 1.944.. Test Accuracy: 0.171\n",
      "Epoch: 10/50.. Train Loss: 1.928.. Test Loss: 1.935.. Test Accuracy: 0.156\n",
      "Epoch: 11/50.. Train Loss: 1.920.. Test Loss: 1.922.. Test Accuracy: 0.155\n",
      "Epoch: 12/50.. Train Loss: 1.906.. Test Loss: 1.909.. Test Accuracy: 0.155\n",
      "Epoch: 13/50.. Train Loss: 1.890.. Test Loss: 1.897.. Test Accuracy: 0.157\n",
      "Epoch: 14/50.. Train Loss: 1.876.. Test Loss: 1.887.. Test Accuracy: 0.163\n",
      "Epoch: 15/50.. Train Loss: 1.866.. Test Loss: 1.879.. Test Accuracy: 0.173\n",
      "Epoch: 16/50.. Train Loss: 1.860.. Test Loss: 1.869.. Test Accuracy: 0.166\n",
      "Epoch: 17/50.. Train Loss: 1.852.. Test Loss: 1.857.. Test Accuracy: 0.273\n",
      "Epoch: 18/50.. Train Loss: 1.849.. Test Loss: 1.847.. Test Accuracy: 0.330\n",
      "Epoch: 19/50.. Train Loss: 1.829.. Test Loss: 1.841.. Test Accuracy: 0.341\n",
      "Epoch: 20/50.. Train Loss: 1.822.. Test Loss: 1.837.. Test Accuracy: 0.315\n",
      "Epoch: 21/50.. Train Loss: 1.806.. Test Loss: 1.828.. Test Accuracy: 0.291\n",
      "Epoch: 22/50.. Train Loss: 1.812.. Test Loss: 1.816.. Test Accuracy: 0.341\n",
      "Epoch: 23/50.. Train Loss: 1.794.. Test Loss: 1.805.. Test Accuracy: 0.342\n",
      "Epoch: 24/50.. Train Loss: 1.782.. Test Loss: 1.797.. Test Accuracy: 0.352\n",
      "Epoch: 25/50.. Train Loss: 1.768.. Test Loss: 1.790.. Test Accuracy: 0.348\n",
      "Epoch: 26/50.. Train Loss: 1.766.. Test Loss: 1.783.. Test Accuracy: 0.349\n",
      "Epoch: 27/50.. Train Loss: 1.764.. Test Loss: 1.775.. Test Accuracy: 0.355\n",
      "Epoch: 28/50.. Train Loss: 1.745.. Test Loss: 1.769.. Test Accuracy: 0.347\n",
      "Epoch: 29/50.. Train Loss: 1.741.. Test Loss: 1.762.. Test Accuracy: 0.348\n",
      "Epoch: 30/50.. Train Loss: 1.739.. Test Loss: 1.755.. Test Accuracy: 0.370\n",
      "Epoch: 31/50.. Train Loss: 1.721.. Test Loss: 1.746.. Test Accuracy: 0.386\n",
      "Epoch: 32/50.. Train Loss: 1.713.. Test Loss: 1.737.. Test Accuracy: 0.383\n",
      "Epoch: 33/50.. Train Loss: 1.710.. Test Loss: 1.729.. Test Accuracy: 0.353\n",
      "Epoch: 34/50.. Train Loss: 1.690.. Test Loss: 1.725.. Test Accuracy: 0.354\n",
      "Epoch: 35/50.. Train Loss: 1.689.. Test Loss: 1.720.. Test Accuracy: 0.369\n",
      "Epoch: 36/50.. Train Loss: 1.680.. Test Loss: 1.712.. Test Accuracy: 0.420\n",
      "Epoch: 37/50.. Train Loss: 1.669.. Test Loss: 1.702.. Test Accuracy: 0.441\n",
      "Epoch: 38/50.. Train Loss: 1.665.. Test Loss: 1.695.. Test Accuracy: 0.437\n",
      "Epoch: 39/50.. Train Loss: 1.658.. Test Loss: 1.689.. Test Accuracy: 0.425\n",
      "Epoch: 40/50.. Train Loss: 1.661.. Test Loss: 1.684.. Test Accuracy: 0.373\n",
      "Epoch: 41/50.. Train Loss: 1.652.. Test Loss: 1.678.. Test Accuracy: 0.354\n",
      "Epoch: 42/50.. Train Loss: 1.636.. Test Loss: 1.672.. Test Accuracy: 0.364\n",
      "Epoch: 43/50.. Train Loss: 1.625.. Test Loss: 1.665.. Test Accuracy: 0.395\n",
      "Epoch: 44/50.. Train Loss: 1.626.. Test Loss: 1.657.. Test Accuracy: 0.422\n",
      "Epoch: 45/50.. Train Loss: 1.617.. Test Loss: 1.652.. Test Accuracy: 0.477\n",
      "Epoch: 46/50.. Train Loss: 1.611.. Test Loss: 1.646.. Test Accuracy: 0.495\n",
      "Epoch: 47/50.. Train Loss: 1.604.. Test Loss: 1.640.. Test Accuracy: 0.502\n",
      "Epoch: 48/50.. Train Loss: 1.589.. Test Loss: 1.635.. Test Accuracy: 0.444\n",
      "Epoch: 49/50.. Train Loss: 1.593.. Test Loss: 1.627.. Test Accuracy: 0.417\n",
      "Epoch: 50/50.. Train Loss: 1.583.. Test Loss: 1.622.. Test Accuracy: 0.404\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load('./models/cnn_feature_extractor_join_20231218-2006.pt'))\n",
    "\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc2.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 50\n",
    "train_losses, test_losses, test_accuracies = train_and_test(model, train_loader, test_loader, criterion, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50.. Train Loss: 4.375.. Test Loss: 2.660.. Test Accuracy: 0.119\n",
      "Epoch: 2/50.. Train Loss: 2.368.. Test Loss: 2.211.. Test Accuracy: 0.186\n",
      "Epoch: 3/50.. Train Loss: 2.142.. Test Loss: 1.963.. Test Accuracy: 0.256\n",
      "Epoch: 4/50.. Train Loss: 1.884.. Test Loss: 1.791.. Test Accuracy: 0.341\n",
      "Epoch: 5/50.. Train Loss: 1.750.. Test Loss: 1.685.. Test Accuracy: 0.289\n",
      "Epoch: 6/50.. Train Loss: 1.654.. Test Loss: 1.583.. Test Accuracy: 0.323\n",
      "Epoch: 7/50.. Train Loss: 1.524.. Test Loss: 1.452.. Test Accuracy: 0.334\n",
      "Epoch: 8/50.. Train Loss: 1.389.. Test Loss: 1.333.. Test Accuracy: 0.421\n",
      "Epoch: 9/50.. Train Loss: 1.300.. Test Loss: 1.216.. Test Accuracy: 0.566\n",
      "Epoch: 10/50.. Train Loss: 1.183.. Test Loss: 1.102.. Test Accuracy: 0.615\n",
      "Epoch: 11/50.. Train Loss: 1.088.. Test Loss: 1.018.. Test Accuracy: 0.704\n",
      "Epoch: 12/50.. Train Loss: 1.024.. Test Loss: 0.938.. Test Accuracy: 0.681\n",
      "Epoch: 13/50.. Train Loss: 0.970.. Test Loss: 0.889.. Test Accuracy: 0.720\n",
      "Epoch: 14/50.. Train Loss: 0.890.. Test Loss: 0.858.. Test Accuracy: 0.713\n",
      "Epoch: 15/50.. Train Loss: 0.870.. Test Loss: 0.799.. Test Accuracy: 0.760\n",
      "Epoch: 16/50.. Train Loss: 0.805.. Test Loss: 0.779.. Test Accuracy: 0.758\n",
      "Epoch: 17/50.. Train Loss: 0.759.. Test Loss: 0.741.. Test Accuracy: 0.775\n",
      "Epoch: 18/50.. Train Loss: 0.739.. Test Loss: 0.710.. Test Accuracy: 0.797\n",
      "Epoch: 19/50.. Train Loss: 0.697.. Test Loss: 0.696.. Test Accuracy: 0.792\n",
      "Epoch: 20/50.. Train Loss: 0.667.. Test Loss: 0.685.. Test Accuracy: 0.781\n",
      "Epoch: 21/50.. Train Loss: 0.647.. Test Loss: 0.667.. Test Accuracy: 0.790\n",
      "Epoch: 22/50.. Train Loss: 0.640.. Test Loss: 0.658.. Test Accuracy: 0.810\n",
      "Epoch: 23/50.. Train Loss: 0.630.. Test Loss: 0.642.. Test Accuracy: 0.804\n",
      "Epoch: 24/50.. Train Loss: 0.606.. Test Loss: 0.643.. Test Accuracy: 0.813\n",
      "Epoch: 25/50.. Train Loss: 0.598.. Test Loss: 0.634.. Test Accuracy: 0.809\n",
      "Epoch: 26/50.. Train Loss: 0.586.. Test Loss: 0.620.. Test Accuracy: 0.808\n",
      "Epoch: 27/50.. Train Loss: 0.570.. Test Loss: 0.610.. Test Accuracy: 0.808\n",
      "Epoch: 28/50.. Train Loss: 0.544.. Test Loss: 0.594.. Test Accuracy: 0.819\n",
      "Epoch: 29/50.. Train Loss: 0.535.. Test Loss: 0.586.. Test Accuracy: 0.828\n",
      "Epoch: 30/50.. Train Loss: 0.531.. Test Loss: 0.589.. Test Accuracy: 0.822\n",
      "Epoch: 31/50.. Train Loss: 0.507.. Test Loss: 0.579.. Test Accuracy: 0.827\n",
      "Epoch: 32/50.. Train Loss: 0.508.. Test Loss: 0.570.. Test Accuracy: 0.837\n",
      "Epoch: 33/50.. Train Loss: 0.495.. Test Loss: 0.563.. Test Accuracy: 0.838\n",
      "Epoch: 34/50.. Train Loss: 0.516.. Test Loss: 0.559.. Test Accuracy: 0.842\n",
      "Epoch: 35/50.. Train Loss: 0.489.. Test Loss: 0.558.. Test Accuracy: 0.827\n",
      "Epoch: 36/50.. Train Loss: 0.474.. Test Loss: 0.561.. Test Accuracy: 0.830\n",
      "Epoch: 37/50.. Train Loss: 0.466.. Test Loss: 0.557.. Test Accuracy: 0.834\n",
      "Epoch: 38/50.. Train Loss: 0.457.. Test Loss: 0.537.. Test Accuracy: 0.840\n",
      "Epoch: 39/50.. Train Loss: 0.455.. Test Loss: 0.548.. Test Accuracy: 0.832\n",
      "Epoch: 40/50.. Train Loss: 0.437.. Test Loss: 0.537.. Test Accuracy: 0.845\n",
      "Epoch: 41/50.. Train Loss: 0.434.. Test Loss: 0.534.. Test Accuracy: 0.855\n",
      "Epoch: 42/50.. Train Loss: 0.427.. Test Loss: 0.541.. Test Accuracy: 0.830\n",
      "Epoch: 43/50.. Train Loss: 0.430.. Test Loss: 0.516.. Test Accuracy: 0.849\n",
      "Epoch: 44/50.. Train Loss: 0.424.. Test Loss: 0.524.. Test Accuracy: 0.857\n",
      "Epoch: 45/50.. Train Loss: 0.406.. Test Loss: 0.528.. Test Accuracy: 0.844\n",
      "Epoch: 46/50.. Train Loss: 0.404.. Test Loss: 0.519.. Test Accuracy: 0.841\n",
      "Epoch: 47/50.. Train Loss: 0.393.. Test Loss: 0.507.. Test Accuracy: 0.855\n",
      "Epoch: 48/50.. Train Loss: 0.379.. Test Loss: 0.524.. Test Accuracy: 0.856\n",
      "Epoch: 49/50.. Train Loss: 0.388.. Test Loss: 0.510.. Test Accuracy: 0.848\n",
      "Epoch: 50/50.. Train Loss: 0.390.. Test Loss: 0.498.. Test Accuracy: 0.855\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load('./models/cnn_feature_extractor_join_20231218-2006.pt'))\n",
    "\n",
    "# Freezing layers up to conv3\n",
    "for name, param in model.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        break\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layers from conv3 onwards\n",
    "unfreeze = False\n",
    "for name, param in model.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        unfreeze = True\n",
    "    if unfreeze:\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Update the final classification layer\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer (only update the parameters that require gradients)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "# Train and test the model\n",
    "num_epochs = 50\n",
    "train_losses, test_losses, test_accuracies = train_and_test(model, train_loader, test_loader, criterion, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50.. Train Loss: 1.917.. Test Loss: 1.502.. Test Accuracy: 0.432\n",
      "Epoch: 2/50.. Train Loss: 1.372.. Test Loss: 1.401.. Test Accuracy: 0.506\n",
      "Epoch: 3/50.. Train Loss: 1.215.. Test Loss: 1.114.. Test Accuracy: 0.534\n",
      "Epoch: 4/50.. Train Loss: 1.073.. Test Loss: 0.985.. Test Accuracy: 0.593\n",
      "Epoch: 5/50.. Train Loss: 0.981.. Test Loss: 0.916.. Test Accuracy: 0.588\n",
      "Epoch: 6/50.. Train Loss: 0.884.. Test Loss: 0.845.. Test Accuracy: 0.664\n",
      "Epoch: 7/50.. Train Loss: 0.809.. Test Loss: 0.826.. Test Accuracy: 0.682\n",
      "Epoch: 8/50.. Train Loss: 0.795.. Test Loss: 0.746.. Test Accuracy: 0.730\n",
      "Epoch: 9/50.. Train Loss: 0.699.. Test Loss: 0.699.. Test Accuracy: 0.745\n",
      "Epoch: 10/50.. Train Loss: 0.657.. Test Loss: 0.638.. Test Accuracy: 0.792\n",
      "Epoch: 11/50.. Train Loss: 0.572.. Test Loss: 0.646.. Test Accuracy: 0.774\n",
      "Epoch: 12/50.. Train Loss: 0.627.. Test Loss: 0.627.. Test Accuracy: 0.787\n",
      "Epoch: 13/50.. Train Loss: 0.649.. Test Loss: 0.649.. Test Accuracy: 0.781\n",
      "Epoch: 14/50.. Train Loss: 0.592.. Test Loss: 0.661.. Test Accuracy: 0.811\n",
      "Epoch: 15/50.. Train Loss: 0.568.. Test Loss: 0.610.. Test Accuracy: 0.812\n",
      "Epoch: 16/50.. Train Loss: 0.516.. Test Loss: 0.583.. Test Accuracy: 0.788\n",
      "Epoch: 17/50.. Train Loss: 0.468.. Test Loss: 0.560.. Test Accuracy: 0.830\n",
      "Epoch: 18/50.. Train Loss: 0.426.. Test Loss: 0.531.. Test Accuracy: 0.839\n",
      "Epoch: 19/50.. Train Loss: 0.419.. Test Loss: 0.521.. Test Accuracy: 0.847\n",
      "Epoch: 20/50.. Train Loss: 0.380.. Test Loss: 0.506.. Test Accuracy: 0.852\n",
      "Epoch: 21/50.. Train Loss: 0.386.. Test Loss: 0.514.. Test Accuracy: 0.852\n",
      "Epoch: 22/50.. Train Loss: 0.360.. Test Loss: 0.501.. Test Accuracy: 0.850\n",
      "Epoch: 23/50.. Train Loss: 0.329.. Test Loss: 0.497.. Test Accuracy: 0.853\n",
      "Epoch: 24/50.. Train Loss: 0.338.. Test Loss: 0.498.. Test Accuracy: 0.856\n",
      "Epoch: 25/50.. Train Loss: 0.326.. Test Loss: 0.515.. Test Accuracy: 0.843\n",
      "Epoch: 26/50.. Train Loss: 0.320.. Test Loss: 0.486.. Test Accuracy: 0.861\n",
      "Epoch: 27/50.. Train Loss: 0.302.. Test Loss: 0.512.. Test Accuracy: 0.856\n",
      "Epoch: 28/50.. Train Loss: 0.325.. Test Loss: 0.515.. Test Accuracy: 0.846\n",
      "Epoch: 29/50.. Train Loss: 0.348.. Test Loss: 0.496.. Test Accuracy: 0.855\n",
      "Epoch: 30/50.. Train Loss: 0.306.. Test Loss: 0.517.. Test Accuracy: 0.842\n",
      "Epoch: 31/50.. Train Loss: 0.311.. Test Loss: 0.503.. Test Accuracy: 0.861\n",
      "Epoch: 32/50.. Train Loss: 0.256.. Test Loss: 0.517.. Test Accuracy: 0.857\n",
      "Epoch: 33/50.. Train Loss: 0.237.. Test Loss: 0.536.. Test Accuracy: 0.854\n",
      "Epoch: 34/50.. Train Loss: 0.253.. Test Loss: 0.526.. Test Accuracy: 0.864\n",
      "Epoch: 35/50.. Train Loss: 0.231.. Test Loss: 0.503.. Test Accuracy: 0.867\n",
      "Epoch: 36/50.. Train Loss: 0.207.. Test Loss: 0.515.. Test Accuracy: 0.865\n",
      "Epoch: 37/50.. Train Loss: 0.185.. Test Loss: 0.543.. Test Accuracy: 0.866\n",
      "Epoch: 38/50.. Train Loss: 0.173.. Test Loss: 0.572.. Test Accuracy: 0.854\n",
      "Epoch: 39/50.. Train Loss: 0.178.. Test Loss: 0.571.. Test Accuracy: 0.863\n",
      "Epoch: 40/50.. Train Loss: 0.178.. Test Loss: 0.527.. Test Accuracy: 0.871\n",
      "Epoch: 41/50.. Train Loss: 0.176.. Test Loss: 0.549.. Test Accuracy: 0.858\n",
      "Epoch: 42/50.. Train Loss: 0.149.. Test Loss: 0.512.. Test Accuracy: 0.867\n",
      "Epoch: 43/50.. Train Loss: 0.152.. Test Loss: 0.639.. Test Accuracy: 0.856\n",
      "Epoch: 44/50.. Train Loss: 0.212.. Test Loss: 0.550.. Test Accuracy: 0.864\n",
      "Epoch: 45/50.. Train Loss: 0.173.. Test Loss: 0.552.. Test Accuracy: 0.849\n",
      "Epoch: 46/50.. Train Loss: 0.151.. Test Loss: 0.528.. Test Accuracy: 0.863\n",
      "Epoch: 47/50.. Train Loss: 0.201.. Test Loss: 0.567.. Test Accuracy: 0.855\n",
      "Epoch: 48/50.. Train Loss: 0.189.. Test Loss: 0.617.. Test Accuracy: 0.842\n",
      "Epoch: 49/50.. Train Loss: 0.214.. Test Loss: 0.589.. Test Accuracy: 0.835\n",
      "Epoch: 50/50.. Train Loss: 0.169.. Test Loss: 0.507.. Test Accuracy: 0.862\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 3  # Assuming 3 input channels (x, y, z axes of the accelerometer)\n",
    "num_channels = [64, 128, 256]  # Example channel sizes for each layer\n",
    "kernel_size = 8  # Kernel size for temporal convolutions\n",
    "\n",
    "model = TCN(num_inputs, num_channels, kernel_size, num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 50\n",
    "train_losses, test_losses, test_accuracies = train_and_test(model, train_loader, test_loader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50.. Train Loss: 3.609.. Test Loss: 2.837.. Test Accuracy: 0.131\n",
      "Epoch: 2/50.. Train Loss: 2.922.. Test Loss: 2.305.. Test Accuracy: 0.261\n",
      "Epoch: 3/50.. Train Loss: 2.537.. Test Loss: 1.965.. Test Accuracy: 0.256\n",
      "Epoch: 4/50.. Train Loss: 2.267.. Test Loss: 1.938.. Test Accuracy: 0.142\n",
      "Epoch: 5/50.. Train Loss: 2.291.. Test Loss: 1.935.. Test Accuracy: 0.139\n",
      "Epoch: 6/50.. Train Loss: 2.183.. Test Loss: 1.779.. Test Accuracy: 0.216\n",
      "Epoch: 7/50.. Train Loss: 2.034.. Test Loss: 1.647.. Test Accuracy: 0.418\n",
      "Epoch: 8/50.. Train Loss: 1.947.. Test Loss: 1.596.. Test Accuracy: 0.463\n",
      "Epoch: 9/50.. Train Loss: 1.823.. Test Loss: 1.567.. Test Accuracy: 0.468\n",
      "Epoch: 10/50.. Train Loss: 1.801.. Test Loss: 1.525.. Test Accuracy: 0.438\n",
      "Epoch: 11/50.. Train Loss: 1.721.. Test Loss: 1.466.. Test Accuracy: 0.474\n",
      "Epoch: 12/50.. Train Loss: 1.728.. Test Loss: 1.408.. Test Accuracy: 0.573\n",
      "Epoch: 13/50.. Train Loss: 1.618.. Test Loss: 1.370.. Test Accuracy: 0.577\n",
      "Epoch: 14/50.. Train Loss: 1.577.. Test Loss: 1.338.. Test Accuracy: 0.571\n",
      "Epoch: 15/50.. Train Loss: 1.567.. Test Loss: 1.303.. Test Accuracy: 0.632\n",
      "Epoch: 16/50.. Train Loss: 1.501.. Test Loss: 1.275.. Test Accuracy: 0.640\n",
      "Epoch: 17/50.. Train Loss: 1.423.. Test Loss: 1.250.. Test Accuracy: 0.655\n",
      "Epoch: 18/50.. Train Loss: 1.426.. Test Loss: 1.226.. Test Accuracy: 0.661\n",
      "Epoch: 19/50.. Train Loss: 1.378.. Test Loss: 1.205.. Test Accuracy: 0.663\n",
      "Epoch: 20/50.. Train Loss: 1.403.. Test Loss: 1.182.. Test Accuracy: 0.680\n",
      "Epoch: 21/50.. Train Loss: 1.315.. Test Loss: 1.161.. Test Accuracy: 0.743\n",
      "Epoch: 22/50.. Train Loss: 1.301.. Test Loss: 1.140.. Test Accuracy: 0.761\n",
      "Epoch: 23/50.. Train Loss: 1.255.. Test Loss: 1.122.. Test Accuracy: 0.717\n",
      "Epoch: 24/50.. Train Loss: 1.236.. Test Loss: 1.104.. Test Accuracy: 0.720\n",
      "Epoch: 25/50.. Train Loss: 1.217.. Test Loss: 1.087.. Test Accuracy: 0.772\n",
      "Epoch: 26/50.. Train Loss: 1.205.. Test Loss: 1.072.. Test Accuracy: 0.778\n",
      "Epoch: 27/50.. Train Loss: 1.206.. Test Loss: 1.060.. Test Accuracy: 0.773\n",
      "Epoch: 28/50.. Train Loss: 1.158.. Test Loss: 1.048.. Test Accuracy: 0.771\n",
      "Epoch: 29/50.. Train Loss: 1.148.. Test Loss: 1.037.. Test Accuracy: 0.757\n",
      "Epoch: 30/50.. Train Loss: 1.131.. Test Loss: 1.025.. Test Accuracy: 0.750\n",
      "Epoch: 31/50.. Train Loss: 1.092.. Test Loss: 1.005.. Test Accuracy: 0.787\n",
      "Epoch: 32/50.. Train Loss: 1.105.. Test Loss: 0.993.. Test Accuracy: 0.784\n",
      "Epoch: 33/50.. Train Loss: 1.088.. Test Loss: 0.982.. Test Accuracy: 0.786\n",
      "Epoch: 34/50.. Train Loss: 1.051.. Test Loss: 0.974.. Test Accuracy: 0.786\n",
      "Epoch: 35/50.. Train Loss: 1.044.. Test Loss: 0.963.. Test Accuracy: 0.785\n",
      "Epoch: 36/50.. Train Loss: 1.045.. Test Loss: 0.952.. Test Accuracy: 0.790\n",
      "Epoch: 37/50.. Train Loss: 1.041.. Test Loss: 0.945.. Test Accuracy: 0.784\n",
      "Epoch: 38/50.. Train Loss: 1.038.. Test Loss: 0.937.. Test Accuracy: 0.786\n",
      "Epoch: 39/50.. Train Loss: 1.004.. Test Loss: 0.928.. Test Accuracy: 0.784\n",
      "Epoch: 40/50.. Train Loss: 1.002.. Test Loss: 0.919.. Test Accuracy: 0.776\n",
      "Epoch: 41/50.. Train Loss: 0.956.. Test Loss: 0.909.. Test Accuracy: 0.790\n",
      "Epoch: 42/50.. Train Loss: 0.995.. Test Loss: 0.898.. Test Accuracy: 0.790\n",
      "Epoch: 43/50.. Train Loss: 0.978.. Test Loss: 0.894.. Test Accuracy: 0.790\n",
      "Epoch: 44/50.. Train Loss: 0.969.. Test Loss: 0.887.. Test Accuracy: 0.794\n",
      "Epoch: 45/50.. Train Loss: 0.934.. Test Loss: 0.878.. Test Accuracy: 0.787\n",
      "Epoch: 46/50.. Train Loss: 0.935.. Test Loss: 0.874.. Test Accuracy: 0.776\n",
      "Epoch: 47/50.. Train Loss: 0.913.. Test Loss: 0.866.. Test Accuracy: 0.792\n",
      "Epoch: 48/50.. Train Loss: 0.905.. Test Loss: 0.857.. Test Accuracy: 0.799\n",
      "Epoch: 49/50.. Train Loss: 0.894.. Test Loss: 0.849.. Test Accuracy: 0.803\n",
      "Epoch: 50/50.. Train Loss: 0.881.. Test Loss: 0.844.. Test Accuracy: 0.803\n"
     ]
    }
   ],
   "source": [
    "model = TCN(num_inputs, num_channels, kernel_size, num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load('./models/tcn_join_20231218-2014.pt'))\n",
    "\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 50\n",
    "train_losses, test_losses, test_accuracies = train_and_test(model, train_loader, test_loader, criterion, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCN(\n",
      "  (tcn): Sequential(\n",
      "    (0): TemporalBlock(\n",
      "      (conv1): Conv1d(3, 64, kernel_size=(8,), stride=(1,))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(8,), stride=(1,))\n",
      "      (relu2): ReLU()\n",
      "      (downsample): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): TemporalBlock(\n",
      "      (conv1): Conv1d(64, 128, kernel_size=(8,), stride=(1,), dilation=(2,))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(8,), stride=(1,), dilation=(2,))\n",
      "      (relu2): ReLU()\n",
      "      (downsample): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): TemporalBlock(\n",
      "      (conv1): Conv1d(128, 256, kernel_size=(8,), stride=(1,), dilation=(4,))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(8,), stride=(1,), dilation=(4,))\n",
      "      (relu2): ReLU()\n",
      "      (downsample): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50.. Train Loss: 3.955.. Test Loss: 3.689.. Test Accuracy: 0.340\n",
      "Epoch: 2/50.. Train Loss: 3.339.. Test Loss: 1.509.. Test Accuracy: 0.515\n",
      "Epoch: 3/50.. Train Loss: 2.094.. Test Loss: 1.782.. Test Accuracy: 0.257\n",
      "Epoch: 4/50.. Train Loss: 1.668.. Test Loss: 1.238.. Test Accuracy: 0.621\n",
      "Epoch: 5/50.. Train Loss: 1.347.. Test Loss: 1.258.. Test Accuracy: 0.480\n",
      "Epoch: 6/50.. Train Loss: 1.239.. Test Loss: 1.061.. Test Accuracy: 0.693\n",
      "Epoch: 7/50.. Train Loss: 1.098.. Test Loss: 1.004.. Test Accuracy: 0.671\n",
      "Epoch: 8/50.. Train Loss: 1.030.. Test Loss: 0.902.. Test Accuracy: 0.758\n",
      "Epoch: 9/50.. Train Loss: 0.915.. Test Loss: 0.861.. Test Accuracy: 0.719\n",
      "Epoch: 10/50.. Train Loss: 0.863.. Test Loss: 0.804.. Test Accuracy: 0.769\n",
      "Epoch: 11/50.. Train Loss: 0.830.. Test Loss: 0.764.. Test Accuracy: 0.776\n",
      "Epoch: 12/50.. Train Loss: 0.793.. Test Loss: 0.741.. Test Accuracy: 0.784\n",
      "Epoch: 13/50.. Train Loss: 0.741.. Test Loss: 0.701.. Test Accuracy: 0.778\n",
      "Epoch: 14/50.. Train Loss: 0.729.. Test Loss: 0.687.. Test Accuracy: 0.798\n",
      "Epoch: 15/50.. Train Loss: 0.702.. Test Loss: 0.670.. Test Accuracy: 0.789\n",
      "Epoch: 16/50.. Train Loss: 0.682.. Test Loss: 0.646.. Test Accuracy: 0.801\n",
      "Epoch: 17/50.. Train Loss: 0.658.. Test Loss: 0.640.. Test Accuracy: 0.801\n",
      "Epoch: 18/50.. Train Loss: 0.626.. Test Loss: 0.622.. Test Accuracy: 0.808\n",
      "Epoch: 19/50.. Train Loss: 0.642.. Test Loss: 0.609.. Test Accuracy: 0.806\n",
      "Epoch: 20/50.. Train Loss: 0.615.. Test Loss: 0.610.. Test Accuracy: 0.801\n",
      "Epoch: 21/50.. Train Loss: 0.588.. Test Loss: 0.592.. Test Accuracy: 0.811\n",
      "Epoch: 22/50.. Train Loss: 0.590.. Test Loss: 0.582.. Test Accuracy: 0.813\n",
      "Epoch: 23/50.. Train Loss: 0.563.. Test Loss: 0.580.. Test Accuracy: 0.817\n",
      "Epoch: 24/50.. Train Loss: 0.584.. Test Loss: 0.570.. Test Accuracy: 0.816\n",
      "Epoch: 25/50.. Train Loss: 0.555.. Test Loss: 0.565.. Test Accuracy: 0.815\n",
      "Epoch: 26/50.. Train Loss: 0.544.. Test Loss: 0.555.. Test Accuracy: 0.819\n",
      "Epoch: 27/50.. Train Loss: 0.521.. Test Loss: 0.558.. Test Accuracy: 0.822\n",
      "Epoch: 28/50.. Train Loss: 0.508.. Test Loss: 0.552.. Test Accuracy: 0.821\n",
      "Epoch: 29/50.. Train Loss: 0.504.. Test Loss: 0.541.. Test Accuracy: 0.822\n",
      "Epoch: 30/50.. Train Loss: 0.509.. Test Loss: 0.536.. Test Accuracy: 0.826\n",
      "Epoch: 31/50.. Train Loss: 0.504.. Test Loss: 0.534.. Test Accuracy: 0.824\n",
      "Epoch: 32/50.. Train Loss: 0.514.. Test Loss: 0.531.. Test Accuracy: 0.824\n",
      "Epoch: 33/50.. Train Loss: 0.501.. Test Loss: 0.529.. Test Accuracy: 0.829\n",
      "Epoch: 34/50.. Train Loss: 0.505.. Test Loss: 0.532.. Test Accuracy: 0.823\n",
      "Epoch: 35/50.. Train Loss: 0.479.. Test Loss: 0.527.. Test Accuracy: 0.828\n",
      "Epoch: 36/50.. Train Loss: 0.480.. Test Loss: 0.517.. Test Accuracy: 0.829\n",
      "Epoch: 37/50.. Train Loss: 0.479.. Test Loss: 0.524.. Test Accuracy: 0.827\n",
      "Epoch: 38/50.. Train Loss: 0.447.. Test Loss: 0.535.. Test Accuracy: 0.816\n",
      "Epoch: 39/50.. Train Loss: 0.461.. Test Loss: 0.515.. Test Accuracy: 0.829\n",
      "Epoch: 40/50.. Train Loss: 0.471.. Test Loss: 0.519.. Test Accuracy: 0.823\n",
      "Epoch: 41/50.. Train Loss: 0.439.. Test Loss: 0.523.. Test Accuracy: 0.828\n",
      "Epoch: 42/50.. Train Loss: 0.458.. Test Loss: 0.514.. Test Accuracy: 0.825\n",
      "Epoch: 43/50.. Train Loss: 0.450.. Test Loss: 0.517.. Test Accuracy: 0.819\n",
      "Epoch: 44/50.. Train Loss: 0.446.. Test Loss: 0.506.. Test Accuracy: 0.832\n",
      "Epoch: 45/50.. Train Loss: 0.445.. Test Loss: 0.502.. Test Accuracy: 0.828\n",
      "Epoch: 46/50.. Train Loss: 0.400.. Test Loss: 0.497.. Test Accuracy: 0.832\n",
      "Epoch: 47/50.. Train Loss: 0.401.. Test Loss: 0.496.. Test Accuracy: 0.834\n",
      "Epoch: 48/50.. Train Loss: 0.422.. Test Loss: 0.500.. Test Accuracy: 0.830\n",
      "Epoch: 49/50.. Train Loss: 0.431.. Test Loss: 0.506.. Test Accuracy: 0.834\n",
      "Epoch: 50/50.. Train Loss: 0.402.. Test Loss: 0.502.. Test Accuracy: 0.835\n"
     ]
    }
   ],
   "source": [
    "model = TCN(num_inputs, num_channels, kernel_size, num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load('./models/tcn_join_20231218-2014.pt'))\n",
    "\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
    "\n",
    "# Freezing all layers initially\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layers from the last TemporalBlock's conv2 onwards\n",
    "num_levels = len(model.tcn)  # Number of TemporalBlocks in your TCN\n",
    "for i, block in enumerate(model.tcn):\n",
    "    if i == num_levels - 1:  # Check if it's the last TemporalBlock\n",
    "        # Unfreeze the conv2 layer and any subsequent layers within this block\n",
    "        unfreeze = False\n",
    "        for name, param in block.named_parameters():\n",
    "            if 'conv2' in name:\n",
    "                unfreeze = True\n",
    "            if unfreeze:\n",
    "                param.requires_grad = True\n",
    "\n",
    "# Unfreeze the classification layer\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 50\n",
    "train_losses, test_losses, test_accuracies = train_and_test(model, train_loader, test_loader, criterion, optimizer, device, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
