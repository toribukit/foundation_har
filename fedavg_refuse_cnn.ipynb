{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import copy\n",
    "from scipy.interpolate import CubicSpline\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy.stats import mode\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import datetime\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 32  # Set your batch size\n",
    "learning_rate_client = 0.001\n",
    "local_epochs = 1\n",
    "subject_dir = 'FL_Data/windowed_data_refused/subject_'  # Set your directory to the subject data\n",
    "numclients = 54\n",
    "num_classes = 9\n",
    "\n",
    "#current timestamp\n",
    "current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "torch.manual_seed(420)\n",
    "np.random.seed(420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_client(id, batch_size=batch_size, type='labelled_train'):\n",
    "    # Load the data\n",
    "    data = np.load(subject_dir + str(id) + '/windowed_' + type + '_x.npy')\n",
    "    labels = np.load(subject_dir + str(id) + '/windowed_' + type + '_y.npy')\n",
    "\n",
    "    # print shape of data\n",
    "    # print(data.shape)\n",
    "    # print(labels.shape)\n",
    "\n",
    "    # Convert to torch tensor\n",
    "    data = torch.from_numpy(data).float()\n",
    "    labels = torch.from_numpy(labels).long()\n",
    "\n",
    "    # Create a dataset\n",
    "    dataset = torch.utils.data.TensorDataset(data, labels)\n",
    "\n",
    "    # Create a dataloader\n",
    "    if type == 'labelled_train' or type == 'unlabelled_train':\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    else:\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(54):\n",
    "#     data_label_train = load_data_client(i, batch_size, 'labelled_train')\n",
    "#     data_unlabel_train = load_data_client(i, batch_size, 'unlabelled_train')\n",
    "#     data_test = load_data_client(i, batch_size, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256 * 12, 128)  # Adjust the input features according to your final conv layer output\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_autoencoder(model, train_loader, device, learning_rate=0.01, epochs=5):\n",
    "#     model.to(device)\n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for epoch in range(epochs):\n",
    "#         for data, target in train_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             # print(data.shape)\n",
    "#             data = data.permute(0, 2, 1)\n",
    "#             optimizer.zero_grad()\n",
    "#             output = model(data)\n",
    "#             # print(output.shape)\n",
    "#             loss = criterion(output, data)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()\n",
    "        \n",
    "#         epoch_loss = total_loss / len(train_loader)\n",
    "#         # print(f'Epoch {epoch+1}, Loss: {epoch_loss}')\n",
    "#         total_loss = 0  # Reset total loss for the next epoch\n",
    "\n",
    "#     results = {\n",
    "#         'train_loss': epoch_loss\n",
    "#     }\n",
    "    \n",
    "#     return results  # Returns the average loss of the last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_autoencoder(model, test_loader, device):\n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "    \n",
    "#     criterion = nn.MSELoss()\n",
    "#     total_loss = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for data, target in test_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             data = data.permute(0, 2, 1)\n",
    "#             output = model(data)\n",
    "#             loss = criterion(output, data)\n",
    "#             total_loss += loss.item()\n",
    "    \n",
    "#     avg_loss = total_loss / len(test_loader)\n",
    "#     # print(f'Test Loss: {avg_loss}')\n",
    "    \n",
    "#     return avg_loss  # Returns the average loss for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train_model(model, train_loader, device, learning_rate=0.001, epochs=1):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.permute(0, 2, 1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = total_loss / len(train_loader)\n",
    "        total_loss = 0  # Reset total loss for the next epoch\n",
    "\n",
    "    results = {\n",
    "        'train_loss': epoch_loss\n",
    "    }\n",
    "    \n",
    "    return results  # Returns the average loss of the last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test the model\n",
    "# method to test the model and get the accuracy and f1 score\n",
    "def test_model(model, test_loader):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.permute(0, 2, 1)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    # print(f'Accuracy: {accuracy}, F1 Score: {f1}')\n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client():\n",
    "  def __init__(self, client_config:dict):\n",
    "    # client config as dict to make configuration dynamic\n",
    "    self.id = client_config[\"id\"]\n",
    "    self.config = client_config\n",
    "    self.__model = None\n",
    "\n",
    "    self.labelled_loader = self.config[\"labelled\"]\n",
    "    self.unlabelled_loader = self.config[\"unlabelled\"]\n",
    "    self.test_loader = self.config[\"test\"]\n",
    "\n",
    "  @property\n",
    "  def model(self):\n",
    "    return self.__model\n",
    "\n",
    "  @model.setter\n",
    "  def model(self, model):\n",
    "    self.__model = model\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"Return a total size of the client's local data.\"\"\"\n",
    "    return len(self.unlabelled_loader.sampler)\n",
    "\n",
    "  def train_ssl(self):\n",
    "    results = train_model(model = self.model,\n",
    "                    train_loader = self.unlabelled_loader,\n",
    "                    device=device,\n",
    "                    learning_rate=learning_rate_client,\n",
    "                    epochs=local_epochs)\n",
    "    print(f\"Train result client {self.id}: {results}\")\n",
    "\n",
    "  def test_ssl(self):\n",
    "    loss = test_model(model = self.model,\n",
    "                    test_loader = self.unlabelled_loader)\n",
    "    print(f\"Test result client {self.id}: {loss}\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvg():\n",
    "  def __init__(self):\n",
    "    self.globalmodel = CNNFeatureExtractor(num_classes=4)\n",
    "    self.rounds = 0\n",
    "    self.params = {}\n",
    "\n",
    "  def aggregate(self, round):\n",
    "    #v1:update the aggregate to save the model with round and date indicator\n",
    "    modelparams = []\n",
    "    for i in self.params.keys():\n",
    "      modelparams.append(self.params[i])\n",
    "\n",
    "    avg_weights = {}\n",
    "    for name in modelparams[0].keys():\n",
    "      avg_weights[name] = torch.mean(torch.stack([w[name] for w in modelparams]), dim = 0)\n",
    "\n",
    "    self.globalmodel.load_state_dict(avg_weights)\n",
    "\n",
    "    #save the model\n",
    "    name_path = f'Refused_FL/Model_Global/{current_time}'\n",
    "    if not os.path.exists(name_path):\n",
    "      os.makedirs(name_path)\n",
    "\n",
    "    torch.save(self.globalmodel.state_dict(), f\"{name_path}/global_model_round_{round}.pth\")\n",
    "    \n",
    "    # filename = f\"{path_glob_m}/global_model_round_{round}_{current_time}.pth\"\n",
    "    # torch.save(self.globalmodel.state_dict(), filename)\n",
    "\n",
    "  def clientstrain(self, clientconfig):\n",
    "    clients = clientconfig\n",
    "    for i in clients.keys():\n",
    "      test_client = Client(clients[i])\n",
    "      test_client.model = copy.deepcopy(self.globalmodel)\n",
    "      test_client.train_ssl()\n",
    "      test_client.test_ssl()\n",
    "      self.params[i] = test_client.model.state_dict()\n",
    "\n",
    "  def initiate_FL(self, clientconfig, serverdata):\n",
    "    clients = clientconfig\n",
    "    print(\"Round: {}\".format(self.rounds))\n",
    "\n",
    "    print(\"Obtaining Weights!!\")\n",
    "    self.clientstrain(clients)\n",
    "\n",
    "    #### Aggregate model\n",
    "    print(\"Aggregating Model!!\")\n",
    "    self.aggregate(self.rounds)\n",
    "\n",
    "    #### Replace parameters with global model parameters\n",
    "    for i in self.params.keys():\n",
    "        self.params[i] = self.globalmodel.state_dict()\n",
    "\n",
    "\n",
    "    servertest = serverdata\n",
    "    result = test_model(model = self.globalmodel,\n",
    "                    test_loader = servertest)\n",
    "    print(\"Round {} metrics:\".format(self.rounds))\n",
    "    print(\"Server Result = {}\".format(result))\n",
    "    print(\"Round {} finished!\".format(self.rounds))\n",
    "    self.rounds += 1\n",
    "    return clients, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client: 0\n",
      "labelled: 12\n",
      "unlabelled: 45\n",
      "test: 14\n",
      "client: 1\n",
      "labelled: 11\n",
      "unlabelled: 43\n",
      "test: 14\n",
      "client: 2\n",
      "labelled: 12\n",
      "unlabelled: 45\n",
      "test: 15\n",
      "client: 3\n",
      "labelled: 10\n",
      "unlabelled: 41\n",
      "test: 13\n",
      "client: 4\n",
      "labelled: 13\n",
      "unlabelled: 51\n",
      "test: 16\n",
      "client: 5\n",
      "labelled: 12\n",
      "unlabelled: 49\n",
      "test: 16\n",
      "client: 6\n",
      "labelled: 3\n",
      "unlabelled: 12\n",
      "test: 4\n",
      "client: 7\n",
      "labelled: 4\n",
      "unlabelled: 13\n",
      "test: 4\n",
      "client: 8\n",
      "labelled: 2\n",
      "unlabelled: 8\n",
      "test: 3\n",
      "client: 9\n",
      "labelled: 11\n",
      "unlabelled: 43\n",
      "test: 14\n",
      "client: 10\n",
      "labelled: 9\n",
      "unlabelled: 34\n",
      "test: 11\n",
      "client: 11\n",
      "labelled: 12\n",
      "unlabelled: 46\n",
      "test: 15\n",
      "client: 12\n",
      "labelled: 11\n",
      "unlabelled: 42\n",
      "test: 13\n",
      "client: 13\n",
      "labelled: 13\n",
      "unlabelled: 50\n",
      "test: 16\n",
      "client: 14\n",
      "labelled: 11\n",
      "unlabelled: 44\n",
      "test: 14\n",
      "client: 15\n",
      "labelled: 10\n",
      "unlabelled: 38\n",
      "test: 12\n",
      "client: 16\n",
      "labelled: 13\n",
      "unlabelled: 49\n",
      "test: 16\n",
      "client: 17\n",
      "labelled: 12\n",
      "unlabelled: 45\n",
      "test: 14\n",
      "client: 18\n",
      "labelled: 11\n",
      "unlabelled: 43\n",
      "test: 14\n",
      "client: 19\n",
      "labelled: 11\n",
      "unlabelled: 45\n",
      "test: 14\n",
      "client: 20\n",
      "labelled: 11\n",
      "unlabelled: 43\n",
      "test: 14\n",
      "client: 21\n",
      "labelled: 11\n",
      "unlabelled: 44\n",
      "test: 14\n",
      "client: 22\n",
      "labelled: 9\n",
      "unlabelled: 36\n",
      "test: 12\n",
      "client: 23\n",
      "labelled: 12\n",
      "unlabelled: 45\n",
      "test: 14\n",
      "client: 24\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 25\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 26\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 27\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 28\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 29\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 30\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 31\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 32\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 33\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 34\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 35\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 36\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 37\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 38\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 39\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 40\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 41\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 42\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 43\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 44\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 45\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 46\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 47\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 48\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 49\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 50\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 51\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "client: 52\n",
      "labelled: 2\n",
      "unlabelled: 5\n",
      "test: 2\n",
      "client: 53\n",
      "labelled: 2\n",
      "unlabelled: 6\n",
      "test: 2\n",
      "combined test: 341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined unlabelled: 1092\n"
     ]
    }
   ],
   "source": [
    "clients = {}\n",
    "\n",
    "for i in range(numclients):\n",
    "    clients[i] = {\"id\": i, \"batch_size\": batch_size, \"local_epoch\": 1}\n",
    "    clients[i]['labelled'] = load_data_client(i, batch_size, 'labelled_train')\n",
    "    clients[i]['unlabelled'] = load_data_client(i, batch_size, 'unlabelled_train')\n",
    "    clients[i]['test'] = load_data_client(i, batch_size, 'test')\n",
    "\n",
    "    print(f\"client: {i}\")\n",
    "    print(f\"labelled: {len(clients[i]['labelled'])}\")\n",
    "    print(f\"unlabelled: {len(clients[i]['unlabelled'])}\")\n",
    "    print(f\"test: {len(clients[i]['test'])}\")\n",
    "\n",
    "# combine all client test data into one\n",
    "combined_test_data = []\n",
    "combined_test_labels = []\n",
    "for i in range(numclients):\n",
    "    for data, labels in clients[i]['test']:\n",
    "        combined_test_data.append(data)\n",
    "        combined_test_labels.append(labels)\n",
    "combined_test_data = torch.cat(combined_test_data, dim=0)\n",
    "combined_test_labels = torch.cat(combined_test_labels, dim=0)\n",
    "# create dataset and dataloader\n",
    "combined_test_dataset = torch.utils.data.TensorDataset(combined_test_data, combined_test_labels)\n",
    "combined_test_dataloader = torch.utils.data.DataLoader(combined_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"combined test: {len(combined_test_dataloader)}\")\n",
    "\n",
    "# combine all client unlabelled data into one\n",
    "combined_unlabelled_data = []\n",
    "combined_unlabelled_labels = []\n",
    "for i in range(numclients):\n",
    "    for data, labels in clients[i]['unlabelled']:\n",
    "        combined_unlabelled_data.append(data)\n",
    "        combined_unlabelled_labels.append(labels)\n",
    "combined_unlabelled_data = torch.cat(combined_unlabelled_data, dim=0)\n",
    "combined_unlabelled_labels = torch.cat(combined_unlabelled_labels, dim=0)\n",
    "# create dataset and dataloader\n",
    "combined_unlabelled_dataset = torch.utils.data.TensorDataset(combined_unlabelled_data, combined_unlabelled_labels)\n",
    "combined_unlabelled_dataloader = torch.utils.data.DataLoader(combined_unlabelled_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"combined unlabelled: {len(combined_unlabelled_dataloader)}\")\n",
    "\n",
    "# # server test_data\n",
    "# server_test_data = combined_unlabelled_dataloader\n",
    "\n",
    "# server = FedAvg()\n",
    "\n",
    "# loss_rounds = []\n",
    "# for i in range(num_epochs):\n",
    "#     clients, loss = server.initiate_FL(clientconfig=clients, serverdata=server_test_data)\n",
    "#     loss_rounds.append(loss)\n",
    "\n",
    "# print(\"\\n\")\n",
    "# print(\"-\" * 50)\n",
    "# print(\"Loss values all rounds: \", loss_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuned Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256 * 12, 128)  # Adjust the input features according to your final conv layer output\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fine-Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined labelled: 273\n"
     ]
    }
   ],
   "source": [
    "# combine all client labelled data into one\n",
    "combined_labelled_data = []\n",
    "combined_labelled_labels = []\n",
    "for i in range(numclients):\n",
    "    for data, labels in clients[i]['labelled']:\n",
    "        combined_labelled_data.append(data)\n",
    "        combined_labelled_labels.append(labels)\n",
    "combined_labelled_data = torch.cat(combined_labelled_data, dim=0)\n",
    "combined_labelled_labels = torch.cat(combined_labelled_labels, dim=0)\n",
    "# create dataset and dataloader\n",
    "combined_labelled_dataset = torch.utils.data.TensorDataset(combined_labelled_data, combined_labelled_labels)\n",
    "combined_labelled_dataloader = torch.utils.data.DataLoader(combined_labelled_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"combined labelled: {len(combined_labelled_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each class\n",
    "class_counts = torch.zeros(num_classes)  # num_classes should be defined based on your dataset\n",
    "for _, target in combined_labelled_dataloader:\n",
    "    class_counts += torch.bincount(target, minlength=num_classes)\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts += 1  # Add 1 to each class count to avoid division by zero\n",
    "c_weight = 1. / class_counts\n",
    "c_weight = c_weight / c_weight.sum() * num_classes\n",
    "c_weight = c_weight.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0120e+03, 1.2410e+03, 1.3840e+03, 1.5050e+03, 8.8300e+02, 3.7800e+02,\n",
       "        1.0000e+00, 9.6700e+02, 1.3440e+03])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.8163e-03, 7.1894e-03, 6.4466e-03, 5.9283e-03, 1.0104e-02, 2.3603e-02,\n",
       "        8.9220e+00, 9.2265e-03, 6.6384e-03], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNFeatureExtractor(\n",
       "  (conv1): Conv1d(3, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=3072, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_path = 'Refused_FL/Model_Global/2024-02-11_22-01-36/global_model_round_199.pth' # model with 200 epochs, 1 local epoch\n",
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# # Freezing layers up to conv3\n",
    "# for name, param in model.named_parameters():\n",
    "#     if 'conv3' in name:\n",
    "#         break\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Unfreeze layers from conv3 onwards\n",
    "# unfreeze = False\n",
    "# for name, param in model.named_parameters():\n",
    "#     if 'conv3' in name:\n",
    "#         unfreeze = True\n",
    "#     if unfreeze:\n",
    "#         param.requires_grad = True\n",
    "\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CNNFeatureExtractor(num_classes=num_classes)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to test the model and get the accuracy and f1 score\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.permute(0, 2, 1)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f'Accuracy: {accuracy}, F1 Score: {f1}')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(model, train_loader, test_loader, num_epochs=200):\n",
    "    # Assuming class weights are calculated and provided as `class_weights`\n",
    "    class_weights = torch.tensor(c_weight).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # optimizer = torch.optim.Adam(model.fc2.parameters(), lr=0.001)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.permute(0, 2, 1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        acc, f1 = test_model(model, test_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, Accuracy: {acc}, F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IME-LAB\\AppData\\Local\\Temp\\ipykernel_4124\\3333203605.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  class_weights = torch.tensor(c_weight).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.375241068968684, F1 Score: 0.3285550801352946\n",
      "Epoch 1/100, Loss: 1.232351541519165, Accuracy: 0.375241068968684, F1 Score: 0.3285550801352946\n",
      "Accuracy: 0.3411699880613463, F1 Score: 0.30695778529494155\n",
      "Epoch 2/100, Loss: 2.0371618270874023, Accuracy: 0.3411699880613463, F1 Score: 0.30695778529494155\n",
      "Accuracy: 0.38295527596657175, F1 Score: 0.3715367828428432\n",
      "Epoch 3/100, Loss: 1.389163851737976, Accuracy: 0.38295527596657175, F1 Score: 0.3715367828428432\n",
      "Accuracy: 0.4003122417118193, F1 Score: 0.38016076471174737\n",
      "Epoch 4/100, Loss: 1.8372427225112915, Accuracy: 0.4003122417118193, F1 Score: 0.38016076471174737\n",
      "Accuracy: 0.40205712186610343, F1 Score: 0.37992687078319687\n",
      "Epoch 5/100, Loss: 0.8084015846252441, Accuracy: 0.40205712186610343, F1 Score: 0.37992687078319687\n",
      "Accuracy: 0.3876389016438608, F1 Score: 0.37539525988540845\n",
      "Epoch 6/100, Loss: 0.9647284150123596, Accuracy: 0.3876389016438608, F1 Score: 0.37539525988540845\n",
      "Accuracy: 0.3709247864817706, F1 Score: 0.3649852601415648\n",
      "Epoch 7/100, Loss: 0.814739465713501, Accuracy: 0.3709247864817706, F1 Score: 0.3649852601415648\n",
      "Accuracy: 0.3637615942694462, F1 Score: 0.35869824930637134\n",
      "Epoch 8/100, Loss: 0.860996425151825, Accuracy: 0.3637615942694462, F1 Score: 0.35869824930637134\n",
      "Accuracy: 0.34640462852419873, F1 Score: 0.3471891883855997\n",
      "Epoch 9/100, Loss: 0.9932377934455872, Accuracy: 0.34640462852419873, F1 Score: 0.3471891883855997\n",
      "Accuracy: 0.37432271099274494, F1 Score: 0.3549246495394079\n",
      "Epoch 10/100, Loss: 0.1937003880739212, Accuracy: 0.37432271099274494, F1 Score: 0.3549246495394079\n",
      "Accuracy: 0.35209844797502066, F1 Score: 0.3513762463267443\n",
      "Epoch 11/100, Loss: 0.14324533939361572, Accuracy: 0.35209844797502066, F1 Score: 0.3513762463267443\n",
      "Accuracy: 0.34300670401322436, F1 Score: 0.3387476997269595\n",
      "Epoch 12/100, Loss: 0.8283683061599731, Accuracy: 0.34300670401322436, F1 Score: 0.3387476997269595\n",
      "Accuracy: 0.33887409312149874, F1 Score: 0.3355487145815801\n",
      "Epoch 13/100, Loss: 0.8823863863945007, Accuracy: 0.33887409312149874, F1 Score: 0.3355487145815801\n",
      "Accuracy: 0.35687390944990355, F1 Score: 0.3532300289364599\n",
      "Epoch 14/100, Loss: 1.4305101103673223e-06, Accuracy: 0.35687390944990355, F1 Score: 0.3532300289364599\n",
      "Accuracy: 0.34805767288088896, F1 Score: 0.3399391238487519\n",
      "Epoch 15/100, Loss: 0.014196031726896763, Accuracy: 0.34805767288088896, F1 Score: 0.3399391238487519\n",
      "Accuracy: 0.3589861327945633, F1 Score: 0.3497638979881154\n",
      "Epoch 16/100, Loss: 0.0003221785300411284, Accuracy: 0.3589861327945633, F1 Score: 0.3497638979881154\n",
      "Accuracy: 0.3353843328129305, F1 Score: 0.3358836687140367\n",
      "Epoch 17/100, Loss: 0.12061417102813721, Accuracy: 0.3353843328129305, F1 Score: 0.3358836687140367\n",
      "Accuracy: 0.3494352098447975, F1 Score: 0.3402439346945252\n",
      "Epoch 18/100, Loss: 0.23789441585540771, Accuracy: 0.3494352098447975, F1 Score: 0.3402439346945252\n",
      "Accuracy: 0.3481495086784829, F1 Score: 0.34614354063089514\n",
      "Epoch 19/100, Loss: 0.003364262171089649, Accuracy: 0.3481495086784829, F1 Score: 0.34614354063089514\n",
      "Accuracy: 0.3538433281293048, F1 Score: 0.3524036170856574\n",
      "Epoch 20/100, Loss: 0.0035897530615329742, Accuracy: 0.3538433281293048, F1 Score: 0.3524036170856574\n",
      "Accuracy: 0.35026173202314265, F1 Score: 0.3472241729792151\n",
      "Epoch 21/100, Loss: 0.0001363568298984319, Accuracy: 0.35026173202314265, F1 Score: 0.3472241729792151\n",
      "Accuracy: 0.35099641840389384, F1 Score: 0.3461671417531859\n",
      "Epoch 22/100, Loss: 0.15497194230556488, Accuracy: 0.35099641840389384, F1 Score: 0.3461671417531859\n",
      "Accuracy: 0.34456791257232067, F1 Score: 0.34278095570672945\n",
      "Epoch 23/100, Loss: 0.07281501591205597, Accuracy: 0.34456791257232067, F1 Score: 0.34278095570672945\n",
      "Accuracy: 0.34374139039397555, F1 Score: 0.3394966107829493\n",
      "Epoch 24/100, Loss: 0.00046303283306770027, Accuracy: 0.34374139039397555, F1 Score: 0.3394966107829493\n",
      "Accuracy: 0.3463127927266048, F1 Score: 0.3482207346338668\n",
      "Epoch 25/100, Loss: 0.0, Accuracy: 0.3463127927266048, F1 Score: 0.3482207346338668\n",
      "Accuracy: 0.34190467444209754, F1 Score: 0.3322532623785137\n",
      "Epoch 26/100, Loss: 6.55650637781946e-07, Accuracy: 0.34190467444209754, F1 Score: 0.3322532623785137\n",
      "Accuracy: 0.34208834603728533, F1 Score: 0.33654667333689725\n",
      "Epoch 27/100, Loss: 0.026248963549733162, Accuracy: 0.34208834603728533, F1 Score: 0.33654667333689725\n",
      "Accuracy: 0.3361190191936817, F1 Score: 0.3311105370765482\n",
      "Epoch 28/100, Loss: 0.0007056473987177014, Accuracy: 0.3361190191936817, F1 Score: 0.3311105370765482\n",
      "Accuracy: 0.34429240517953896, F1 Score: 0.3427109080087183\n",
      "Epoch 29/100, Loss: 0.4168112277984619, Accuracy: 0.34429240517953896, F1 Score: 0.3427109080087183\n",
      "Accuracy: 0.3463127927266048, F1 Score: 0.34207729944723037\n",
      "Epoch 30/100, Loss: 0.0001383828348480165, Accuracy: 0.3463127927266048, F1 Score: 0.34207729944723037\n",
      "Accuracy: 0.34805767288088896, F1 Score: 0.3457027679866282\n",
      "Epoch 31/100, Loss: 0.00041022402001544833, Accuracy: 0.34805767288088896, F1 Score: 0.3457027679866282\n",
      "Accuracy: 0.34612912113141703, F1 Score: 0.343520179368311\n",
      "Epoch 32/100, Loss: 0.0005422138492576778, Accuracy: 0.34612912113141703, F1 Score: 0.343520179368311\n",
      "Accuracy: 0.33997612269262556, F1 Score: 0.3370372738513525\n",
      "Epoch 33/100, Loss: 0.00013534884783439338, Accuracy: 0.33997612269262556, F1 Score: 0.3370372738513525\n",
      "Accuracy: 0.32454770869685, F1 Score: 0.3240297293377897\n",
      "Epoch 34/100, Loss: 8.463787708024029e-06, Accuracy: 0.32454770869685, F1 Score: 0.3240297293377897\n",
      "Accuracy: 0.34273119662044266, F1 Score: 0.33646719443146506\n",
      "Epoch 35/100, Loss: 0.0012681431835517287, Accuracy: 0.34273119662044266, F1 Score: 0.33646719443146506\n",
      "Accuracy: 0.3360271833960878, F1 Score: 0.3364422339009558\n",
      "Epoch 36/100, Loss: 0.00027708575362339616, Accuracy: 0.3360271833960878, F1 Score: 0.3364422339009558\n",
      "Accuracy: 0.3309762145284232, F1 Score: 0.33212942489031194\n",
      "Epoch 37/100, Loss: 5.483598670252832e-06, Accuracy: 0.3309762145284232, F1 Score: 0.33212942489031194\n",
      "Accuracy: 0.3494352098447975, F1 Score: 0.34025333111643413\n",
      "Epoch 38/100, Loss: 0.040588364005088806, Accuracy: 0.3494352098447975, F1 Score: 0.34025333111643413\n",
      "Accuracy: 0.33510882542014875, F1 Score: 0.33043075396232136\n",
      "Epoch 39/100, Loss: 2.2768545022699982e-05, Accuracy: 0.33510882542014875, F1 Score: 0.33043075396232136\n",
      "Accuracy: 0.3487005234640463, F1 Score: 0.3364950671972145\n",
      "Epoch 40/100, Loss: 0.0, Accuracy: 0.3487005234640463, F1 Score: 0.3364950671972145\n",
      "Accuracy: 0.34300670401322436, F1 Score: 0.3363147627100791\n",
      "Epoch 41/100, Loss: 2.0861582470388385e-06, Accuracy: 0.34300670401322436, F1 Score: 0.3363147627100791\n",
      "Accuracy: 0.34677197171457436, F1 Score: 0.339488356402822\n",
      "Epoch 42/100, Loss: 0.0, Accuracy: 0.34677197171457436, F1 Score: 0.339488356402822\n",
      "Accuracy: 0.3468638075121682, F1 Score: 0.34432007541220516\n",
      "Epoch 43/100, Loss: 0.039887893944978714, Accuracy: 0.3468638075121682, F1 Score: 0.34432007541220516\n",
      "Accuracy: 0.3506290752135182, F1 Score: 0.3483193682064035\n",
      "Epoch 44/100, Loss: 0.0002633831463754177, Accuracy: 0.3506290752135182, F1 Score: 0.3483193682064035\n",
      "Accuracy: 0.3482413444760768, F1 Score: 0.34437710870662525\n",
      "Epoch 45/100, Loss: 2.2410844394471496e-05, Accuracy: 0.3482413444760768, F1 Score: 0.34437710870662525\n",
      "Accuracy: 0.3307007071356415, F1 Score: 0.3251554335989957\n",
      "Epoch 46/100, Loss: 0.01254815049469471, Accuracy: 0.3307007071356415, F1 Score: 0.3251554335989957\n",
      "Accuracy: 0.3453025989530719, F1 Score: 0.33701886334299\n",
      "Epoch 47/100, Loss: 0.0019310330972075462, Accuracy: 0.3453025989530719, F1 Score: 0.33701886334299\n",
      "Accuracy: 0.3425475250252548, F1 Score: 0.333789950638801\n",
      "Epoch 48/100, Loss: 0.005634649656713009, Accuracy: 0.3425475250252548, F1 Score: 0.333789950638801\n",
      "Accuracy: 0.3325374230875195, F1 Score: 0.33138111203787773\n",
      "Epoch 49/100, Loss: 1.3232065612100996e-05, Accuracy: 0.3325374230875195, F1 Score: 0.33138111203787773\n",
      "Accuracy: 0.35264946276058406, F1 Score: 0.350684742725584\n",
      "Epoch 50/100, Loss: 0.029153361916542053, Accuracy: 0.35264946276058406, F1 Score: 0.350684742725584\n",
      "Accuracy: 0.33924143631187437, F1 Score: 0.33435807553488356\n",
      "Epoch 51/100, Loss: 1.8000278942054138e-05, Accuracy: 0.33924143631187437, F1 Score: 0.33435807553488356\n",
      "Accuracy: 0.3495270456423914, F1 Score: 0.34192656075195954\n",
      "Epoch 52/100, Loss: 9.715472515381407e-06, Accuracy: 0.3495270456423914, F1 Score: 0.34192656075195954\n",
      "Accuracy: 0.340527137478189, F1 Score: 0.3363226534118828\n",
      "Epoch 53/100, Loss: 4.642989006242715e-05, Accuracy: 0.340527137478189, F1 Score: 0.3363226534118828\n",
      "Accuracy: 0.35108825420148776, F1 Score: 0.33352607591301114\n",
      "Epoch 54/100, Loss: 0.000247357675107196, Accuracy: 0.35108825420148776, F1 Score: 0.33352607591301114\n",
      "Accuracy: 0.3397924510974378, F1 Score: 0.3336930500577918\n",
      "Epoch 55/100, Loss: 0.00010370132804382592, Accuracy: 0.3397924510974378, F1 Score: 0.3336930500577918\n",
      "Accuracy: 0.34677197171457436, F1 Score: 0.340520608866503\n",
      "Epoch 56/100, Loss: 0.05708012729883194, Accuracy: 0.34677197171457436, F1 Score: 0.340520608866503\n",
      "Accuracy: 0.34328221140600607, F1 Score: 0.33654226807283455\n",
      "Epoch 57/100, Loss: 0.00010948174895020202, Accuracy: 0.34328221140600607, F1 Score: 0.33654226807283455\n",
      "Accuracy: 0.34668013591698044, F1 Score: 0.3399054339327129\n",
      "Epoch 58/100, Loss: 8.344643447344424e-07, Accuracy: 0.34668013591698044, F1 Score: 0.3399054339327129\n",
      "Accuracy: 0.34539443475066584, F1 Score: 0.335322752160434\n",
      "Epoch 59/100, Loss: 5.9604641222676946e-08, Accuracy: 0.34539443475066584, F1 Score: 0.335322752160434\n",
      "Accuracy: 0.33676186977683903, F1 Score: 0.33246852340225463\n",
      "Epoch 60/100, Loss: 0.002643320942297578, Accuracy: 0.33676186977683903, F1 Score: 0.33246852340225463\n",
      "Accuracy: 0.3497107172375792, F1 Score: 0.34656544478165624\n",
      "Epoch 61/100, Loss: 1.6689273252268322e-06, Accuracy: 0.3497107172375792, F1 Score: 0.34656544478165624\n",
      "Accuracy: 0.3499862246303609, F1 Score: 0.3455074478626041\n",
      "Epoch 62/100, Loss: 6.854064122308046e-05, Accuracy: 0.3499862246303609, F1 Score: 0.3455074478626041\n",
      "Accuracy: 0.3374965561575902, F1 Score: 0.3351188957919381\n",
      "Epoch 63/100, Loss: 0.011839834973216057, Accuracy: 0.3374965561575902, F1 Score: 0.3351188957919381\n",
      "Accuracy: 0.3441087335843512, F1 Score: 0.33615352202169174\n",
      "Epoch 64/100, Loss: 4.172323428974778e-07, Accuracy: 0.3441087335843512, F1 Score: 0.33615352202169174\n",
      "Accuracy: 0.3425475250252548, F1 Score: 0.3347035103690919\n",
      "Epoch 65/100, Loss: 1.1920927533992653e-07, Accuracy: 0.3425475250252548, F1 Score: 0.3347035103690919\n",
      "Accuracy: 0.33795573514555977, F1 Score: 0.3345237050818878\n",
      "Epoch 66/100, Loss: 1.2778851985931396, Accuracy: 0.33795573514555977, F1 Score: 0.3345237050818878\n",
      "Accuracy: 0.3552208650932133, F1 Score: 0.34595837248251066\n",
      "Epoch 67/100, Loss: 8.165769941115286e-06, Accuracy: 0.3552208650932133, F1 Score: 0.34595837248251066\n",
      "Accuracy: 0.3453025989530719, F1 Score: 0.3363369226383644\n",
      "Epoch 68/100, Loss: 2.6822046947927447e-06, Accuracy: 0.3453025989530719, F1 Score: 0.3363369226383644\n",
      "Accuracy: 0.3562310588667463, F1 Score: 0.35067527937177556\n",
      "Epoch 69/100, Loss: 0.0001742565946187824, Accuracy: 0.3562310588667463, F1 Score: 0.35067527937177556\n",
      "Accuracy: 0.35136376159426946, F1 Score: 0.34549988545085436\n",
      "Epoch 70/100, Loss: 0.0, Accuracy: 0.35136376159426946, F1 Score: 0.34549988545085436\n",
      "Accuracy: 0.34640462852419873, F1 Score: 0.34545649928259065\n",
      "Epoch 71/100, Loss: 0.0, Accuracy: 0.34640462852419873, F1 Score: 0.34545649928259065\n",
      "Accuracy: 0.3460372853338231, F1 Score: 0.3442311196632948\n",
      "Epoch 72/100, Loss: 2.6822040126717184e-06, Accuracy: 0.3460372853338231, F1 Score: 0.3442311196632948\n",
      "Accuracy: 0.3465883001193865, F1 Score: 0.3428684275437167\n",
      "Epoch 73/100, Loss: 0.0014661491150036454, Accuracy: 0.3465883001193865, F1 Score: 0.3428684275437167\n",
      "Accuracy: 0.33823124253834147, F1 Score: 0.3350226652537605\n",
      "Epoch 74/100, Loss: 0.0, Accuracy: 0.33823124253834147, F1 Score: 0.3350226652537605\n",
      "Accuracy: 0.33520066121774267, F1 Score: 0.3329121707740209\n",
      "Epoch 75/100, Loss: 0.0, Accuracy: 0.33520066121774267, F1 Score: 0.3329121707740209\n",
      "Accuracy: 0.35136376159426946, F1 Score: 0.34637088757848755\n",
      "Epoch 76/100, Loss: 0.009753582999110222, Accuracy: 0.35136376159426946, F1 Score: 0.34637088757848755\n",
      "Accuracy: 0.34190467444209754, F1 Score: 0.33118897876546655\n",
      "Epoch 77/100, Loss: 0.00022072686988394707, Accuracy: 0.34190467444209754, F1 Score: 0.33118897876546655\n",
      "Accuracy: 0.3352924970153366, F1 Score: 0.3246567550068593\n",
      "Epoch 78/100, Loss: 0.0008820551447570324, Accuracy: 0.3352924970153366, F1 Score: 0.3246567550068593\n",
      "Accuracy: 0.3415373312517219, F1 Score: 0.3362800632304312\n",
      "Epoch 79/100, Loss: 0.00010191438195761293, Accuracy: 0.3415373312517219, F1 Score: 0.3362800632304312\n",
      "Accuracy: 0.33703737716962073, F1 Score: 0.32656249591553577\n",
      "Epoch 80/100, Loss: 0.0, Accuracy: 0.33703737716962073, F1 Score: 0.32656249591553577\n",
      "Accuracy: 0.34263936082284874, F1 Score: 0.34074338998035314\n",
      "Epoch 81/100, Loss: 1.0132780516869389e-06, Accuracy: 0.34263936082284874, F1 Score: 0.34074338998035314\n",
      "Accuracy: 0.3397924510974378, F1 Score: 0.3336862806536302\n",
      "Epoch 82/100, Loss: 0.0, Accuracy: 0.3397924510974378, F1 Score: 0.3336862806536302\n",
      "Accuracy: 0.3368537055744329, F1 Score: 0.3309071308569065\n",
      "Epoch 83/100, Loss: 0.0007732489029876888, Accuracy: 0.3368537055744329, F1 Score: 0.3309071308569065\n",
      "Accuracy: 0.35044540361833043, F1 Score: 0.33744823779760963\n",
      "Epoch 84/100, Loss: 0.0011095601366832852, Accuracy: 0.35044540361833043, F1 Score: 0.33744823779760963\n",
      "Accuracy: 0.34319037560841215, F1 Score: 0.3351610932744133\n",
      "Epoch 85/100, Loss: 4.887566319666803e-06, Accuracy: 0.34319037560841215, F1 Score: 0.3351610932744133\n",
      "Accuracy: 0.3447515841675085, F1 Score: 0.33960726574166583\n",
      "Epoch 86/100, Loss: 0.008533026091754436, Accuracy: 0.3447515841675085, F1 Score: 0.33960726574166583\n",
      "Accuracy: 0.34668013591698044, F1 Score: 0.3326315282210744\n",
      "Epoch 87/100, Loss: 0.0, Accuracy: 0.34668013591698044, F1 Score: 0.3326315282210744\n",
      "Accuracy: 0.340527137478189, F1 Score: 0.33009130837349004\n",
      "Epoch 88/100, Loss: 0.0, Accuracy: 0.340527137478189, F1 Score: 0.33009130837349004\n",
      "Accuracy: 0.3328129304803012, F1 Score: 0.33200756174820817\n",
      "Epoch 89/100, Loss: 1.7881390590446244e-07, Accuracy: 0.3328129304803012, F1 Score: 0.33200756174820817\n",
      "Accuracy: 0.34640462852419873, F1 Score: 0.342537133943966\n",
      "Epoch 90/100, Loss: 0.0, Accuracy: 0.34640462852419873, F1 Score: 0.342537133943966\n",
      "Accuracy: 0.34484341996510237, F1 Score: 0.3300999486946017\n",
      "Epoch 91/100, Loss: 0.0001028127153404057, Accuracy: 0.34484341996510237, F1 Score: 0.3300999486946017\n",
      "Accuracy: 0.3353843328129305, F1 Score: 0.3349768056347705\n",
      "Epoch 92/100, Loss: 3.695474333653692e-06, Accuracy: 0.3353843328129305, F1 Score: 0.3349768056347705\n",
      "Accuracy: 0.33005785655248415, F1 Score: 0.331427402419125\n",
      "Epoch 93/100, Loss: 0.0, Accuracy: 0.33005785655248415, F1 Score: 0.331427402419125\n",
      "Accuracy: 0.3224354853521903, F1 Score: 0.32132192271723525\n",
      "Epoch 94/100, Loss: 5.245181910140673e-06, Accuracy: 0.3224354853521903, F1 Score: 0.32132192271723525\n",
      "Accuracy: 0.3433740472036, F1 Score: 0.33477199569301086\n",
      "Epoch 95/100, Loss: 0.017146561294794083, Accuracy: 0.3433740472036, F1 Score: 0.33477199569301086\n",
      "Accuracy: 0.3310680503260171, F1 Score: 0.3223205169899487\n",
      "Epoch 96/100, Loss: 2.4496908736182377e-05, Accuracy: 0.3310680503260171, F1 Score: 0.3223205169899487\n",
      "Accuracy: 0.3499862246303609, F1 Score: 0.3449749851958945\n",
      "Epoch 97/100, Loss: 8.940688758229953e-07, Accuracy: 0.3499862246303609, F1 Score: 0.3449749851958945\n",
      "Accuracy: 0.3409863164661585, F1 Score: 0.33747487917101127\n",
      "Epoch 98/100, Loss: 1.4487524032592773, Accuracy: 0.3409863164661585, F1 Score: 0.33747487917101127\n",
      "Accuracy: 0.32032326200753053, F1 Score: 0.3171795639095878\n",
      "Epoch 99/100, Loss: 4.2675103031797335e-05, Accuracy: 0.32032326200753053, F1 Score: 0.3171795639095878\n",
      "Accuracy: 0.34456791257232067, F1 Score: 0.34241968738923095\n",
      "Epoch 100/100, Loss: 7.152552257139178e-07, Accuracy: 0.34456791257232067, F1 Score: 0.34241968738923095\n"
     ]
    }
   ],
   "source": [
    "fine_tune_model(model.to(device), combined_labelled_dataloader, combined_test_dataloader,num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34456791257232067, F1 Score: 0.34241968738923095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.34456791257232067, 0.34241968738923095)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, combined_test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
