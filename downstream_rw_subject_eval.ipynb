{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.interpolate import CubicSpline\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "np.random.seed(420)\n",
    "torch.manual_seed(420)\n",
    "torch.cuda.manual_seed(420)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.57434</td>\n",
       "      <td>-2.02733</td>\n",
       "      <td>1.34506</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.56479</td>\n",
       "      <td>-1.99597</td>\n",
       "      <td>1.39345</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.55122</td>\n",
       "      <td>-1.98445</td>\n",
       "      <td>1.41139</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.51335</td>\n",
       "      <td>-1.97557</td>\n",
       "      <td>1.42615</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.52959</td>\n",
       "      <td>-1.98187</td>\n",
       "      <td>1.45395</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id    acc_x    acc_y    acc_z     activity\n",
       "0           0 -9.57434 -2.02733  1.34506  climbing_up\n",
       "1           0 -9.56479 -1.99597  1.39345  climbing_up\n",
       "2           0 -9.55122 -1.98445  1.41139  climbing_up\n",
       "3           0 -9.51335 -1.97557  1.42615  climbing_up\n",
       "4           0 -9.52959 -1.98187  1.45395  climbing_up"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data without header\n",
    "data = pd.read_csv('./ISWC21_data_plus_raw/rwhar_data.csv', header=None)\n",
    "# add header\n",
    "data.columns = ['subject_id', 'acc_x', 'acc_y', 'acc_z', 'activity']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique subjects is 15\n"
     ]
    }
   ],
   "source": [
    "# print the count of unique subjects\n",
    "print('The number of unique subjects is {}'.format(data['subject_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200803, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(data['activity'])\n",
    "data['encoded_activity'] = encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>activity</th>\n",
       "      <th>encoded_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.57434</td>\n",
       "      <td>-2.02733</td>\n",
       "      <td>1.34506</td>\n",
       "      <td>climbing_up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.56479</td>\n",
       "      <td>-1.99597</td>\n",
       "      <td>1.39345</td>\n",
       "      <td>climbing_up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.55122</td>\n",
       "      <td>-1.98445</td>\n",
       "      <td>1.41139</td>\n",
       "      <td>climbing_up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.51335</td>\n",
       "      <td>-1.97557</td>\n",
       "      <td>1.42615</td>\n",
       "      <td>climbing_up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.52959</td>\n",
       "      <td>-1.98187</td>\n",
       "      <td>1.45395</td>\n",
       "      <td>climbing_up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id    acc_x    acc_y    acc_z     activity  encoded_activity\n",
       "0           0 -9.57434 -2.02733  1.34506  climbing_up                 1\n",
       "1           0 -9.56479 -1.99597  1.39345  climbing_up                 1\n",
       "2           0 -9.55122 -1.98445  1.41139  climbing_up                 1\n",
       "3           0 -9.51335 -1.97557  1.42615  climbing_up                 1\n",
       "4           0 -9.52959 -1.98187  1.45395  climbing_up                 1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of classes\n",
    "num_classes = data['encoded_activity'].nunique()\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_id          0\n",
       "acc_x               0\n",
       "acc_y               0\n",
       "acc_z               0\n",
       "activity            0\n",
       "encoded_activity    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the null values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of train users is 10\n",
      "The number of test users is 5\n",
      "The shape of train is (2200794, 6)\n",
      "The shape of test is (1000009, 6)\n"
     ]
    }
   ],
   "source": [
    "# split train and test users\n",
    "# randomly select 70% of the users for training\n",
    "train_subjects = np.random.choice(data['subject_id'].unique(), int(0.7*len(data['subject_id'].unique())), replace=False)\n",
    "# split the data into train and test\n",
    "train = data[data['subject_id'].isin(train_subjects)]\n",
    "test = data[~data['subject_id'].isin(train_subjects)]\n",
    "\n",
    "# print test and train users\n",
    "print('The number of train users is {}'.format(train['subject_id'].nunique()))\n",
    "print('The number of test users is {}'.format(test['subject_id'].nunique()))\n",
    "\n",
    "# print the shape of train and test\n",
    "print('The shape of train is {}'.format(train.shape))\n",
    "print('The shape of test is {}'.format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 14,  5,  0, 11,  4, 10, 12,  7, 13], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test subjects are [1 3 6 8 9]\n"
     ]
    }
   ],
   "source": [
    "# print the test subjects\n",
    "print('The test subjects are {}'.format(test['subject_id'].unique()))\n",
    "\n",
    "# [1 3 6 8 9] are the test subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setup the mean and std for normalization\n",
    "# mean = {'acc_x': 0.816012, 'acc_y': -0.007595, 'acc_z': 0.074082}\n",
    "# std = {'acc_x': 0.398664, 'acc_y': 0.375481, 'acc_z': 0.366527}\n",
    "\n",
    "# # normalize the data for acc_x, acc_y, acc_z\n",
    "# data['acc_x'] = (data['acc_x'] - mean['acc_x']) / std['acc_x']\n",
    "# data['acc_y'] = (data['acc_y'] - mean['acc_y']) / std['acc_y']\n",
    "# data['acc_z'] = (data['acc_z'] - mean['acc_z']) / std['acc_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # z-normalize the data for acc_x, acc_y, acc_z with mean and std of train data\n",
    "# train_data_mean = train[['acc_x', 'acc_y', 'acc_z']].mean()\n",
    "# train_data_std = train[['acc_x', 'acc_y', 'acc_z']].std()\n",
    "\n",
    "# # Normalize Training Data\n",
    "# train.loc[:, ['acc_x', 'acc_y', 'acc_z']] = (train[['acc_x', 'acc_y', 'acc_z']] - train_data_mean) / train_data_std\n",
    "\n",
    "# # Normalize Test Data with Training Statistics\n",
    "# test.loc[:, ['acc_x', 'acc_y', 'acc_z']] = (test[['acc_x', 'acc_y', 'acc_z']] - train_data_mean) / train_data_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Subset of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train subjects are [ 2  4  5  7 12 13 14]\n",
      "The shape of train_75 is (1553420, 6)\n"
     ]
    }
   ],
   "source": [
    "# randomly select 75% of the users for training\n",
    "# train_subjects_75 = np.random.choice(train['subject_id'].unique(), int(0.75*len(train['subject_id'].unique())), replace=False)\n",
    "train_subjects_75 = [2, 4, 5, 7, 12, 13, 14]\n",
    "train_75 = data[data['subject_id'].isin(train_subjects_75)]\n",
    "\n",
    "# print the train subjects\n",
    "print('The train subjects are {}'.format(train_75['subject_id'].unique()))\n",
    "#print shape of train_75\n",
    "print('The shape of train_75 is {}'.format(train_75.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train subjects are [ 0  2  5 12 14]\n",
      "The shape of train_50 is (1099152, 6)\n"
     ]
    }
   ],
   "source": [
    "# randomly select 50% of the users for training\n",
    "# train_subjects_50 = np.random.choice(train['subject_id'].unique(), int(0.5*len(train['subject_id'].unique())), replace=False)\n",
    "train_subjects_50 = [0, 2, 5, 12, 14]\n",
    "train_50 = data[data['subject_id'].isin(train_subjects_50)]\n",
    "\n",
    "# print the train subjects\n",
    "print('The train subjects are {}'.format(train_50['subject_id'].unique()))\n",
    "#print shape of train_50\n",
    "print('The shape of train_50 is {}'.format(train_50.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train subjects are [ 5 10]\n",
      "The shape of train_25 is (436182, 6)\n"
     ]
    }
   ],
   "source": [
    "# randomly select 25% of the users for training\n",
    "# train_subjects_25 = np.random.choice(train['subject_id'].unique(), int(0.25*len(train['subject_id'].unique())), replace=False)\n",
    "train_subjects_25 = [5, 10]\n",
    "train_25 = data[data['subject_id'].isin(train_subjects_25)]\n",
    "\n",
    "# print the train subjects\n",
    "print('The train subjects are {}'.format(train_25['subject_id'].unique()))\n",
    "#print shape of train_25\n",
    "print('The shape of train_25 is {}'.format(train_25.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train subjects are [11]\n",
      "The shape of train_10 is (212453, 6)\n"
     ]
    }
   ],
   "source": [
    "# randomly select 10% of the users for training\n",
    "# train_subjects_10 = np.random.choice(train['subject_id'].unique(), int(0.1*len(train['subject_id'].unique())), replace=False)\n",
    "train_subjects_10 = [11]\n",
    "train_10 = data[data['subject_id'].isin(train_subjects_10)]\n",
    "\n",
    "# print the train subjects\n",
    "print('The train subjects are {}'.format(train_10['subject_id'].unique()))\n",
    "#print shape of train_10\n",
    "print('The shape of train_10 is {}'.format(train_10.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_samples(data, samples_per_window, overlap_ratio):\n",
    "    \"\"\"\n",
    "    Return a sliding window measured in number of samples over a data array along with the mode label for each window.\n",
    "\n",
    "    :param data: input array, can be numpy or pandas dataframe\n",
    "    :param samples_per_window: window length as number of samples\n",
    "    :param overlap_ratio: overlap is meant as percentage and should be an integer value\n",
    "    :return: tuple of windows, indices, and labels\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    indices = []\n",
    "    labels = []\n",
    "    curr = 0\n",
    "    win_len = int(samples_per_window)\n",
    "    if overlap_ratio is not None:\n",
    "        overlapping_elements = int((overlap_ratio / 100) * win_len)\n",
    "        if overlapping_elements >= win_len:\n",
    "            print('Number of overlapping elements exceeds window size.')\n",
    "            return\n",
    "    while curr < len(data) - win_len:\n",
    "        window = data[curr:curr + win_len]\n",
    "        windows.append(window.iloc[:, :-2])  # Exclude the last two columns (original and encoded labels)\n",
    "        indices.append([curr, curr + win_len])\n",
    "        \n",
    "        # Extract and compute the mode of the encoded labels for the current window\n",
    "        window_labels = window['encoded_activity']\n",
    "        mode_result = mode(window_labels)\n",
    "        window_label = mode_result[0] if mode_result[0].size > 0 else mode_result\n",
    "        labels.append(window_label)\n",
    "\n",
    "        curr += win_len - overlapping_elements\n",
    "\n",
    "    result_windows = np.array(windows)\n",
    "    result_indices = np.array(indices)\n",
    "    result_labels = np.array(labels)\n",
    "    return result_windows, result_indices, result_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train window dataset (2 sec with 0% overlap): (22007, 100, 4)\n",
      "shape of test window dataset (2 sec with 0% overlap): (10000, 100, 4)\n"
     ]
    }
   ],
   "source": [
    "# sampling_rate = 50\n",
    "# time_window = 8\n",
    "# window_size = sampling_rate * time_window\n",
    "# overlap_ratio = 50\n",
    "\n",
    "sampling_rate = 50\n",
    "time_window = 2\n",
    "window_size = sampling_rate * time_window\n",
    "overlap_ratio = 0\n",
    "\n",
    "train_window_data, _, train_window_label = sliding_window_samples(train, window_size, overlap_ratio)\n",
    "print(f\"shape of train window dataset ({time_window} sec with {overlap_ratio}% overlap): {train_window_data.shape}\")\n",
    "\n",
    "test_window_data, _, test_window_label = sliding_window_samples(test, window_size, overlap_ratio)\n",
    "print(f\"shape of test window dataset ({time_window} sec with {overlap_ratio}% overlap): {test_window_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.     , -9.57434, -2.02733,  1.34506],\n",
       "       [ 0.     , -9.56479, -1.99597,  1.39345],\n",
       "       [ 0.     , -9.55122, -1.98445,  1.41139],\n",
       "       [ 0.     , -9.51335, -1.97557,  1.42615],\n",
       "       [ 0.     , -9.52959, -1.98187,  1.45395],\n",
       "       [ 0.     , -9.55446, -2.00818,  1.40735],\n",
       "       [ 0.     , -9.53834, -2.00737,  1.37628],\n",
       "       [ 0.     , -9.53804, -2.01022,  1.39708],\n",
       "       [ 0.     , -9.54524, -2.00552,  1.33041],\n",
       "       [ 0.     , -9.52776, -2.00702,  1.34845],\n",
       "       [ 0.     , -9.55386, -2.02527,  1.35837],\n",
       "       [ 0.     , -9.52835, -2.03238,  1.38365],\n",
       "       [ 0.     , -9.56699, -1.99843,  1.39401],\n",
       "       [ 0.     , -9.56685, -2.00259,  1.39221],\n",
       "       [ 0.     , -9.52701, -2.00899,  1.43456],\n",
       "       [ 0.     , -9.5379 , -1.98004,  1.41574],\n",
       "       [ 0.     , -9.5269 , -2.00275,  1.39914],\n",
       "       [ 0.     , -9.53383, -2.01756,  1.39552],\n",
       "       [ 0.     , -9.52927, -2.04524,  1.39505],\n",
       "       [ 0.     , -9.54939, -2.06349,  1.35515],\n",
       "       [ 0.     , -9.57919, -2.05342,  1.30473],\n",
       "       [ 0.     , -9.54581, -2.00975,  1.40678],\n",
       "       [ 0.     , -9.55437, -1.97728,  1.37785],\n",
       "       [ 0.     , -9.53853, -1.91187,  1.42242],\n",
       "       [ 0.     , -9.54269, -1.93948,  1.38406],\n",
       "       [ 0.     , -9.55089, -1.94292,  1.35092],\n",
       "       [ 0.     , -9.55858, -1.92409,  1.37088],\n",
       "       [ 0.     , -9.58437, -1.9384 ,  1.30769],\n",
       "       [ 0.     , -9.60376, -1.9664 ,  1.30066],\n",
       "       [ 0.     , -9.57201, -1.937  ,  1.37991],\n",
       "       [ 0.     , -9.48825, -1.94637,  1.41388],\n",
       "       [ 0.     , -9.50738, -1.98032,  1.39027],\n",
       "       [ 0.     , -9.50343, -1.9859 ,  1.43124],\n",
       "       [ 0.     , -9.51437, -2.00862,  1.39946],\n",
       "       [ 0.     , -9.60202, -2.0014 ,  1.37727],\n",
       "       [ 0.     , -9.59247, -1.99593,  1.33881],\n",
       "       [ 0.     , -9.54808, -2.01442,  1.33626],\n",
       "       [ 0.     , -9.53618, -1.96252,  1.39854],\n",
       "       [ 0.     , -9.49696, -1.96182,  1.40451],\n",
       "       [ 0.     , -9.54164, -1.99272,  1.42386],\n",
       "       [ 0.     , -9.54819, -2.03534,  1.40292],\n",
       "       [ 0.     , -9.53156, -2.03748,  1.4025 ],\n",
       "       [ 0.     , -9.56239, -2.03786,  1.37531],\n",
       "       [ 0.     , -9.53401, -1.9895 ,  1.36824],\n",
       "       [ 0.     , -9.54245, -2.00624,  1.36913],\n",
       "       [ 0.     , -9.53153, -2.01468,  1.35768],\n",
       "       [ 0.     , -9.52769, -2.04039,  1.38901],\n",
       "       [ 0.     , -9.53714, -1.98903,  1.3676 ],\n",
       "       [ 0.     , -9.53729, -2.00072,  1.38795],\n",
       "       [ 0.     , -9.56065, -2.00671,  1.36797],\n",
       "       [ 0.     , -9.53923, -1.98451,  1.40778],\n",
       "       [ 0.     , -9.54686, -1.99846,  1.39595],\n",
       "       [ 0.     , -9.54067, -1.9949 ,  1.38991],\n",
       "       [ 0.     , -9.55211, -2.03433,  1.37581],\n",
       "       [ 0.     , -9.5605 , -2.02248,  1.34822],\n",
       "       [ 0.     , -9.5572 , -1.98334,  1.36485],\n",
       "       [ 0.     , -9.53024, -1.99268,  1.38704],\n",
       "       [ 0.     , -9.52623, -1.9971 ,  1.35849],\n",
       "       [ 0.     , -9.5197 , -1.99419,  1.41997],\n",
       "       [ 0.     , -9.56703, -2.01167,  1.36169],\n",
       "       [ 0.     , -9.57712, -2.0105 ,  1.37529],\n",
       "       [ 0.     , -9.53651, -1.99554,  1.28723],\n",
       "       [ 0.     , -9.57671, -1.98624,  1.3004 ],\n",
       "       [ 0.     , -9.59233, -1.97415,  1.3421 ],\n",
       "       [ 0.     , -9.51952, -1.96303,  1.4254 ],\n",
       "       [ 0.     , -9.51927, -1.96407,  1.40817],\n",
       "       [ 0.     , -9.52806, -1.99628,  1.37447],\n",
       "       [ 0.     , -9.51862, -2.03751,  1.39439],\n",
       "       [ 0.     , -9.55586, -2.04478,  1.3385 ],\n",
       "       [ 0.     , -9.56255, -2.04832,  1.31299],\n",
       "       [ 0.     , -9.56233, -1.98579,  1.30225],\n",
       "       [ 0.     , -9.55365, -1.97885,  1.37724],\n",
       "       [ 0.     , -9.53552, -1.98027,  1.39236],\n",
       "       [ 0.     , -9.58125, -1.95444,  1.44051],\n",
       "       [ 0.     , -9.57291, -2.01328,  1.39828],\n",
       "       [ 0.     , -9.55646, -2.01436,  1.3744 ],\n",
       "       [ 0.     , -9.52835, -2.01096,  1.34441],\n",
       "       [ 0.     , -9.5558 , -2.00215,  1.32759],\n",
       "       [ 0.     , -9.51975, -1.99797,  1.37598],\n",
       "       [ 0.     , -9.52168, -2.02998,  1.34213],\n",
       "       [ 0.     , -9.55077, -2.00726,  1.34149],\n",
       "       [ 0.     , -9.56644, -2.04855,  1.3988 ],\n",
       "       [ 0.     , -9.54649, -2.03125,  1.41132],\n",
       "       [ 0.     , -9.55216, -1.98485,  1.44388],\n",
       "       [ 0.     , -9.54489, -1.97496,  1.45764],\n",
       "       [ 0.     , -9.55424, -1.97469,  1.43362],\n",
       "       [ 0.     , -9.53337, -2.00058,  1.42389],\n",
       "       [ 0.     , -9.55183, -2.00632,  1.37601],\n",
       "       [ 0.     , -9.55583, -2.0061 ,  1.37352],\n",
       "       [ 0.     , -9.55884, -2.03387,  1.36136],\n",
       "       [ 0.     , -9.54465, -1.98581,  1.42012],\n",
       "       [ 0.     , -9.50615, -1.9633 ,  1.38219],\n",
       "       [ 0.     , -9.54141, -1.94768,  1.36845],\n",
       "       [ 0.     , -9.55809, -2.01511,  1.31859],\n",
       "       [ 0.     , -9.5717 , -1.98106,  1.38014],\n",
       "       [ 0.     , -9.57861, -1.94254,  1.39775],\n",
       "       [ 0.     , -9.52849, -1.92653,  1.32771],\n",
       "       [ 0.     , -9.55745, -1.96399,  1.37877],\n",
       "       [ 0.     , -9.51877, -1.95482,  1.36098],\n",
       "       [ 0.     , -9.4998 , -1.95235,  1.38393]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_window_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.     , -9.35294, -1.67323,  2.46066],\n",
       "       [ 1.     , -9.42616, -1.75624,  2.50548],\n",
       "       [ 1.     , -9.47662, -1.78891,  2.5455 ],\n",
       "       [ 1.     , -9.42629, -1.78287,  2.54344],\n",
       "       [ 1.     , -9.35275, -1.7596 ,  2.53835],\n",
       "       [ 1.     , -9.29709, -1.73738,  2.54102],\n",
       "       [ 1.     , -9.32877, -1.72122,  2.536  ],\n",
       "       [ 1.     , -9.3667 , -1.76122,  2.53564],\n",
       "       [ 1.     , -9.35768, -1.81294,  2.53825],\n",
       "       [ 1.     , -9.35069, -1.75685,  2.5417 ],\n",
       "       [ 1.     , -9.33185, -1.75745,  2.47327],\n",
       "       [ 1.     , -9.31728, -1.76526,  2.50044],\n",
       "       [ 1.     , -9.35815, -1.77258,  2.52861],\n",
       "       [ 1.     , -9.39821, -1.81906,  2.49355],\n",
       "       [ 1.     , -9.39832, -1.82091,  2.53049],\n",
       "       [ 1.     , -9.37132, -1.74995,  2.50548],\n",
       "       [ 1.     , -9.28165, -1.61356,  2.51125],\n",
       "       [ 1.     , -9.29468, -1.58972,  2.51004],\n",
       "       [ 1.     , -9.30177, -1.60652,  2.49599],\n",
       "       [ 1.     , -9.35545, -1.70586,  2.52438],\n",
       "       [ 1.     , -9.40688, -1.8092 ,  2.49126],\n",
       "       [ 1.     , -9.41953, -1.83566,  2.47298],\n",
       "       [ 1.     , -9.41011, -1.77924,  2.49774],\n",
       "       [ 1.     , -9.3692 , -1.7339 ,  2.47829],\n",
       "       [ 1.     , -9.3373 , -1.71843,  2.47244],\n",
       "       [ 1.     , -9.35317, -1.74146,  2.46037],\n",
       "       [ 1.     , -9.35477, -1.72058,  2.44823],\n",
       "       [ 1.     , -9.38956, -1.71939,  2.48119],\n",
       "       [ 1.     , -9.41521, -1.70201,  2.49811],\n",
       "       [ 1.     , -9.42604, -1.69345,  2.49553],\n",
       "       [ 1.     , -9.37607, -1.68413,  2.47702],\n",
       "       [ 1.     , -9.33383, -1.69371,  2.45232],\n",
       "       [ 1.     , -9.33923, -1.69551,  2.44989],\n",
       "       [ 1.     , -9.35622, -1.71025,  2.45355],\n",
       "       [ 1.     , -9.39238, -1.69147,  2.46976],\n",
       "       [ 1.     , -9.36606, -1.70625,  2.45844],\n",
       "       [ 1.     , -9.31772, -1.67906,  2.43901],\n",
       "       [ 1.     , -9.31491, -1.66817,  2.42781],\n",
       "       [ 1.     , -9.2879 , -1.69966,  2.46422],\n",
       "       [ 1.     , -9.36737, -1.71494,  2.49957],\n",
       "       [ 1.     , -9.43674, -1.82051,  2.46077],\n",
       "       [ 1.     , -9.44074, -1.85687,  2.54274],\n",
       "       [ 1.     , -9.43111, -1.7061 ,  2.49516],\n",
       "       [ 1.     , -9.358  , -1.62465,  2.46927],\n",
       "       [ 1.     , -9.29748, -1.57248,  2.43246],\n",
       "       [ 1.     , -9.3037 , -1.53337,  2.45525],\n",
       "       [ 1.     , -9.38223, -1.6458 ,  2.4679 ],\n",
       "       [ 1.     , -9.43265, -1.80287,  2.50008],\n",
       "       [ 1.     , -9.42702, -1.80363,  2.46159],\n",
       "       [ 1.     , -9.39801, -1.82425,  2.51913],\n",
       "       [ 1.     , -9.38882, -1.78075,  2.55551],\n",
       "       [ 1.     , -9.33446, -1.71407,  2.56836],\n",
       "       [ 1.     , -9.39951, -1.77611,  2.56026],\n",
       "       [ 1.     , -9.36301, -1.80498,  2.53308],\n",
       "       [ 1.     , -9.35005, -1.77327,  2.5051 ],\n",
       "       [ 1.     , -9.33569, -1.7312 ,  2.47203],\n",
       "       [ 1.     , -9.33969, -1.74203,  2.4848 ],\n",
       "       [ 1.     , -9.38599, -1.74773,  2.49344],\n",
       "       [ 1.     , -9.36346, -1.74767,  2.55247],\n",
       "       [ 1.     , -9.36369, -1.7794 ,  2.58269],\n",
       "       [ 1.     , -9.339  , -1.78046,  2.55402],\n",
       "       [ 1.     , -9.3493 , -1.75955,  2.55669],\n",
       "       [ 1.     , -9.32794, -1.77264,  2.56857],\n",
       "       [ 1.     , -9.33676, -1.76915,  2.52612],\n",
       "       [ 1.     , -9.35576, -1.78928,  2.5811 ],\n",
       "       [ 1.     , -9.34222, -1.80598,  2.51724],\n",
       "       [ 1.     , -9.36713, -1.80688,  2.55305],\n",
       "       [ 1.     , -9.37637, -1.83376,  2.55357],\n",
       "       [ 1.     , -9.3703 , -1.84062,  2.57709],\n",
       "       [ 1.     , -9.36844, -1.79843,  2.60553],\n",
       "       [ 1.     , -9.28529, -1.71019,  2.57436],\n",
       "       [ 1.     , -9.30797, -1.64288,  2.5377 ],\n",
       "       [ 1.     , -9.29955, -1.61552,  2.52873],\n",
       "       [ 1.     , -9.34979, -1.6925 ,  2.56181],\n",
       "       [ 1.     , -9.42668, -1.79846,  2.56143],\n",
       "       [ 1.     , -9.39195, -1.85458,  2.53087],\n",
       "       [ 1.     , -9.41405, -1.83122,  2.50549],\n",
       "       [ 1.     , -9.43585, -1.79315,  2.51715],\n",
       "       [ 1.     , -9.37849, -1.69867,  2.50563],\n",
       "       [ 1.     , -9.39014, -1.72377,  2.57622],\n",
       "       [ 1.     , -9.36534, -1.71996,  2.5374 ],\n",
       "       [ 1.     , -9.40656, -1.80086,  2.519  ],\n",
       "       [ 1.     , -9.40779, -1.76154,  2.49522],\n",
       "       [ 1.     , -9.37965, -1.75789,  2.53915],\n",
       "       [ 1.     , -9.37245, -1.77719,  2.54585],\n",
       "       [ 1.     , -9.35445, -1.75751,  2.55707],\n",
       "       [ 1.     , -9.32788, -1.8103 ,  2.53183],\n",
       "       [ 1.     , -9.34332, -1.79565,  2.52219],\n",
       "       [ 1.     , -9.36287, -1.75945,  2.5667 ],\n",
       "       [ 1.     , -9.37234, -1.76253,  2.54205],\n",
       "       [ 1.     , -9.38443, -1.78   ,  2.54858],\n",
       "       [ 1.     , -9.37282, -1.79271,  2.47566],\n",
       "       [ 1.     , -9.38222, -1.78081,  2.50887],\n",
       "       [ 1.     , -9.3865 , -1.73401,  2.50584],\n",
       "       [ 1.     , -9.407  , -1.79205,  2.5052 ],\n",
       "       [ 1.     , -9.38718, -1.82713,  2.52019],\n",
       "       [ 1.     , -9.40346, -1.75146,  2.51932],\n",
       "       [ 1.     , -9.33595, -1.702  ,  2.54662],\n",
       "       [ 1.     , -9.30173, -1.68068,  2.45674],\n",
       "       [ 1.     , -9.23666, -1.63107,  2.51102]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_window_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the subject column\n",
    "train_window_data = train_window_data[:, :, 1:]\n",
    "test_window_data = test_window_data[:, :, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train is (22007, 100, 3)\n",
      "The shape of test is (10000, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of train and test\n",
    "print('The shape of train is {}'.format(train_window_data.shape))\n",
    "print('The shape of test is {}'.format(test_window_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train label is 22007\n",
      "The length of test label is 10000\n"
     ]
    }
   ],
   "source": [
    "# length of train and test label\n",
    "print('The length of train label is {}'.format(len(train_window_label)))\n",
    "print('The length of test label is {}'.format(len(test_window_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train window dataset (8 sec with 50% overlap): (7766, 400, 4)\n"
     ]
    }
   ],
   "source": [
    "sampling_rate = 50\n",
    "time_window = 8\n",
    "window_size = sampling_rate * time_window\n",
    "overlap_ratio = 50\n",
    "\n",
    "train_window_data_75, _, train_window_label_75 = sliding_window_samples(train_75, window_size, overlap_ratio)\n",
    "print(f\"shape of train window dataset ({time_window} sec with {overlap_ratio}% overlap): {train_window_data_75.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the subject column\n",
    "train_window_data_75 = train_window_data_75[:, :, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_75 is (7766, 400, 3)\n",
      "The length of train_75 label is 7766\n"
     ]
    }
   ],
   "source": [
    "print('The shape of train_75 is {}'.format(train_window_data_75.shape))\n",
    "print('The length of train_75 label is {}'.format(len(train_window_label_75)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train window dataset (8 sec with 50% overlap): (5494, 400, 4)\n",
      "The shape of train_50 is (5494, 400, 3)\n",
      "The length of train_50 label is 5494\n"
     ]
    }
   ],
   "source": [
    "train_window_data_50, _, train_window_label_50 = sliding_window_samples(train_50, window_size, overlap_ratio)\n",
    "print(f\"shape of train window dataset ({time_window} sec with {overlap_ratio}% overlap): {train_window_data_50.shape}\")\n",
    "\n",
    "# remove the subject column\n",
    "train_window_data_50 = train_window_data_50[:, :, 1:]\n",
    "\n",
    "print('The shape of train_50 is {}'.format(train_window_data_50.shape))\n",
    "print('The length of train_50 label is {}'.format(len(train_window_label_50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_25 is (2179, 400, 3)\n",
      "The length of train_25 label is 2179\n"
     ]
    }
   ],
   "source": [
    "train_window_data_25, _, train_window_label_25 = sliding_window_samples(train_25, window_size, overlap_ratio)\n",
    "# remove the subject column\n",
    "train_window_data_25 = train_window_data_25[:, :, 1:]\n",
    "\n",
    "print('The shape of train_25 is {}'.format(train_window_data_25.shape))\n",
    "print('The length of train_25 label is {}'.format(len(train_window_label_25)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_10 is (1061, 400, 3)\n",
      "The length of train_10 label is 1061\n"
     ]
    }
   ],
   "source": [
    "train_window_data_10, _, train_window_label_10 = sliding_window_samples(train_10, window_size, overlap_ratio)\n",
    "# remove the subject column\n",
    "train_window_data_10 = train_window_data_10[:, :, 1:]\n",
    "\n",
    "print('The shape of train_10 is {}'.format(train_window_data_10.shape))\n",
    "print('The length of train_10 label is {}'.format(len(train_window_label_10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Subset of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the sample size\n",
    "# sample_size = int(0.75 * len(train_window_data))\n",
    "\n",
    "# # Generate random indices\n",
    "# indices = random.sample(range(len(train_window_data)), sample_size)\n",
    "\n",
    "# # Sample the data and labels\n",
    "# sampled_train_window_data_75 = [train_window_data[i] for i in indices]\n",
    "# sampled_train_window_label_75 = [train_window_label[i] for i in indices]\n",
    "\n",
    "# # print the shape of sampled train data and label\n",
    "# print('The shape of sampled train label is {}'.format(np.array(sampled_train_window_label_75).shape))\n",
    "# print('The shape of sampled train is {}'.format(np.array(sampled_train_window_data_75).shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the sample size\n",
    "# sample_size = int(0.5 * len(train_window_data))\n",
    "\n",
    "# # Generate random indices\n",
    "# indices = random.sample(range(len(train_window_data)), sample_size)\n",
    "\n",
    "# # Sample the data and labels\n",
    "# sampled_train_window_data_50 = [train_window_data[i] for i in indices]\n",
    "# sampled_train_window_label_50 = [train_window_label[i] for i in indices]\n",
    "\n",
    "# # print the shape of sampled train data and label\n",
    "# print('The shape of sampled train label is {}'.format(np.array(sampled_train_window_label_50).shape))\n",
    "# print('The shape of sampled train is {}'.format(np.array(sampled_train_window_data_50).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the sample size\n",
    "# sample_size = int(0.25 * len(train_window_data))\n",
    "\n",
    "# # Generate random indices\n",
    "# indices = random.sample(range(len(train_window_data)), sample_size)\n",
    "\n",
    "# # Sample the data and labels\n",
    "# sampled_train_window_data_25 = [train_window_data[i] for i in indices]\n",
    "# sampled_train_window_label_25 = [train_window_label[i] for i in indices]\n",
    "\n",
    "# # print the shape of sampled train data and label\n",
    "# print('The shape of sampled train label is {}'.format(np.array(sampled_train_window_label_25).shape))\n",
    "# print('The shape of sampled train is {}'.format(np.array(sampled_train_window_data_25).shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the sample size\n",
    "# sample_size = int(0.1 * len(train_window_data))\n",
    "\n",
    "# # Generate random indices\n",
    "# indices = random.sample(range(len(train_window_data)), sample_size)\n",
    "\n",
    "# # Sample the data and labels\n",
    "# sampled_train_window_data_10 = [train_window_data[i] for i in indices]\n",
    "# sampled_train_window_label_10 = [train_window_label[i] for i in indices]\n",
    "\n",
    "# # print the shape of sampled train data and label\n",
    "# print('The shape of sampled train label is {}'.format(np.array(sampled_train_window_label_10).shape))\n",
    "# print('The shape of sampled train is {}'.format(np.array(sampled_train_window_data_10).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataloader for train and test\n",
    "def generate_dataloader(data, label, batch_size, is_shuffle=True):\n",
    "    \"\"\"\n",
    "    Generate dataloader for train and test\n",
    "\n",
    "    :param data: input data\n",
    "    :param label: input label\n",
    "    :param batch_size: batch size\n",
    "    :return: train and test dataloader\n",
    "    \"\"\"\n",
    "    # Check if data and label are lists, and convert them to NumPy arrays if they are\n",
    "    if isinstance(data, list):\n",
    "        data = np.array(data)\n",
    "    if isinstance(label, list):\n",
    "        label = np.array(label)\n",
    "    \n",
    "    # Convert data and label to tensor\n",
    "    data_tensor = torch.from_numpy(data).float()  # Ensure data is converted to float for PyTorch\n",
    "    label_tensor = torch.from_numpy(label).long()  # Labels typically converted to long for classification tasks\n",
    "    \n",
    "    # Generate dataloader\n",
    "    dataset = TensorDataset(data_tensor, label_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=is_shuffle)\n",
    "    \n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataloader for train and test\n",
    "train_dataloader = generate_dataloader(train_window_data, train_window_label, batch_size)   \n",
    "test_dataloader = generate_dataloader(test_window_data, test_window_label, batch_size, is_shuffle=False)\n",
    "\n",
    "# # generate dataloader for train sampled data and label\n",
    "# train_dataloader_75 = generate_dataloader(sampled_train_window_data_75, sampled_train_window_label_75, batch_size)\n",
    "# train_dataloader_50 = generate_dataloader(sampled_train_window_data_50, sampled_train_window_label_50, batch_size)\n",
    "# train_dataloader_25 = generate_dataloader(sampled_train_window_data_25, sampled_train_window_label_25, batch_size)\n",
    "# train_dataloader_10 = generate_dataloader(sampled_train_window_data_10, sampled_train_window_label_10, batch_size)\n",
    "\n",
    "# generate dataloader for train and test in subject subsetting\n",
    "train_dataloader_75 = generate_dataloader(train_window_data_75, train_window_label_75, batch_size)\n",
    "train_dataloader_50 = generate_dataloader(train_window_data_50, train_window_label_50, batch_size)\n",
    "train_dataloader_25 = generate_dataloader(train_window_data_25, train_window_label_25, batch_size)\n",
    "train_dataloader_10 = generate_dataloader(train_window_data_10, train_window_label_10, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training function\n",
    "def train_function(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.transpose(1, 2)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs = inputs.transpose(1, 2)  # Assuming this is necessary for your model\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Collect all true labels and predictions for F1 score calculation\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    \n",
    "    # Calculate F1 score. You might need to adjust the 'average' parameter based on your task\n",
    "    # For binary classification, you can use 'binary'. For multi-class, consider 'macro' or 'weighted'\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "    return running_loss / len(test_loader), accuracy, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to train and test model\n",
    "def train_and_test(model, train_loader, test_loader, criterion, optimizer, device, num_epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    test_f1_scores = []  # List to store F1-scores for each epoch\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        train_loss = train_function(model, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Testing phase\n",
    "        test_loss, test_accuracy, test_f1 = test_function(model, test_loader, criterion, device)  # Modified to receive F1-score\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        test_f1_scores.append(test_f1)  # Store the F1-score\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch: {epoch + 1}/{num_epochs}.. Train Loss: {train_loss:.3f}.. \"\n",
    "              f\"Test Loss: {test_loss:.3f}.. Test Accuracy: {test_accuracy:.3f}.. Test F1 Score: {test_f1:.3f}\")\n",
    "\n",
    "    return train_losses, test_losses, test_accuracies, test_f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask Self Supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TPN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TPN, self).__init__()\n",
    "        self.trunk = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=3, out_channels=32, kernel_size=24, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=16, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv1d(in_channels=64, out_channels=96, kernel_size=8, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.AdaptiveMaxPool1d(output_size=1)\n",
    "        )\n",
    "\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(96, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 1),\n",
    "                nn.Sigmoid()\n",
    "            ) for _ in range(8)  # 8 heads for 8 different transformations\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.trunk(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully-connected layer\n",
    "        outputs = [head(x) for head in self.heads]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedTPN(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_classes):\n",
    "        super(SupervisedTPN, self).__init__()\n",
    "        self.trunk = pretrained_model.trunk # Use the trunk from the pretrained model\n",
    "        # Freeze the trunk\n",
    "        for param in self.trunk.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(96, 1024),  # Adjusted to match the document's description\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, num_classes)  # Softmax applied externally during training\n",
    "        )\n",
    "        # No softmax here as it's included in nn.CrossEntropyLoss during training\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.trunk(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully-connected layer\n",
    "        output = self.head(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Only Head Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "pretrained_model_path = './multitask/tpn_30_epoch_regularized_2.pt'  # Adjust as necessary\n",
    "pretrained_model = TPN()\n",
    "pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Create the supervised model by adjusting the pre-trained model\n",
    "supervised_model = SupervisedTPN(pretrained_model, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 0.924.. Test Loss: 1.127.. Test Accuracy: 0.661.. Test F1 Score: 0.651\n",
      "Epoch: 2/30.. Train Loss: 0.772.. Test Loss: 1.122.. Test Accuracy: 0.669.. Test F1 Score: 0.663\n",
      "Epoch: 3/30.. Train Loss: 0.735.. Test Loss: 1.073.. Test Accuracy: 0.667.. Test F1 Score: 0.656\n",
      "Epoch: 4/30.. Train Loss: 0.700.. Test Loss: 0.994.. Test Accuracy: 0.668.. Test F1 Score: 0.655\n",
      "Epoch: 5/30.. Train Loss: 0.682.. Test Loss: 1.000.. Test Accuracy: 0.680.. Test F1 Score: 0.668\n",
      "Epoch: 6/30.. Train Loss: 0.665.. Test Loss: 1.066.. Test Accuracy: 0.669.. Test F1 Score: 0.656\n",
      "Epoch: 7/30.. Train Loss: 0.649.. Test Loss: 0.960.. Test Accuracy: 0.686.. Test F1 Score: 0.674\n",
      "Epoch: 8/30.. Train Loss: 0.637.. Test Loss: 1.003.. Test Accuracy: 0.669.. Test F1 Score: 0.654\n",
      "Epoch: 9/30.. Train Loss: 0.627.. Test Loss: 0.983.. Test Accuracy: 0.698.. Test F1 Score: 0.691\n",
      "Epoch: 10/30.. Train Loss: 0.615.. Test Loss: 1.050.. Test Accuracy: 0.678.. Test F1 Score: 0.671\n",
      "Epoch: 11/30.. Train Loss: 0.616.. Test Loss: 1.058.. Test Accuracy: 0.671.. Test F1 Score: 0.658\n",
      "Epoch: 12/30.. Train Loss: 0.604.. Test Loss: 1.039.. Test Accuracy: 0.678.. Test F1 Score: 0.671\n",
      "Epoch: 13/30.. Train Loss: 0.601.. Test Loss: 1.071.. Test Accuracy: 0.676.. Test F1 Score: 0.669\n",
      "Epoch: 14/30.. Train Loss: 0.597.. Test Loss: 1.032.. Test Accuracy: 0.680.. Test F1 Score: 0.669\n",
      "Epoch: 15/30.. Train Loss: 0.590.. Test Loss: 1.022.. Test Accuracy: 0.627.. Test F1 Score: 0.625\n",
      "Epoch: 16/30.. Train Loss: 0.581.. Test Loss: 1.068.. Test Accuracy: 0.681.. Test F1 Score: 0.670\n",
      "Epoch: 17/30.. Train Loss: 0.579.. Test Loss: 1.018.. Test Accuracy: 0.689.. Test F1 Score: 0.681\n",
      "Epoch: 18/30.. Train Loss: 0.580.. Test Loss: 1.037.. Test Accuracy: 0.692.. Test F1 Score: 0.684\n",
      "Epoch: 19/30.. Train Loss: 0.575.. Test Loss: 1.071.. Test Accuracy: 0.677.. Test F1 Score: 0.674\n",
      "Epoch: 20/30.. Train Loss: 0.569.. Test Loss: 1.083.. Test Accuracy: 0.678.. Test F1 Score: 0.673\n",
      "Epoch: 21/30.. Train Loss: 0.570.. Test Loss: 1.137.. Test Accuracy: 0.682.. Test F1 Score: 0.681\n",
      "Epoch: 22/30.. Train Loss: 0.567.. Test Loss: 1.035.. Test Accuracy: 0.682.. Test F1 Score: 0.675\n",
      "Epoch: 23/30.. Train Loss: 0.562.. Test Loss: 1.033.. Test Accuracy: 0.649.. Test F1 Score: 0.642\n",
      "Epoch: 24/30.. Train Loss: 0.560.. Test Loss: 1.098.. Test Accuracy: 0.659.. Test F1 Score: 0.652\n",
      "Epoch: 25/30.. Train Loss: 0.564.. Test Loss: 1.084.. Test Accuracy: 0.677.. Test F1 Score: 0.671\n",
      "Epoch: 26/30.. Train Loss: 0.560.. Test Loss: 1.095.. Test Accuracy: 0.674.. Test F1 Score: 0.670\n",
      "Epoch: 27/30.. Train Loss: 0.555.. Test Loss: 1.118.. Test Accuracy: 0.638.. Test F1 Score: 0.629\n",
      "Epoch: 28/30.. Train Loss: 0.553.. Test Loss: 1.062.. Test Accuracy: 0.641.. Test F1 Score: 0.641\n",
      "Epoch: 29/30.. Train Loss: 0.553.. Test Loss: 1.105.. Test Accuracy: 0.641.. Test F1 Score: 0.639\n",
      "Epoch: 30/30.. Train Loss: 0.547.. Test Loss: 1.109.. Test Accuracy: 0.678.. Test F1 Score: 0.669\n"
     ]
    }
   ],
   "source": [
    "# Prepare for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(supervised_model.head.parameters(), lr=0.0003, weight_decay=0.0001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(supervised_model, train_dataloader, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "pretrained_model = TPN()\n",
    "pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Create the supervised model by adjusting the pre-trained model\n",
    "supervised_model = SupervisedTPN(pretrained_model, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.025.. Test Loss: 1.366.. Test Accuracy: 0.571.. Test F1 Score: 0.544\n",
      "Epoch: 2/30.. Train Loss: 0.767.. Test Loss: 1.331.. Test Accuracy: 0.585.. Test F1 Score: 0.562\n",
      "Epoch: 3/30.. Train Loss: 0.682.. Test Loss: 1.317.. Test Accuracy: 0.597.. Test F1 Score: 0.575\n",
      "Epoch: 4/30.. Train Loss: 0.649.. Test Loss: 1.580.. Test Accuracy: 0.613.. Test F1 Score: 0.583\n",
      "Epoch: 5/30.. Train Loss: 0.618.. Test Loss: 1.616.. Test Accuracy: 0.598.. Test F1 Score: 0.575\n",
      "Epoch: 6/30.. Train Loss: 0.612.. Test Loss: 1.635.. Test Accuracy: 0.602.. Test F1 Score: 0.576\n",
      "Epoch: 7/30.. Train Loss: 0.604.. Test Loss: 1.668.. Test Accuracy: 0.590.. Test F1 Score: 0.563\n",
      "Epoch: 8/30.. Train Loss: 0.561.. Test Loss: 1.666.. Test Accuracy: 0.575.. Test F1 Score: 0.551\n",
      "Epoch: 9/30.. Train Loss: 0.553.. Test Loss: 1.524.. Test Accuracy: 0.617.. Test F1 Score: 0.600\n",
      "Epoch: 10/30.. Train Loss: 0.545.. Test Loss: 1.734.. Test Accuracy: 0.609.. Test F1 Score: 0.578\n",
      "Epoch: 11/30.. Train Loss: 0.522.. Test Loss: 1.579.. Test Accuracy: 0.611.. Test F1 Score: 0.589\n",
      "Epoch: 12/30.. Train Loss: 0.508.. Test Loss: 1.635.. Test Accuracy: 0.603.. Test F1 Score: 0.576\n",
      "Epoch: 13/30.. Train Loss: 0.501.. Test Loss: 1.660.. Test Accuracy: 0.608.. Test F1 Score: 0.584\n",
      "Epoch: 14/30.. Train Loss: 0.488.. Test Loss: 1.640.. Test Accuracy: 0.607.. Test F1 Score: 0.582\n",
      "Epoch: 15/30.. Train Loss: 0.491.. Test Loss: 1.667.. Test Accuracy: 0.611.. Test F1 Score: 0.595\n",
      "Epoch: 16/30.. Train Loss: 0.473.. Test Loss: 1.636.. Test Accuracy: 0.618.. Test F1 Score: 0.600\n",
      "Epoch: 17/30.. Train Loss: 0.480.. Test Loss: 1.666.. Test Accuracy: 0.614.. Test F1 Score: 0.597\n",
      "Epoch: 18/30.. Train Loss: 0.463.. Test Loss: 1.636.. Test Accuracy: 0.608.. Test F1 Score: 0.588\n",
      "Epoch: 19/30.. Train Loss: 0.464.. Test Loss: 1.658.. Test Accuracy: 0.590.. Test F1 Score: 0.575\n",
      "Epoch: 20/30.. Train Loss: 0.447.. Test Loss: 1.912.. Test Accuracy: 0.570.. Test F1 Score: 0.549\n",
      "Epoch: 21/30.. Train Loss: 0.448.. Test Loss: 1.574.. Test Accuracy: 0.594.. Test F1 Score: 0.574\n",
      "Epoch: 22/30.. Train Loss: 0.442.. Test Loss: 1.674.. Test Accuracy: 0.602.. Test F1 Score: 0.582\n",
      "Epoch: 23/30.. Train Loss: 0.427.. Test Loss: 1.616.. Test Accuracy: 0.618.. Test F1 Score: 0.598\n",
      "Epoch: 24/30.. Train Loss: 0.436.. Test Loss: 1.677.. Test Accuracy: 0.597.. Test F1 Score: 0.579\n",
      "Epoch: 25/30.. Train Loss: 0.429.. Test Loss: 1.741.. Test Accuracy: 0.615.. Test F1 Score: 0.593\n",
      "Epoch: 26/30.. Train Loss: 0.418.. Test Loss: 1.690.. Test Accuracy: 0.616.. Test F1 Score: 0.593\n",
      "Epoch: 27/30.. Train Loss: 0.422.. Test Loss: 1.738.. Test Accuracy: 0.611.. Test F1 Score: 0.586\n",
      "Epoch: 28/30.. Train Loss: 0.410.. Test Loss: 1.747.. Test Accuracy: 0.589.. Test F1 Score: 0.574\n",
      "Epoch: 29/30.. Train Loss: 0.411.. Test Loss: 1.783.. Test Accuracy: 0.623.. Test F1 Score: 0.595\n",
      "Epoch: 30/30.. Train Loss: 0.410.. Test Loss: 1.766.. Test Accuracy: 0.580.. Test F1 Score: 0.566\n"
     ]
    }
   ],
   "source": [
    "# prepare for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(supervised_model.head.parameters(), lr=0.0003, weight_decay=0.0001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(supervised_model, train_dataloader_75, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "pretrained_model = TPN()\n",
    "pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Create the supervised model by adjusting the pre-trained model\n",
    "supervised_model = SupervisedTPN(pretrained_model, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.078.. Test Loss: 1.375.. Test Accuracy: 0.476.. Test F1 Score: 0.464\n",
      "Epoch: 2/30.. Train Loss: 0.711.. Test Loss: 1.306.. Test Accuracy: 0.570.. Test F1 Score: 0.548\n",
      "Epoch: 3/30.. Train Loss: 0.648.. Test Loss: 1.384.. Test Accuracy: 0.553.. Test F1 Score: 0.538\n",
      "Epoch: 4/30.. Train Loss: 0.592.. Test Loss: 1.195.. Test Accuracy: 0.624.. Test F1 Score: 0.609\n",
      "Epoch: 5/30.. Train Loss: 0.582.. Test Loss: 1.276.. Test Accuracy: 0.598.. Test F1 Score: 0.586\n",
      "Epoch: 6/30.. Train Loss: 0.527.. Test Loss: 1.203.. Test Accuracy: 0.645.. Test F1 Score: 0.623\n",
      "Epoch: 7/30.. Train Loss: 0.564.. Test Loss: 1.212.. Test Accuracy: 0.613.. Test F1 Score: 0.602\n",
      "Epoch: 8/30.. Train Loss: 0.518.. Test Loss: 1.310.. Test Accuracy: 0.589.. Test F1 Score: 0.585\n",
      "Epoch: 9/30.. Train Loss: 0.506.. Test Loss: 1.154.. Test Accuracy: 0.653.. Test F1 Score: 0.641\n",
      "Epoch: 10/30.. Train Loss: 0.490.. Test Loss: 1.298.. Test Accuracy: 0.596.. Test F1 Score: 0.581\n",
      "Epoch: 11/30.. Train Loss: 0.513.. Test Loss: 1.302.. Test Accuracy: 0.624.. Test F1 Score: 0.611\n",
      "Epoch: 12/30.. Train Loss: 0.468.. Test Loss: 1.227.. Test Accuracy: 0.632.. Test F1 Score: 0.619\n",
      "Epoch: 13/30.. Train Loss: 0.459.. Test Loss: 1.368.. Test Accuracy: 0.602.. Test F1 Score: 0.586\n",
      "Epoch: 14/30.. Train Loss: 0.455.. Test Loss: 1.237.. Test Accuracy: 0.645.. Test F1 Score: 0.626\n",
      "Epoch: 15/30.. Train Loss: 0.432.. Test Loss: 1.201.. Test Accuracy: 0.647.. Test F1 Score: 0.630\n",
      "Epoch: 16/30.. Train Loss: 0.434.. Test Loss: 1.238.. Test Accuracy: 0.651.. Test F1 Score: 0.632\n",
      "Epoch: 17/30.. Train Loss: 0.429.. Test Loss: 1.240.. Test Accuracy: 0.603.. Test F1 Score: 0.598\n",
      "Epoch: 18/30.. Train Loss: 0.421.. Test Loss: 1.278.. Test Accuracy: 0.627.. Test F1 Score: 0.613\n",
      "Epoch: 19/30.. Train Loss: 0.419.. Test Loss: 1.347.. Test Accuracy: 0.651.. Test F1 Score: 0.627\n",
      "Epoch: 20/30.. Train Loss: 0.408.. Test Loss: 1.347.. Test Accuracy: 0.633.. Test F1 Score: 0.617\n",
      "Epoch: 21/30.. Train Loss: 0.404.. Test Loss: 1.302.. Test Accuracy: 0.620.. Test F1 Score: 0.612\n",
      "Epoch: 22/30.. Train Loss: 0.417.. Test Loss: 1.305.. Test Accuracy: 0.619.. Test F1 Score: 0.601\n",
      "Epoch: 23/30.. Train Loss: 0.396.. Test Loss: 1.403.. Test Accuracy: 0.573.. Test F1 Score: 0.554\n",
      "Epoch: 24/30.. Train Loss: 0.383.. Test Loss: 1.277.. Test Accuracy: 0.605.. Test F1 Score: 0.582\n",
      "Epoch: 25/30.. Train Loss: 0.397.. Test Loss: 1.326.. Test Accuracy: 0.596.. Test F1 Score: 0.577\n",
      "Epoch: 26/30.. Train Loss: 0.382.. Test Loss: 1.326.. Test Accuracy: 0.574.. Test F1 Score: 0.558\n",
      "Epoch: 27/30.. Train Loss: 0.373.. Test Loss: 1.718.. Test Accuracy: 0.555.. Test F1 Score: 0.511\n",
      "Epoch: 28/30.. Train Loss: 0.377.. Test Loss: 1.260.. Test Accuracy: 0.635.. Test F1 Score: 0.622\n",
      "Epoch: 29/30.. Train Loss: 0.371.. Test Loss: 1.534.. Test Accuracy: 0.547.. Test F1 Score: 0.531\n",
      "Epoch: 30/30.. Train Loss: 0.374.. Test Loss: 1.280.. Test Accuracy: 0.606.. Test F1 Score: 0.591\n"
     ]
    }
   ],
   "source": [
    "# prepare for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(supervised_model.head.parameters(), lr=0.0003, weight_decay=0.0001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(supervised_model, train_dataloader_50, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "pretrained_model = TPN()\n",
    "pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Create the supervised model by adjusting the pre-trained model\n",
    "supervised_model = SupervisedTPN(pretrained_model, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 0.948.. Test Loss: 1.677.. Test Accuracy: 0.502.. Test F1 Score: 0.479\n",
      "Epoch: 2/30.. Train Loss: 0.703.. Test Loss: 1.800.. Test Accuracy: 0.489.. Test F1 Score: 0.461\n",
      "Epoch: 3/30.. Train Loss: 0.445.. Test Loss: 1.800.. Test Accuracy: 0.485.. Test F1 Score: 0.466\n",
      "Epoch: 4/30.. Train Loss: 0.409.. Test Loss: 1.747.. Test Accuracy: 0.498.. Test F1 Score: 0.477\n",
      "Epoch: 5/30.. Train Loss: 0.401.. Test Loss: 1.846.. Test Accuracy: 0.492.. Test F1 Score: 0.469\n",
      "Epoch: 6/30.. Train Loss: 0.400.. Test Loss: 1.845.. Test Accuracy: 0.495.. Test F1 Score: 0.473\n",
      "Epoch: 7/30.. Train Loss: 0.381.. Test Loss: 1.987.. Test Accuracy: 0.466.. Test F1 Score: 0.440\n",
      "Epoch: 8/30.. Train Loss: 0.363.. Test Loss: 2.051.. Test Accuracy: 0.491.. Test F1 Score: 0.473\n",
      "Epoch: 9/30.. Train Loss: 0.320.. Test Loss: 2.251.. Test Accuracy: 0.472.. Test F1 Score: 0.445\n",
      "Epoch: 10/30.. Train Loss: 0.324.. Test Loss: 1.978.. Test Accuracy: 0.494.. Test F1 Score: 0.473\n",
      "Epoch: 11/30.. Train Loss: 0.315.. Test Loss: 2.137.. Test Accuracy: 0.474.. Test F1 Score: 0.447\n",
      "Epoch: 12/30.. Train Loss: 0.309.. Test Loss: 2.072.. Test Accuracy: 0.475.. Test F1 Score: 0.449\n",
      "Epoch: 13/30.. Train Loss: 0.354.. Test Loss: 1.898.. Test Accuracy: 0.518.. Test F1 Score: 0.506\n",
      "Epoch: 14/30.. Train Loss: 0.317.. Test Loss: 2.188.. Test Accuracy: 0.480.. Test F1 Score: 0.455\n",
      "Epoch: 15/30.. Train Loss: 0.297.. Test Loss: 2.173.. Test Accuracy: 0.498.. Test F1 Score: 0.467\n",
      "Epoch: 16/30.. Train Loss: 0.321.. Test Loss: 2.143.. Test Accuracy: 0.494.. Test F1 Score: 0.482\n",
      "Epoch: 17/30.. Train Loss: 0.287.. Test Loss: 2.165.. Test Accuracy: 0.505.. Test F1 Score: 0.487\n",
      "Epoch: 18/30.. Train Loss: 0.325.. Test Loss: 2.128.. Test Accuracy: 0.472.. Test F1 Score: 0.460\n",
      "Epoch: 19/30.. Train Loss: 0.292.. Test Loss: 2.116.. Test Accuracy: 0.466.. Test F1 Score: 0.444\n",
      "Epoch: 20/30.. Train Loss: 0.248.. Test Loss: 2.231.. Test Accuracy: 0.483.. Test F1 Score: 0.459\n",
      "Epoch: 21/30.. Train Loss: 0.262.. Test Loss: 2.809.. Test Accuracy: 0.444.. Test F1 Score: 0.418\n",
      "Epoch: 22/30.. Train Loss: 0.258.. Test Loss: 2.256.. Test Accuracy: 0.480.. Test F1 Score: 0.460\n",
      "Epoch: 23/30.. Train Loss: 0.262.. Test Loss: 2.135.. Test Accuracy: 0.492.. Test F1 Score: 0.475\n",
      "Epoch: 24/30.. Train Loss: 0.255.. Test Loss: 2.275.. Test Accuracy: 0.486.. Test F1 Score: 0.463\n",
      "Epoch: 25/30.. Train Loss: 0.255.. Test Loss: 2.144.. Test Accuracy: 0.530.. Test F1 Score: 0.500\n",
      "Epoch: 26/30.. Train Loss: 0.253.. Test Loss: 2.478.. Test Accuracy: 0.471.. Test F1 Score: 0.453\n",
      "Epoch: 27/30.. Train Loss: 0.243.. Test Loss: 2.209.. Test Accuracy: 0.480.. Test F1 Score: 0.469\n",
      "Epoch: 28/30.. Train Loss: 0.275.. Test Loss: 2.201.. Test Accuracy: 0.494.. Test F1 Score: 0.482\n",
      "Epoch: 29/30.. Train Loss: 0.261.. Test Loss: 1.979.. Test Accuracy: 0.541.. Test F1 Score: 0.530\n",
      "Epoch: 30/30.. Train Loss: 0.229.. Test Loss: 2.268.. Test Accuracy: 0.504.. Test F1 Score: 0.485\n"
     ]
    }
   ],
   "source": [
    "# prepare for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(supervised_model.head.parameters(), lr=0.0003, weight_decay=0.0001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(supervised_model, train_dataloader_25, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "pretrained_model = TPN()\n",
    "pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Create the supervised model by adjusting the pre-trained model\n",
    "supervised_model = SupervisedTPN(pretrained_model, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.179.. Test Loss: 1.647.. Test Accuracy: 0.509.. Test F1 Score: 0.478\n",
      "Epoch: 2/30.. Train Loss: 0.564.. Test Loss: 1.703.. Test Accuracy: 0.456.. Test F1 Score: 0.427\n",
      "Epoch: 3/30.. Train Loss: 0.471.. Test Loss: 1.640.. Test Accuracy: 0.508.. Test F1 Score: 0.492\n",
      "Epoch: 4/30.. Train Loss: 0.486.. Test Loss: 1.913.. Test Accuracy: 0.426.. Test F1 Score: 0.405\n",
      "Epoch: 5/30.. Train Loss: 0.358.. Test Loss: 1.876.. Test Accuracy: 0.442.. Test F1 Score: 0.428\n",
      "Epoch: 6/30.. Train Loss: 0.306.. Test Loss: 1.735.. Test Accuracy: 0.475.. Test F1 Score: 0.462\n",
      "Epoch: 7/30.. Train Loss: 0.277.. Test Loss: 1.993.. Test Accuracy: 0.425.. Test F1 Score: 0.409\n",
      "Epoch: 8/30.. Train Loss: 0.260.. Test Loss: 2.002.. Test Accuracy: 0.445.. Test F1 Score: 0.430\n",
      "Epoch: 9/30.. Train Loss: 0.239.. Test Loss: 2.071.. Test Accuracy: 0.444.. Test F1 Score: 0.427\n",
      "Epoch: 10/30.. Train Loss: 0.220.. Test Loss: 2.046.. Test Accuracy: 0.429.. Test F1 Score: 0.409\n",
      "Epoch: 11/30.. Train Loss: 0.218.. Test Loss: 2.152.. Test Accuracy: 0.444.. Test F1 Score: 0.431\n",
      "Epoch: 12/30.. Train Loss: 0.194.. Test Loss: 2.074.. Test Accuracy: 0.432.. Test F1 Score: 0.417\n",
      "Epoch: 13/30.. Train Loss: 0.234.. Test Loss: 1.983.. Test Accuracy: 0.481.. Test F1 Score: 0.473\n",
      "Epoch: 14/30.. Train Loss: 0.193.. Test Loss: 2.368.. Test Accuracy: 0.425.. Test F1 Score: 0.402\n",
      "Epoch: 15/30.. Train Loss: 0.173.. Test Loss: 2.218.. Test Accuracy: 0.439.. Test F1 Score: 0.420\n",
      "Epoch: 16/30.. Train Loss: 0.178.. Test Loss: 2.365.. Test Accuracy: 0.434.. Test F1 Score: 0.410\n",
      "Epoch: 17/30.. Train Loss: 0.189.. Test Loss: 2.146.. Test Accuracy: 0.447.. Test F1 Score: 0.446\n",
      "Epoch: 18/30.. Train Loss: 0.163.. Test Loss: 2.358.. Test Accuracy: 0.440.. Test F1 Score: 0.430\n",
      "Epoch: 19/30.. Train Loss: 0.178.. Test Loss: 2.308.. Test Accuracy: 0.441.. Test F1 Score: 0.428\n",
      "Epoch: 20/30.. Train Loss: 0.156.. Test Loss: 2.822.. Test Accuracy: 0.415.. Test F1 Score: 0.397\n",
      "Epoch: 21/30.. Train Loss: 0.198.. Test Loss: 2.486.. Test Accuracy: 0.434.. Test F1 Score: 0.410\n",
      "Epoch: 22/30.. Train Loss: 0.262.. Test Loss: 2.610.. Test Accuracy: 0.414.. Test F1 Score: 0.392\n",
      "Epoch: 23/30.. Train Loss: 0.163.. Test Loss: 2.514.. Test Accuracy: 0.435.. Test F1 Score: 0.428\n",
      "Epoch: 24/30.. Train Loss: 0.186.. Test Loss: 2.180.. Test Accuracy: 0.467.. Test F1 Score: 0.461\n",
      "Epoch: 25/30.. Train Loss: 0.158.. Test Loss: 2.637.. Test Accuracy: 0.439.. Test F1 Score: 0.423\n",
      "Epoch: 26/30.. Train Loss: 0.175.. Test Loss: 2.972.. Test Accuracy: 0.434.. Test F1 Score: 0.413\n",
      "Epoch: 27/30.. Train Loss: 0.266.. Test Loss: 3.104.. Test Accuracy: 0.419.. Test F1 Score: 0.401\n",
      "Epoch: 28/30.. Train Loss: 0.175.. Test Loss: 2.533.. Test Accuracy: 0.436.. Test F1 Score: 0.437\n",
      "Epoch: 29/30.. Train Loss: 0.138.. Test Loss: 2.665.. Test Accuracy: 0.431.. Test F1 Score: 0.425\n",
      "Epoch: 30/30.. Train Loss: 0.114.. Test Loss: 2.467.. Test Accuracy: 0.443.. Test F1 Score: 0.441\n"
     ]
    }
   ],
   "source": [
    "# prepare for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(supervised_model.head.parameters(), lr=0.0003, weight_decay=0.0001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(supervised_model, train_dataloader_10, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune Last Conv Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedTPN(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_classes):\n",
    "        super(SupervisedTPN, self).__init__()\n",
    "        self.trunk = pretrained_model.trunk  # Use the trunk from the pretrained model\n",
    "\n",
    "        # Freeze all the trunk layers first\n",
    "        for param in self.trunk.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze the last convolutional layer\n",
    "        # Assuming the last conv layer is the third from the last in the trunk sequence\n",
    "        for param in self.trunk[-3].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(96, 1024),  # Adjusted to match the document's description\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, num_classes)  # Softmax applied externally during training\n",
    "        )\n",
    "        # No softmax here as it's included in nn.CrossEntropyLoss during training\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.trunk(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully-connected layer\n",
    "        output = self.head(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "pretrained_model = TPN()\n",
    "pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Create the supervised model by adjusting the pre-trained model\n",
    "supervised_model = SupervisedTPN(pretrained_model, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 0.925.. Test Loss: 1.127.. Test Accuracy: 0.663.. Test F1 Score: 0.650\n",
      "Epoch: 2/30.. Train Loss: 0.773.. Test Loss: 1.032.. Test Accuracy: 0.666.. Test F1 Score: 0.659\n",
      "Epoch: 3/30.. Train Loss: 0.729.. Test Loss: 1.111.. Test Accuracy: 0.665.. Test F1 Score: 0.655\n",
      "Epoch: 4/30.. Train Loss: 0.702.. Test Loss: 1.061.. Test Accuracy: 0.659.. Test F1 Score: 0.664\n",
      "Epoch: 5/30.. Train Loss: 0.683.. Test Loss: 1.008.. Test Accuracy: 0.675.. Test F1 Score: 0.666\n",
      "Epoch: 6/30.. Train Loss: 0.661.. Test Loss: 1.050.. Test Accuracy: 0.681.. Test F1 Score: 0.670\n",
      "Epoch: 7/30.. Train Loss: 0.649.. Test Loss: 1.042.. Test Accuracy: 0.676.. Test F1 Score: 0.666\n",
      "Epoch: 8/30.. Train Loss: 0.631.. Test Loss: 1.055.. Test Accuracy: 0.672.. Test F1 Score: 0.673\n",
      "Epoch: 9/30.. Train Loss: 0.625.. Test Loss: 1.048.. Test Accuracy: 0.669.. Test F1 Score: 0.653\n",
      "Epoch: 10/30.. Train Loss: 0.616.. Test Loss: 1.011.. Test Accuracy: 0.667.. Test F1 Score: 0.663\n",
      "Epoch: 11/30.. Train Loss: 0.607.. Test Loss: 1.037.. Test Accuracy: 0.676.. Test F1 Score: 0.666\n",
      "Epoch: 12/30.. Train Loss: 0.602.. Test Loss: 1.059.. Test Accuracy: 0.683.. Test F1 Score: 0.675\n",
      "Epoch: 13/30.. Train Loss: 0.597.. Test Loss: 1.056.. Test Accuracy: 0.639.. Test F1 Score: 0.634\n",
      "Epoch: 14/30.. Train Loss: 0.594.. Test Loss: 1.057.. Test Accuracy: 0.636.. Test F1 Score: 0.629\n",
      "Epoch: 15/30.. Train Loss: 0.587.. Test Loss: 1.040.. Test Accuracy: 0.695.. Test F1 Score: 0.686\n",
      "Epoch: 16/30.. Train Loss: 0.582.. Test Loss: 1.035.. Test Accuracy: 0.696.. Test F1 Score: 0.690\n",
      "Epoch: 17/30.. Train Loss: 0.582.. Test Loss: 1.060.. Test Accuracy: 0.679.. Test F1 Score: 0.670\n",
      "Epoch: 18/30.. Train Loss: 0.579.. Test Loss: 1.049.. Test Accuracy: 0.664.. Test F1 Score: 0.656\n",
      "Epoch: 19/30.. Train Loss: 0.573.. Test Loss: 1.112.. Test Accuracy: 0.679.. Test F1 Score: 0.671\n",
      "Epoch: 20/30.. Train Loss: 0.572.. Test Loss: 1.078.. Test Accuracy: 0.682.. Test F1 Score: 0.673\n",
      "Epoch: 21/30.. Train Loss: 0.568.. Test Loss: 1.122.. Test Accuracy: 0.680.. Test F1 Score: 0.678\n",
      "Epoch: 22/30.. Train Loss: 0.565.. Test Loss: 1.055.. Test Accuracy: 0.637.. Test F1 Score: 0.628\n",
      "Epoch: 23/30.. Train Loss: 0.566.. Test Loss: 1.119.. Test Accuracy: 0.676.. Test F1 Score: 0.667\n",
      "Epoch: 24/30.. Train Loss: 0.561.. Test Loss: 1.080.. Test Accuracy: 0.674.. Test F1 Score: 0.671\n",
      "Epoch: 25/30.. Train Loss: 0.558.. Test Loss: 1.085.. Test Accuracy: 0.679.. Test F1 Score: 0.672\n",
      "Epoch: 26/30.. Train Loss: 0.552.. Test Loss: 1.114.. Test Accuracy: 0.636.. Test F1 Score: 0.628\n",
      "Epoch: 27/30.. Train Loss: 0.555.. Test Loss: 1.068.. Test Accuracy: 0.687.. Test F1 Score: 0.677\n",
      "Epoch: 28/30.. Train Loss: 0.552.. Test Loss: 1.149.. Test Accuracy: 0.677.. Test F1 Score: 0.671\n",
      "Epoch: 29/30.. Train Loss: 0.549.. Test Loss: 1.164.. Test Accuracy: 0.625.. Test F1 Score: 0.624\n",
      "Epoch: 30/30.. Train Loss: 0.549.. Test Loss: 1.109.. Test Accuracy: 0.663.. Test F1 Score: 0.658\n"
     ]
    }
   ],
   "source": [
    "# prepare for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(supervised_model.parameters(), lr=0.0003, weight_decay=0.0001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(supervised_model, train_dataloader, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "pretrained_model = TPN()\n",
    "pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Create the supervised model by adjusting the pre-trained model\n",
    "supervised_model = SupervisedTPN(pretrained_model, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 0.983.. Test Loss: 1.446.. Test Accuracy: 0.527.. Test F1 Score: 0.505\n",
      "Epoch: 2/30.. Train Loss: 0.753.. Test Loss: 1.481.. Test Accuracy: 0.529.. Test F1 Score: 0.508\n",
      "Epoch: 3/30.. Train Loss: 0.673.. Test Loss: 1.549.. Test Accuracy: 0.593.. Test F1 Score: 0.556\n",
      "Epoch: 4/30.. Train Loss: 0.651.. Test Loss: 1.490.. Test Accuracy: 0.591.. Test F1 Score: 0.564\n",
      "Epoch: 5/30.. Train Loss: 0.617.. Test Loss: 1.410.. Test Accuracy: 0.581.. Test F1 Score: 0.567\n",
      "Epoch: 6/30.. Train Loss: 0.595.. Test Loss: 1.772.. Test Accuracy: 0.595.. Test F1 Score: 0.562\n",
      "Epoch: 7/30.. Train Loss: 0.604.. Test Loss: 1.589.. Test Accuracy: 0.606.. Test F1 Score: 0.586\n",
      "Epoch: 8/30.. Train Loss: 0.570.. Test Loss: 1.502.. Test Accuracy: 0.603.. Test F1 Score: 0.583\n",
      "Epoch: 9/30.. Train Loss: 0.555.. Test Loss: 1.653.. Test Accuracy: 0.599.. Test F1 Score: 0.576\n",
      "Epoch: 10/30.. Train Loss: 0.537.. Test Loss: 1.760.. Test Accuracy: 0.588.. Test F1 Score: 0.560\n",
      "Epoch: 11/30.. Train Loss: 0.516.. Test Loss: 1.578.. Test Accuracy: 0.590.. Test F1 Score: 0.574\n",
      "Epoch: 12/30.. Train Loss: 0.530.. Test Loss: 1.526.. Test Accuracy: 0.605.. Test F1 Score: 0.588\n",
      "Epoch: 13/30.. Train Loss: 0.504.. Test Loss: 1.625.. Test Accuracy: 0.593.. Test F1 Score: 0.564\n",
      "Epoch: 14/30.. Train Loss: 0.496.. Test Loss: 1.633.. Test Accuracy: 0.604.. Test F1 Score: 0.581\n",
      "Epoch: 15/30.. Train Loss: 0.492.. Test Loss: 1.712.. Test Accuracy: 0.607.. Test F1 Score: 0.581\n",
      "Epoch: 16/30.. Train Loss: 0.479.. Test Loss: 1.531.. Test Accuracy: 0.596.. Test F1 Score: 0.574\n",
      "Epoch: 17/30.. Train Loss: 0.468.. Test Loss: 1.718.. Test Accuracy: 0.592.. Test F1 Score: 0.569\n",
      "Epoch: 18/30.. Train Loss: 0.460.. Test Loss: 1.730.. Test Accuracy: 0.604.. Test F1 Score: 0.580\n",
      "Epoch: 19/30.. Train Loss: 0.451.. Test Loss: 1.645.. Test Accuracy: 0.599.. Test F1 Score: 0.574\n",
      "Epoch: 20/30.. Train Loss: 0.450.. Test Loss: 1.641.. Test Accuracy: 0.594.. Test F1 Score: 0.570\n",
      "Epoch: 21/30.. Train Loss: 0.448.. Test Loss: 1.549.. Test Accuracy: 0.633.. Test F1 Score: 0.611\n",
      "Epoch: 22/30.. Train Loss: 0.442.. Test Loss: 1.683.. Test Accuracy: 0.625.. Test F1 Score: 0.596\n",
      "Epoch: 23/30.. Train Loss: 0.434.. Test Loss: 1.675.. Test Accuracy: 0.613.. Test F1 Score: 0.585\n",
      "Epoch: 24/30.. Train Loss: 0.430.. Test Loss: 1.718.. Test Accuracy: 0.577.. Test F1 Score: 0.561\n",
      "Epoch: 25/30.. Train Loss: 0.427.. Test Loss: 1.688.. Test Accuracy: 0.618.. Test F1 Score: 0.590\n",
      "Epoch: 26/30.. Train Loss: 0.428.. Test Loss: 1.623.. Test Accuracy: 0.614.. Test F1 Score: 0.588\n",
      "Epoch: 27/30.. Train Loss: 0.424.. Test Loss: 1.821.. Test Accuracy: 0.603.. Test F1 Score: 0.578\n",
      "Epoch: 28/30.. Train Loss: 0.414.. Test Loss: 1.731.. Test Accuracy: 0.620.. Test F1 Score: 0.591\n",
      "Epoch: 29/30.. Train Loss: 0.423.. Test Loss: 1.858.. Test Accuracy: 0.607.. Test F1 Score: 0.577\n",
      "Epoch: 30/30.. Train Loss: 0.403.. Test Loss: 1.788.. Test Accuracy: 0.597.. Test F1 Score: 0.571\n"
     ]
    }
   ],
   "source": [
    "# prepare for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(supervised_model.parameters(), lr=0.0003, weight_decay=0.0001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_75, test_losses_75, test_accuracies_75, test_f1_scores_75 = train_and_test(supervised_model, train_dataloader_75, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "pretrained_model = TPN()\n",
    "pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Create the supervised model by adjusting the pre-trained model\n",
    "supervised_model = SupervisedTPN(pretrained_model, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 0.980.. Test Loss: 1.272.. Test Accuracy: 0.560.. Test F1 Score: 0.535\n",
      "Epoch: 2/30.. Train Loss: 0.706.. Test Loss: 1.243.. Test Accuracy: 0.619.. Test F1 Score: 0.594\n",
      "Epoch: 3/30.. Train Loss: 0.646.. Test Loss: 1.436.. Test Accuracy: 0.574.. Test F1 Score: 0.549\n",
      "Epoch: 4/30.. Train Loss: 0.608.. Test Loss: 1.207.. Test Accuracy: 0.632.. Test F1 Score: 0.608\n",
      "Epoch: 5/30.. Train Loss: 0.579.. Test Loss: 1.276.. Test Accuracy: 0.593.. Test F1 Score: 0.582\n",
      "Epoch: 6/30.. Train Loss: 0.567.. Test Loss: 1.131.. Test Accuracy: 0.638.. Test F1 Score: 0.621\n",
      "Epoch: 7/30.. Train Loss: 0.539.. Test Loss: 1.174.. Test Accuracy: 0.675.. Test F1 Score: 0.651\n",
      "Epoch: 8/30.. Train Loss: 0.526.. Test Loss: 1.235.. Test Accuracy: 0.645.. Test F1 Score: 0.628\n",
      "Epoch: 9/30.. Train Loss: 0.509.. Test Loss: 1.183.. Test Accuracy: 0.648.. Test F1 Score: 0.633\n",
      "Epoch: 10/30.. Train Loss: 0.492.. Test Loss: 1.181.. Test Accuracy: 0.605.. Test F1 Score: 0.587\n",
      "Epoch: 11/30.. Train Loss: 0.494.. Test Loss: 1.179.. Test Accuracy: 0.671.. Test F1 Score: 0.647\n",
      "Epoch: 12/30.. Train Loss: 0.469.. Test Loss: 1.181.. Test Accuracy: 0.651.. Test F1 Score: 0.632\n",
      "Epoch: 13/30.. Train Loss: 0.454.. Test Loss: 1.172.. Test Accuracy: 0.656.. Test F1 Score: 0.637\n",
      "Epoch: 14/30.. Train Loss: 0.466.. Test Loss: 1.204.. Test Accuracy: 0.647.. Test F1 Score: 0.630\n",
      "Epoch: 15/30.. Train Loss: 0.459.. Test Loss: 1.213.. Test Accuracy: 0.659.. Test F1 Score: 0.641\n",
      "Epoch: 16/30.. Train Loss: 0.445.. Test Loss: 1.186.. Test Accuracy: 0.656.. Test F1 Score: 0.639\n",
      "Epoch: 17/30.. Train Loss: 0.427.. Test Loss: 1.175.. Test Accuracy: 0.667.. Test F1 Score: 0.648\n",
      "Epoch: 18/30.. Train Loss: 0.442.. Test Loss: 1.166.. Test Accuracy: 0.656.. Test F1 Score: 0.640\n",
      "Epoch: 19/30.. Train Loss: 0.435.. Test Loss: 1.244.. Test Accuracy: 0.655.. Test F1 Score: 0.639\n",
      "Epoch: 20/30.. Train Loss: 0.419.. Test Loss: 1.228.. Test Accuracy: 0.641.. Test F1 Score: 0.628\n",
      "Epoch: 21/30.. Train Loss: 0.405.. Test Loss: 1.323.. Test Accuracy: 0.598.. Test F1 Score: 0.571\n",
      "Epoch: 22/30.. Train Loss: 0.408.. Test Loss: 1.168.. Test Accuracy: 0.650.. Test F1 Score: 0.637\n",
      "Epoch: 23/30.. Train Loss: 0.394.. Test Loss: 1.286.. Test Accuracy: 0.598.. Test F1 Score: 0.579\n",
      "Epoch: 24/30.. Train Loss: 0.397.. Test Loss: 1.290.. Test Accuracy: 0.578.. Test F1 Score: 0.566\n",
      "Epoch: 25/30.. Train Loss: 0.395.. Test Loss: 1.303.. Test Accuracy: 0.659.. Test F1 Score: 0.638\n",
      "Epoch: 26/30.. Train Loss: 0.404.. Test Loss: 1.367.. Test Accuracy: 0.607.. Test F1 Score: 0.589\n",
      "Epoch: 27/30.. Train Loss: 0.389.. Test Loss: 1.557.. Test Accuracy: 0.583.. Test F1 Score: 0.567\n",
      "Epoch: 28/30.. Train Loss: 0.388.. Test Loss: 1.317.. Test Accuracy: 0.640.. Test F1 Score: 0.625\n",
      "Epoch: 29/30.. Train Loss: 0.380.. Test Loss: 1.441.. Test Accuracy: 0.597.. Test F1 Score: 0.568\n",
      "Epoch: 30/30.. Train Loss: 0.360.. Test Loss: 1.315.. Test Accuracy: 0.614.. Test F1 Score: 0.600\n"
     ]
    }
   ],
   "source": [
    "# prepare for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(supervised_model.parameters(), lr=0.0003, weight_decay=0.0001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_50, test_losses_50, test_accuracies_50, test_f1_scores_50 = train_and_test(supervised_model, train_dataloader_50, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "pretrained_model = TPN()\n",
    "pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Create the supervised model by adjusting the pre-trained model\n",
    "supervised_model = SupervisedTPN(pretrained_model, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.113.. Test Loss: 1.681.. Test Accuracy: 0.489.. Test F1 Score: 0.455\n",
      "Epoch: 2/30.. Train Loss: 0.538.. Test Loss: 1.733.. Test Accuracy: 0.441.. Test F1 Score: 0.423\n",
      "Epoch: 3/30.. Train Loss: 0.482.. Test Loss: 1.781.. Test Accuracy: 0.484.. Test F1 Score: 0.451\n",
      "Epoch: 4/30.. Train Loss: 0.438.. Test Loss: 1.933.. Test Accuracy: 0.452.. Test F1 Score: 0.425\n",
      "Epoch: 5/30.. Train Loss: 0.427.. Test Loss: 1.888.. Test Accuracy: 0.457.. Test F1 Score: 0.428\n",
      "Epoch: 6/30.. Train Loss: 0.442.. Test Loss: 1.805.. Test Accuracy: 0.489.. Test F1 Score: 0.468\n",
      "Epoch: 7/30.. Train Loss: 0.551.. Test Loss: 1.935.. Test Accuracy: 0.474.. Test F1 Score: 0.443\n",
      "Epoch: 8/30.. Train Loss: 0.374.. Test Loss: 1.691.. Test Accuracy: 0.521.. Test F1 Score: 0.507\n",
      "Epoch: 9/30.. Train Loss: 0.362.. Test Loss: 2.104.. Test Accuracy: 0.440.. Test F1 Score: 0.407\n",
      "Epoch: 10/30.. Train Loss: 0.320.. Test Loss: 1.791.. Test Accuracy: 0.489.. Test F1 Score: 0.462\n",
      "Epoch: 11/30.. Train Loss: 0.316.. Test Loss: 1.952.. Test Accuracy: 0.483.. Test F1 Score: 0.464\n",
      "Epoch: 12/30.. Train Loss: 0.305.. Test Loss: 1.937.. Test Accuracy: 0.472.. Test F1 Score: 0.451\n",
      "Epoch: 13/30.. Train Loss: 0.307.. Test Loss: 1.885.. Test Accuracy: 0.488.. Test F1 Score: 0.467\n",
      "Epoch: 14/30.. Train Loss: 0.302.. Test Loss: 1.823.. Test Accuracy: 0.486.. Test F1 Score: 0.469\n",
      "Epoch: 15/30.. Train Loss: 0.327.. Test Loss: 2.089.. Test Accuracy: 0.530.. Test F1 Score: 0.520\n",
      "Epoch: 16/30.. Train Loss: 0.365.. Test Loss: 2.315.. Test Accuracy: 0.451.. Test F1 Score: 0.420\n",
      "Epoch: 17/30.. Train Loss: 0.328.. Test Loss: 1.989.. Test Accuracy: 0.487.. Test F1 Score: 0.480\n",
      "Epoch: 18/30.. Train Loss: 0.324.. Test Loss: 2.454.. Test Accuracy: 0.476.. Test F1 Score: 0.447\n",
      "Epoch: 19/30.. Train Loss: 0.277.. Test Loss: 2.097.. Test Accuracy: 0.465.. Test F1 Score: 0.450\n",
      "Epoch: 20/30.. Train Loss: 0.311.. Test Loss: 1.956.. Test Accuracy: 0.493.. Test F1 Score: 0.480\n",
      "Epoch: 21/30.. Train Loss: 0.254.. Test Loss: 1.840.. Test Accuracy: 0.519.. Test F1 Score: 0.515\n",
      "Epoch: 22/30.. Train Loss: 0.272.. Test Loss: 2.042.. Test Accuracy: 0.500.. Test F1 Score: 0.474\n",
      "Epoch: 23/30.. Train Loss: 0.256.. Test Loss: 2.068.. Test Accuracy: 0.490.. Test F1 Score: 0.470\n",
      "Epoch: 24/30.. Train Loss: 0.284.. Test Loss: 1.947.. Test Accuracy: 0.514.. Test F1 Score: 0.496\n",
      "Epoch: 25/30.. Train Loss: 0.240.. Test Loss: 2.000.. Test Accuracy: 0.502.. Test F1 Score: 0.479\n",
      "Epoch: 26/30.. Train Loss: 0.237.. Test Loss: 2.047.. Test Accuracy: 0.505.. Test F1 Score: 0.489\n",
      "Epoch: 27/30.. Train Loss: 0.257.. Test Loss: 2.058.. Test Accuracy: 0.486.. Test F1 Score: 0.467\n",
      "Epoch: 28/30.. Train Loss: 0.236.. Test Loss: 1.797.. Test Accuracy: 0.529.. Test F1 Score: 0.520\n",
      "Epoch: 29/30.. Train Loss: 0.281.. Test Loss: 2.056.. Test Accuracy: 0.494.. Test F1 Score: 0.482\n",
      "Epoch: 30/30.. Train Loss: 0.247.. Test Loss: 2.074.. Test Accuracy: 0.518.. Test F1 Score: 0.497\n"
     ]
    }
   ],
   "source": [
    "# prepare for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(supervised_model.parameters(), lr=0.0003, weight_decay=0.0001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_25, test_losses_25, test_accuracies_25, test_f1_scores_25 = train_and_test(supervised_model, train_dataloader_25, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "pretrained_model = TPN()\n",
    "pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Create the supervised model by adjusting the pre-trained model\n",
    "supervised_model = SupervisedTPN(pretrained_model, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.496.. Test Loss: 1.953.. Test Accuracy: 0.349.. Test F1 Score: 0.308\n",
      "Epoch: 2/30.. Train Loss: 0.623.. Test Loss: 1.813.. Test Accuracy: 0.426.. Test F1 Score: 0.410\n",
      "Epoch: 3/30.. Train Loss: 0.475.. Test Loss: 1.804.. Test Accuracy: 0.388.. Test F1 Score: 0.355\n",
      "Epoch: 4/30.. Train Loss: 0.381.. Test Loss: 1.914.. Test Accuracy: 0.411.. Test F1 Score: 0.380\n",
      "Epoch: 5/30.. Train Loss: 0.346.. Test Loss: 1.978.. Test Accuracy: 0.410.. Test F1 Score: 0.382\n",
      "Epoch: 6/30.. Train Loss: 0.271.. Test Loss: 1.825.. Test Accuracy: 0.409.. Test F1 Score: 0.384\n",
      "Epoch: 7/30.. Train Loss: 0.275.. Test Loss: 2.026.. Test Accuracy: 0.417.. Test F1 Score: 0.400\n",
      "Epoch: 8/30.. Train Loss: 0.262.. Test Loss: 2.058.. Test Accuracy: 0.404.. Test F1 Score: 0.373\n",
      "Epoch: 9/30.. Train Loss: 0.230.. Test Loss: 2.166.. Test Accuracy: 0.422.. Test F1 Score: 0.391\n",
      "Epoch: 10/30.. Train Loss: 0.252.. Test Loss: 2.111.. Test Accuracy: 0.407.. Test F1 Score: 0.375\n",
      "Epoch: 11/30.. Train Loss: 0.215.. Test Loss: 2.069.. Test Accuracy: 0.428.. Test F1 Score: 0.411\n",
      "Epoch: 12/30.. Train Loss: 0.198.. Test Loss: 2.013.. Test Accuracy: 0.418.. Test F1 Score: 0.410\n",
      "Epoch: 13/30.. Train Loss: 0.203.. Test Loss: 2.550.. Test Accuracy: 0.401.. Test F1 Score: 0.379\n",
      "Epoch: 14/30.. Train Loss: 0.223.. Test Loss: 2.009.. Test Accuracy: 0.479.. Test F1 Score: 0.471\n",
      "Epoch: 15/30.. Train Loss: 0.228.. Test Loss: 2.302.. Test Accuracy: 0.435.. Test F1 Score: 0.421\n",
      "Epoch: 16/30.. Train Loss: 0.180.. Test Loss: 2.615.. Test Accuracy: 0.409.. Test F1 Score: 0.380\n",
      "Epoch: 17/30.. Train Loss: 0.182.. Test Loss: 2.253.. Test Accuracy: 0.422.. Test F1 Score: 0.406\n",
      "Epoch: 18/30.. Train Loss: 0.204.. Test Loss: 2.259.. Test Accuracy: 0.423.. Test F1 Score: 0.420\n",
      "Epoch: 19/30.. Train Loss: 0.297.. Test Loss: 2.577.. Test Accuracy: 0.414.. Test F1 Score: 0.391\n",
      "Epoch: 20/30.. Train Loss: 0.165.. Test Loss: 2.556.. Test Accuracy: 0.417.. Test F1 Score: 0.403\n",
      "Epoch: 21/30.. Train Loss: 0.168.. Test Loss: 2.416.. Test Accuracy: 0.425.. Test F1 Score: 0.408\n",
      "Epoch: 22/30.. Train Loss: 0.162.. Test Loss: 2.462.. Test Accuracy: 0.418.. Test F1 Score: 0.404\n",
      "Epoch: 23/30.. Train Loss: 0.169.. Test Loss: 2.503.. Test Accuracy: 0.430.. Test F1 Score: 0.424\n",
      "Epoch: 24/30.. Train Loss: 0.202.. Test Loss: 2.732.. Test Accuracy: 0.418.. Test F1 Score: 0.404\n",
      "Epoch: 25/30.. Train Loss: 0.129.. Test Loss: 2.557.. Test Accuracy: 0.424.. Test F1 Score: 0.416\n",
      "Epoch: 26/30.. Train Loss: 0.119.. Test Loss: 2.454.. Test Accuracy: 0.435.. Test F1 Score: 0.428\n",
      "Epoch: 27/30.. Train Loss: 0.133.. Test Loss: 2.622.. Test Accuracy: 0.406.. Test F1 Score: 0.401\n",
      "Epoch: 28/30.. Train Loss: 0.130.. Test Loss: 2.670.. Test Accuracy: 0.423.. Test F1 Score: 0.416\n",
      "Epoch: 29/30.. Train Loss: 0.142.. Test Loss: 2.869.. Test Accuracy: 0.411.. Test F1 Score: 0.392\n",
      "Epoch: 30/30.. Train Loss: 0.175.. Test Loss: 2.863.. Test Accuracy: 0.409.. Test F1 Score: 0.375\n"
     ]
    }
   ],
   "source": [
    "# prepare for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(supervised_model.parameters(), lr=0.0003, weight_decay=0.0001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_10, test_losses_10, test_accuracies_10, test_f1_scores_10 = train_and_test(supervised_model, train_dataloader_10, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RefuseAct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Window Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train window dataset (2 sec with 0% overlap): (22007, 100, 4)\n",
      "shape of test window dataset (2 sec with 0% overlap): (10000, 100, 4)\n"
     ]
    }
   ],
   "source": [
    "# windowing data\n",
    "sampling_rate = 50\n",
    "time_window = 2\n",
    "window_size = sampling_rate * time_window\n",
    "overlap_ratio = 0\n",
    "\n",
    "train_window_data, _, train_window_label = sliding_window_samples(train, window_size, overlap_ratio)\n",
    "print(f\"shape of train window dataset ({time_window} sec with {overlap_ratio}% overlap): {train_window_data.shape}\")\n",
    "\n",
    "test_window_data, _, test_window_label = sliding_window_samples(test, window_size, overlap_ratio)\n",
    "print(f\"shape of test window dataset ({time_window} sec with {overlap_ratio}% overlap): {test_window_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train is (22007, 100, 3)\n",
      "The shape of test is (10000, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# remove the subject column\n",
    "train_window_data = train_window_data[:, :, 1:]\n",
    "test_window_data = test_window_data[:, :, 1:]\n",
    "\n",
    "# print the shape of train and test\n",
    "print('The shape of train is {}'.format(train_window_data.shape))\n",
    "print('The shape of test is {}'.format(test_window_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train window dataset (2 sec with 0% overlap): (15534, 100, 4)\n",
      "The shape of train_75 is (15534, 100, 3)\n",
      "The length of train_75 label is 15534\n"
     ]
    }
   ],
   "source": [
    "train_window_data_75, _, train_window_label_75 = sliding_window_samples(train_75, window_size, overlap_ratio)\n",
    "print(f\"shape of train window dataset ({time_window} sec with {overlap_ratio}% overlap): {train_window_data_75.shape}\")\n",
    "\n",
    "# remove the subject column\n",
    "train_window_data_75 = train_window_data_75[:, :, 1:]\n",
    "\n",
    "print('The shape of train_75 is {}'.format(train_window_data_75.shape))\n",
    "print('The length of train_75 label is {}'.format(len(train_window_label_75)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train window dataset (2 sec with 0% overlap): (10991, 100, 4)\n",
      "The shape of train_50 is (10991, 100, 3)\n",
      "The length of train_50 label is 10991\n"
     ]
    }
   ],
   "source": [
    "train_window_data_50, _, train_window_label_50 = sliding_window_samples(train_50, window_size, overlap_ratio)\n",
    "print(f\"shape of train window dataset ({time_window} sec with {overlap_ratio}% overlap): {train_window_data_50.shape}\")\n",
    "\n",
    "# remove the subject column\n",
    "train_window_data_50 = train_window_data_50[:, :, 1:]\n",
    "\n",
    "print('The shape of train_50 is {}'.format(train_window_data_50.shape))\n",
    "print('The length of train_50 label is {}'.format(len(train_window_label_50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_25 is (4361, 100, 3)\n",
      "The length of train_25 label is 4361\n"
     ]
    }
   ],
   "source": [
    "train_window_data_25, _, train_window_label_25 = sliding_window_samples(train_25, window_size, overlap_ratio)\n",
    "# remove the subject column\n",
    "train_window_data_25 = train_window_data_25[:, :, 1:]\n",
    "\n",
    "print('The shape of train_25 is {}'.format(train_window_data_25.shape))\n",
    "print('The length of train_25 label is {}'.format(len(train_window_label_25)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_10 is (2124, 100, 3)\n",
      "The length of train_10 label is 2124\n"
     ]
    }
   ],
   "source": [
    "train_window_data_10, _, train_window_label_10 = sliding_window_samples(train_10, window_size, overlap_ratio)\n",
    "# remove the subject column\n",
    "train_window_data_10 = train_window_data_10[:, :, 1:]\n",
    "\n",
    "print('The shape of train_10 is {}'.format(train_window_data_10.shape))\n",
    "print('The length of train_10 label is {}'.format(len(train_window_label_10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataloader for train and test\n",
    "train_dataloader = generate_dataloader(train_window_data, train_window_label, batch_size)   \n",
    "test_dataloader = generate_dataloader(test_window_data, test_window_label, batch_size, is_shuffle=False)\n",
    "\n",
    "# generate dataloader for train and test in subject subsetting\n",
    "train_dataloader_75 = generate_dataloader(train_window_data_75, train_window_label_75, batch_size)\n",
    "train_dataloader_50 = generate_dataloader(train_window_data_50, train_window_label_50, batch_size)\n",
    "train_dataloader_25 = generate_dataloader(train_window_data_25, train_window_label_25, batch_size)\n",
    "train_dataloader_10 = generate_dataloader(train_window_data_10, train_window_label_10, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256 * 12, 128)  # Adjust the input features according to your final conv layer output\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, padding):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                               stride=stride, padding=0, dilation=dilation)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
    "                               stride=stride, padding=0, dilation=dilation)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "\n",
    "        # Adjusting the length of the residual to match the output\n",
    "        if out.size(2) != res.size(2):\n",
    "            desired_length = out.size(2)\n",
    "            res = res[:, :, :desired_length]\n",
    "\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size, dropout=0.2, num_classes=4):\n",
    "        super(TCN, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size + (dilation_size - 1))]\n",
    "\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(num_channels[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tcn(x)\n",
    "        x = F.avg_pool1d(x, x.size(2)).squeeze(2)  # Global Average Pooling\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.577.. Test Loss: 1.294.. Test Accuracy: 0.574.. Test F1 Score: 0.545\n",
      "Epoch: 2/30.. Train Loss: 1.224.. Test Loss: 1.173.. Test Accuracy: 0.617.. Test F1 Score: 0.581\n",
      "Epoch: 3/30.. Train Loss: 1.123.. Test Loss: 1.130.. Test Accuracy: 0.635.. Test F1 Score: 0.622\n",
      "Epoch: 4/30.. Train Loss: 1.070.. Test Loss: 1.123.. Test Accuracy: 0.642.. Test F1 Score: 0.639\n",
      "Epoch: 5/30.. Train Loss: 1.038.. Test Loss: 1.090.. Test Accuracy: 0.649.. Test F1 Score: 0.632\n",
      "Epoch: 6/30.. Train Loss: 1.014.. Test Loss: 1.050.. Test Accuracy: 0.653.. Test F1 Score: 0.628\n",
      "Epoch: 7/30.. Train Loss: 0.993.. Test Loss: 1.064.. Test Accuracy: 0.654.. Test F1 Score: 0.641\n",
      "Epoch: 8/30.. Train Loss: 0.980.. Test Loss: 1.072.. Test Accuracy: 0.675.. Test F1 Score: 0.663\n",
      "Epoch: 9/30.. Train Loss: 0.968.. Test Loss: 1.044.. Test Accuracy: 0.669.. Test F1 Score: 0.665\n",
      "Epoch: 10/30.. Train Loss: 0.959.. Test Loss: 1.059.. Test Accuracy: 0.627.. Test F1 Score: 0.627\n",
      "Epoch: 11/30.. Train Loss: 0.947.. Test Loss: 1.048.. Test Accuracy: 0.652.. Test F1 Score: 0.658\n",
      "Epoch: 12/30.. Train Loss: 0.939.. Test Loss: 1.014.. Test Accuracy: 0.655.. Test F1 Score: 0.643\n",
      "Epoch: 13/30.. Train Loss: 0.934.. Test Loss: 1.020.. Test Accuracy: 0.663.. Test F1 Score: 0.645\n",
      "Epoch: 14/30.. Train Loss: 0.925.. Test Loss: 1.015.. Test Accuracy: 0.691.. Test F1 Score: 0.681\n",
      "Epoch: 15/30.. Train Loss: 0.919.. Test Loss: 1.064.. Test Accuracy: 0.661.. Test F1 Score: 0.671\n",
      "Epoch: 16/30.. Train Loss: 0.912.. Test Loss: 1.008.. Test Accuracy: 0.647.. Test F1 Score: 0.643\n",
      "Epoch: 17/30.. Train Loss: 0.911.. Test Loss: 1.033.. Test Accuracy: 0.687.. Test F1 Score: 0.682\n",
      "Epoch: 18/30.. Train Loss: 0.904.. Test Loss: 1.025.. Test Accuracy: 0.667.. Test F1 Score: 0.663\n",
      "Epoch: 19/30.. Train Loss: 0.900.. Test Loss: 1.013.. Test Accuracy: 0.649.. Test F1 Score: 0.653\n",
      "Epoch: 20/30.. Train Loss: 0.897.. Test Loss: 1.028.. Test Accuracy: 0.652.. Test F1 Score: 0.646\n",
      "Epoch: 21/30.. Train Loss: 0.892.. Test Loss: 0.997.. Test Accuracy: 0.654.. Test F1 Score: 0.645\n",
      "Epoch: 22/30.. Train Loss: 0.891.. Test Loss: 1.028.. Test Accuracy: 0.646.. Test F1 Score: 0.642\n",
      "Epoch: 23/30.. Train Loss: 0.888.. Test Loss: 1.012.. Test Accuracy: 0.676.. Test F1 Score: 0.670\n",
      "Epoch: 24/30.. Train Loss: 0.881.. Test Loss: 1.004.. Test Accuracy: 0.677.. Test F1 Score: 0.664\n",
      "Epoch: 25/30.. Train Loss: 0.879.. Test Loss: 1.043.. Test Accuracy: 0.647.. Test F1 Score: 0.654\n",
      "Epoch: 26/30.. Train Loss: 0.877.. Test Loss: 1.006.. Test Accuracy: 0.663.. Test F1 Score: 0.662\n",
      "Epoch: 27/30.. Train Loss: 0.876.. Test Loss: 1.019.. Test Accuracy: 0.686.. Test F1 Score: 0.674\n",
      "Epoch: 28/30.. Train Loss: 0.872.. Test Loss: 1.026.. Test Accuracy: 0.659.. Test F1 Score: 0.661\n",
      "Epoch: 29/30.. Train Loss: 0.872.. Test Loss: 1.004.. Test Accuracy: 0.657.. Test F1 Score: 0.643\n",
      "Epoch: 30/30.. Train Loss: 0.869.. Test Loss: 1.019.. Test Accuracy: 0.663.. Test F1 Score: 0.668\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_path = './models/cnn_feature_extractor_join_20231218-2006.pt'\n",
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc2.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(model, train_dataloader, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.716.. Test Loss: 1.438.. Test Accuracy: 0.546.. Test F1 Score: 0.487\n",
      "Epoch: 2/30.. Train Loss: 1.321.. Test Loss: 1.209.. Test Accuracy: 0.638.. Test F1 Score: 0.602\n",
      "Epoch: 3/30.. Train Loss: 1.200.. Test Loss: 1.179.. Test Accuracy: 0.636.. Test F1 Score: 0.620\n",
      "Epoch: 4/30.. Train Loss: 1.140.. Test Loss: 1.185.. Test Accuracy: 0.576.. Test F1 Score: 0.556\n",
      "Epoch: 5/30.. Train Loss: 1.104.. Test Loss: 1.117.. Test Accuracy: 0.652.. Test F1 Score: 0.619\n",
      "Epoch: 6/30.. Train Loss: 1.076.. Test Loss: 1.088.. Test Accuracy: 0.639.. Test F1 Score: 0.599\n",
      "Epoch: 7/30.. Train Loss: 1.056.. Test Loss: 1.111.. Test Accuracy: 0.633.. Test F1 Score: 0.631\n",
      "Epoch: 8/30.. Train Loss: 1.038.. Test Loss: 1.095.. Test Accuracy: 0.670.. Test F1 Score: 0.669\n",
      "Epoch: 9/30.. Train Loss: 1.024.. Test Loss: 1.069.. Test Accuracy: 0.666.. Test F1 Score: 0.651\n",
      "Epoch: 10/30.. Train Loss: 1.012.. Test Loss: 1.098.. Test Accuracy: 0.657.. Test F1 Score: 0.642\n",
      "Epoch: 11/30.. Train Loss: 1.003.. Test Loss: 1.053.. Test Accuracy: 0.662.. Test F1 Score: 0.632\n",
      "Epoch: 12/30.. Train Loss: 0.993.. Test Loss: 1.062.. Test Accuracy: 0.659.. Test F1 Score: 0.640\n",
      "Epoch: 13/30.. Train Loss: 0.986.. Test Loss: 1.058.. Test Accuracy: 0.660.. Test F1 Score: 0.631\n",
      "Epoch: 14/30.. Train Loss: 0.978.. Test Loss: 1.084.. Test Accuracy: 0.654.. Test F1 Score: 0.646\n",
      "Epoch: 15/30.. Train Loss: 0.969.. Test Loss: 1.071.. Test Accuracy: 0.662.. Test F1 Score: 0.663\n",
      "Epoch: 16/30.. Train Loss: 0.964.. Test Loss: 1.069.. Test Accuracy: 0.641.. Test F1 Score: 0.620\n",
      "Epoch: 17/30.. Train Loss: 0.957.. Test Loss: 1.046.. Test Accuracy: 0.680.. Test F1 Score: 0.662\n",
      "Epoch: 18/30.. Train Loss: 0.954.. Test Loss: 1.057.. Test Accuracy: 0.665.. Test F1 Score: 0.652\n",
      "Epoch: 19/30.. Train Loss: 0.948.. Test Loss: 1.099.. Test Accuracy: 0.645.. Test F1 Score: 0.623\n",
      "Epoch: 20/30.. Train Loss: 0.944.. Test Loss: 1.077.. Test Accuracy: 0.659.. Test F1 Score: 0.655\n",
      "Epoch: 21/30.. Train Loss: 0.939.. Test Loss: 1.055.. Test Accuracy: 0.667.. Test F1 Score: 0.654\n",
      "Epoch: 22/30.. Train Loss: 0.936.. Test Loss: 1.054.. Test Accuracy: 0.654.. Test F1 Score: 0.634\n",
      "Epoch: 23/30.. Train Loss: 0.933.. Test Loss: 1.073.. Test Accuracy: 0.654.. Test F1 Score: 0.651\n",
      "Epoch: 24/30.. Train Loss: 0.926.. Test Loss: 1.079.. Test Accuracy: 0.650.. Test F1 Score: 0.649\n",
      "Epoch: 25/30.. Train Loss: 0.924.. Test Loss: 1.057.. Test Accuracy: 0.653.. Test F1 Score: 0.628\n",
      "Epoch: 26/30.. Train Loss: 0.921.. Test Loss: 1.070.. Test Accuracy: 0.655.. Test F1 Score: 0.651\n",
      "Epoch: 27/30.. Train Loss: 0.918.. Test Loss: 1.047.. Test Accuracy: 0.642.. Test F1 Score: 0.637\n",
      "Epoch: 28/30.. Train Loss: 0.917.. Test Loss: 1.041.. Test Accuracy: 0.666.. Test F1 Score: 0.664\n",
      "Epoch: 29/30.. Train Loss: 0.913.. Test Loss: 1.084.. Test Accuracy: 0.661.. Test F1 Score: 0.640\n",
      "Epoch: 30/30.. Train Loss: 0.913.. Test Loss: 1.040.. Test Accuracy: 0.647.. Test F1 Score: 0.632\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc2.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(model, train_dataloader_75, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.738.. Test Loss: 1.493.. Test Accuracy: 0.575.. Test F1 Score: 0.530\n",
      "Epoch: 2/30.. Train Loss: 1.378.. Test Loss: 1.307.. Test Accuracy: 0.591.. Test F1 Score: 0.574\n",
      "Epoch: 3/30.. Train Loss: 1.237.. Test Loss: 1.233.. Test Accuracy: 0.544.. Test F1 Score: 0.507\n",
      "Epoch: 4/30.. Train Loss: 1.165.. Test Loss: 1.166.. Test Accuracy: 0.608.. Test F1 Score: 0.564\n",
      "Epoch: 5/30.. Train Loss: 1.114.. Test Loss: 1.145.. Test Accuracy: 0.595.. Test F1 Score: 0.579\n",
      "Epoch: 6/30.. Train Loss: 1.079.. Test Loss: 1.116.. Test Accuracy: 0.641.. Test F1 Score: 0.627\n",
      "Epoch: 7/30.. Train Loss: 1.055.. Test Loss: 1.085.. Test Accuracy: 0.636.. Test F1 Score: 0.606\n",
      "Epoch: 8/30.. Train Loss: 1.028.. Test Loss: 1.097.. Test Accuracy: 0.621.. Test F1 Score: 0.615\n",
      "Epoch: 9/30.. Train Loss: 1.014.. Test Loss: 1.081.. Test Accuracy: 0.639.. Test F1 Score: 0.639\n",
      "Epoch: 10/30.. Train Loss: 0.995.. Test Loss: 1.096.. Test Accuracy: 0.573.. Test F1 Score: 0.563\n",
      "Epoch: 11/30.. Train Loss: 0.981.. Test Loss: 1.131.. Test Accuracy: 0.555.. Test F1 Score: 0.521\n",
      "Epoch: 12/30.. Train Loss: 0.975.. Test Loss: 1.061.. Test Accuracy: 0.643.. Test F1 Score: 0.640\n",
      "Epoch: 13/30.. Train Loss: 0.957.. Test Loss: 1.076.. Test Accuracy: 0.610.. Test F1 Score: 0.602\n",
      "Epoch: 14/30.. Train Loss: 0.950.. Test Loss: 1.043.. Test Accuracy: 0.668.. Test F1 Score: 0.668\n",
      "Epoch: 15/30.. Train Loss: 0.938.. Test Loss: 1.051.. Test Accuracy: 0.619.. Test F1 Score: 0.614\n",
      "Epoch: 16/30.. Train Loss: 0.932.. Test Loss: 1.033.. Test Accuracy: 0.654.. Test F1 Score: 0.649\n",
      "Epoch: 17/30.. Train Loss: 0.924.. Test Loss: 1.043.. Test Accuracy: 0.642.. Test F1 Score: 0.642\n",
      "Epoch: 18/30.. Train Loss: 0.918.. Test Loss: 1.041.. Test Accuracy: 0.623.. Test F1 Score: 0.617\n",
      "Epoch: 19/30.. Train Loss: 0.910.. Test Loss: 1.034.. Test Accuracy: 0.650.. Test F1 Score: 0.629\n",
      "Epoch: 20/30.. Train Loss: 0.908.. Test Loss: 1.039.. Test Accuracy: 0.635.. Test F1 Score: 0.624\n",
      "Epoch: 21/30.. Train Loss: 0.901.. Test Loss: 1.021.. Test Accuracy: 0.663.. Test F1 Score: 0.654\n",
      "Epoch: 22/30.. Train Loss: 0.894.. Test Loss: 1.031.. Test Accuracy: 0.659.. Test F1 Score: 0.662\n",
      "Epoch: 23/30.. Train Loss: 0.889.. Test Loss: 1.018.. Test Accuracy: 0.667.. Test F1 Score: 0.660\n",
      "Epoch: 24/30.. Train Loss: 0.883.. Test Loss: 1.016.. Test Accuracy: 0.660.. Test F1 Score: 0.648\n",
      "Epoch: 25/30.. Train Loss: 0.881.. Test Loss: 1.015.. Test Accuracy: 0.641.. Test F1 Score: 0.630\n",
      "Epoch: 26/30.. Train Loss: 0.876.. Test Loss: 1.045.. Test Accuracy: 0.627.. Test F1 Score: 0.624\n",
      "Epoch: 27/30.. Train Loss: 0.872.. Test Loss: 1.025.. Test Accuracy: 0.674.. Test F1 Score: 0.675\n",
      "Epoch: 28/30.. Train Loss: 0.869.. Test Loss: 1.024.. Test Accuracy: 0.662.. Test F1 Score: 0.663\n",
      "Epoch: 29/30.. Train Loss: 0.864.. Test Loss: 1.027.. Test Accuracy: 0.678.. Test F1 Score: 0.673\n",
      "Epoch: 30/30.. Train Loss: 0.866.. Test Loss: 1.039.. Test Accuracy: 0.626.. Test F1 Score: 0.630\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc2.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(model, train_dataloader_50, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.979.. Test Loss: 1.756.. Test Accuracy: 0.417.. Test F1 Score: 0.338\n",
      "Epoch: 2/30.. Train Loss: 1.597.. Test Loss: 1.577.. Test Accuracy: 0.432.. Test F1 Score: 0.376\n",
      "Epoch: 3/30.. Train Loss: 1.402.. Test Loss: 1.494.. Test Accuracy: 0.448.. Test F1 Score: 0.368\n",
      "Epoch: 4/30.. Train Loss: 1.281.. Test Loss: 1.407.. Test Accuracy: 0.502.. Test F1 Score: 0.450\n",
      "Epoch: 5/30.. Train Loss: 1.192.. Test Loss: 1.343.. Test Accuracy: 0.534.. Test F1 Score: 0.521\n",
      "Epoch: 6/30.. Train Loss: 1.121.. Test Loss: 1.290.. Test Accuracy: 0.558.. Test F1 Score: 0.544\n",
      "Epoch: 7/30.. Train Loss: 1.066.. Test Loss: 1.266.. Test Accuracy: 0.551.. Test F1 Score: 0.535\n",
      "Epoch: 8/30.. Train Loss: 1.017.. Test Loss: 1.255.. Test Accuracy: 0.546.. Test F1 Score: 0.537\n",
      "Epoch: 9/30.. Train Loss: 0.986.. Test Loss: 1.222.. Test Accuracy: 0.572.. Test F1 Score: 0.530\n",
      "Epoch: 10/30.. Train Loss: 0.955.. Test Loss: 1.208.. Test Accuracy: 0.583.. Test F1 Score: 0.558\n",
      "Epoch: 11/30.. Train Loss: 0.927.. Test Loss: 1.242.. Test Accuracy: 0.525.. Test F1 Score: 0.502\n",
      "Epoch: 12/30.. Train Loss: 0.903.. Test Loss: 1.217.. Test Accuracy: 0.546.. Test F1 Score: 0.531\n",
      "Epoch: 13/30.. Train Loss: 0.882.. Test Loss: 1.204.. Test Accuracy: 0.568.. Test F1 Score: 0.555\n",
      "Epoch: 14/30.. Train Loss: 0.867.. Test Loss: 1.206.. Test Accuracy: 0.555.. Test F1 Score: 0.543\n",
      "Epoch: 15/30.. Train Loss: 0.848.. Test Loss: 1.192.. Test Accuracy: 0.550.. Test F1 Score: 0.543\n",
      "Epoch: 16/30.. Train Loss: 0.834.. Test Loss: 1.184.. Test Accuracy: 0.597.. Test F1 Score: 0.553\n",
      "Epoch: 17/30.. Train Loss: 0.823.. Test Loss: 1.199.. Test Accuracy: 0.593.. Test F1 Score: 0.590\n",
      "Epoch: 18/30.. Train Loss: 0.809.. Test Loss: 1.199.. Test Accuracy: 0.577.. Test F1 Score: 0.565\n",
      "Epoch: 19/30.. Train Loss: 0.801.. Test Loss: 1.179.. Test Accuracy: 0.589.. Test F1 Score: 0.569\n",
      "Epoch: 20/30.. Train Loss: 0.791.. Test Loss: 1.180.. Test Accuracy: 0.610.. Test F1 Score: 0.601\n",
      "Epoch: 21/30.. Train Loss: 0.787.. Test Loss: 1.180.. Test Accuracy: 0.585.. Test F1 Score: 0.580\n",
      "Epoch: 22/30.. Train Loss: 0.772.. Test Loss: 1.187.. Test Accuracy: 0.607.. Test F1 Score: 0.607\n",
      "Epoch: 23/30.. Train Loss: 0.765.. Test Loss: 1.192.. Test Accuracy: 0.599.. Test F1 Score: 0.602\n",
      "Epoch: 24/30.. Train Loss: 0.758.. Test Loss: 1.184.. Test Accuracy: 0.617.. Test F1 Score: 0.615\n",
      "Epoch: 25/30.. Train Loss: 0.753.. Test Loss: 1.203.. Test Accuracy: 0.596.. Test F1 Score: 0.593\n",
      "Epoch: 26/30.. Train Loss: 0.745.. Test Loss: 1.200.. Test Accuracy: 0.599.. Test F1 Score: 0.596\n",
      "Epoch: 27/30.. Train Loss: 0.738.. Test Loss: 1.186.. Test Accuracy: 0.613.. Test F1 Score: 0.609\n",
      "Epoch: 28/30.. Train Loss: 0.727.. Test Loss: 1.183.. Test Accuracy: 0.594.. Test F1 Score: 0.594\n",
      "Epoch: 29/30.. Train Loss: 0.725.. Test Loss: 1.231.. Test Accuracy: 0.599.. Test F1 Score: 0.603\n",
      "Epoch: 30/30.. Train Loss: 0.720.. Test Loss: 1.215.. Test Accuracy: 0.599.. Test F1 Score: 0.600\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc2.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(model, train_dataloader_25, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 2.118.. Test Loss: 1.909.. Test Accuracy: 0.321.. Test F1 Score: 0.268\n",
      "Epoch: 2/30.. Train Loss: 1.779.. Test Loss: 1.777.. Test Accuracy: 0.393.. Test F1 Score: 0.352\n",
      "Epoch: 3/30.. Train Loss: 1.611.. Test Loss: 1.673.. Test Accuracy: 0.505.. Test F1 Score: 0.478\n",
      "Epoch: 4/30.. Train Loss: 1.470.. Test Loss: 1.564.. Test Accuracy: 0.597.. Test F1 Score: 0.571\n",
      "Epoch: 5/30.. Train Loss: 1.357.. Test Loss: 1.529.. Test Accuracy: 0.551.. Test F1 Score: 0.525\n",
      "Epoch: 6/30.. Train Loss: 1.272.. Test Loss: 1.490.. Test Accuracy: 0.533.. Test F1 Score: 0.503\n",
      "Epoch: 7/30.. Train Loss: 1.197.. Test Loss: 1.422.. Test Accuracy: 0.552.. Test F1 Score: 0.537\n",
      "Epoch: 8/30.. Train Loss: 1.132.. Test Loss: 1.395.. Test Accuracy: 0.576.. Test F1 Score: 0.567\n",
      "Epoch: 9/30.. Train Loss: 1.077.. Test Loss: 1.376.. Test Accuracy: 0.597.. Test F1 Score: 0.584\n",
      "Epoch: 10/30.. Train Loss: 1.032.. Test Loss: 1.376.. Test Accuracy: 0.578.. Test F1 Score: 0.565\n",
      "Epoch: 11/30.. Train Loss: 1.003.. Test Loss: 1.363.. Test Accuracy: 0.555.. Test F1 Score: 0.545\n",
      "Epoch: 12/30.. Train Loss: 0.962.. Test Loss: 1.335.. Test Accuracy: 0.602.. Test F1 Score: 0.604\n",
      "Epoch: 13/30.. Train Loss: 0.936.. Test Loss: 1.313.. Test Accuracy: 0.594.. Test F1 Score: 0.588\n",
      "Epoch: 14/30.. Train Loss: 0.909.. Test Loss: 1.337.. Test Accuracy: 0.566.. Test F1 Score: 0.553\n",
      "Epoch: 15/30.. Train Loss: 0.885.. Test Loss: 1.302.. Test Accuracy: 0.610.. Test F1 Score: 0.605\n",
      "Epoch: 16/30.. Train Loss: 0.860.. Test Loss: 1.294.. Test Accuracy: 0.596.. Test F1 Score: 0.599\n",
      "Epoch: 17/30.. Train Loss: 0.847.. Test Loss: 1.279.. Test Accuracy: 0.604.. Test F1 Score: 0.606\n",
      "Epoch: 18/30.. Train Loss: 0.818.. Test Loss: 1.341.. Test Accuracy: 0.564.. Test F1 Score: 0.565\n",
      "Epoch: 19/30.. Train Loss: 0.802.. Test Loss: 1.287.. Test Accuracy: 0.602.. Test F1 Score: 0.599\n",
      "Epoch: 20/30.. Train Loss: 0.787.. Test Loss: 1.243.. Test Accuracy: 0.623.. Test F1 Score: 0.615\n",
      "Epoch: 21/30.. Train Loss: 0.776.. Test Loss: 1.291.. Test Accuracy: 0.588.. Test F1 Score: 0.590\n",
      "Epoch: 22/30.. Train Loss: 0.755.. Test Loss: 1.272.. Test Accuracy: 0.599.. Test F1 Score: 0.596\n",
      "Epoch: 23/30.. Train Loss: 0.750.. Test Loss: 1.268.. Test Accuracy: 0.588.. Test F1 Score: 0.590\n",
      "Epoch: 24/30.. Train Loss: 0.731.. Test Loss: 1.340.. Test Accuracy: 0.570.. Test F1 Score: 0.571\n",
      "Epoch: 25/30.. Train Loss: 0.728.. Test Loss: 1.380.. Test Accuracy: 0.544.. Test F1 Score: 0.526\n",
      "Epoch: 26/30.. Train Loss: 0.716.. Test Loss: 1.263.. Test Accuracy: 0.600.. Test F1 Score: 0.601\n",
      "Epoch: 27/30.. Train Loss: 0.705.. Test Loss: 1.312.. Test Accuracy: 0.571.. Test F1 Score: 0.572\n",
      "Epoch: 28/30.. Train Loss: 0.693.. Test Loss: 1.239.. Test Accuracy: 0.621.. Test F1 Score: 0.624\n",
      "Epoch: 29/30.. Train Loss: 0.687.. Test Loss: 1.274.. Test Accuracy: 0.606.. Test F1 Score: 0.613\n",
      "Epoch: 30/30.. Train Loss: 0.676.. Test Loss: 1.292.. Test Accuracy: 0.562.. Test F1 Score: 0.567\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc2.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(model, train_dataloader_10, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune CNN Conv-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.574.. Test Loss: 1.317.. Test Accuracy: 0.533.. Test F1 Score: 0.492\n",
      "Epoch: 2/30.. Train Loss: 1.221.. Test Loss: 1.167.. Test Accuracy: 0.589.. Test F1 Score: 0.564\n",
      "Epoch: 3/30.. Train Loss: 1.119.. Test Loss: 1.125.. Test Accuracy: 0.638.. Test F1 Score: 0.625\n",
      "Epoch: 4/30.. Train Loss: 1.068.. Test Loss: 1.092.. Test Accuracy: 0.614.. Test F1 Score: 0.597\n",
      "Epoch: 5/30.. Train Loss: 1.038.. Test Loss: 1.081.. Test Accuracy: 0.657.. Test F1 Score: 0.655\n",
      "Epoch: 6/30.. Train Loss: 1.010.. Test Loss: 1.081.. Test Accuracy: 0.616.. Test F1 Score: 0.611\n",
      "Epoch: 7/30.. Train Loss: 0.991.. Test Loss: 1.061.. Test Accuracy: 0.628.. Test F1 Score: 0.612\n",
      "Epoch: 8/30.. Train Loss: 0.978.. Test Loss: 1.043.. Test Accuracy: 0.671.. Test F1 Score: 0.667\n",
      "Epoch: 9/30.. Train Loss: 0.964.. Test Loss: 1.031.. Test Accuracy: 0.655.. Test F1 Score: 0.650\n",
      "Epoch: 10/30.. Train Loss: 0.955.. Test Loss: 1.026.. Test Accuracy: 0.685.. Test F1 Score: 0.676\n",
      "Epoch: 11/30.. Train Loss: 0.944.. Test Loss: 1.034.. Test Accuracy: 0.668.. Test F1 Score: 0.658\n",
      "Epoch: 12/30.. Train Loss: 0.937.. Test Loss: 1.038.. Test Accuracy: 0.678.. Test F1 Score: 0.681\n",
      "Epoch: 13/30.. Train Loss: 0.930.. Test Loss: 1.017.. Test Accuracy: 0.670.. Test F1 Score: 0.659\n",
      "Epoch: 14/30.. Train Loss: 0.922.. Test Loss: 1.028.. Test Accuracy: 0.679.. Test F1 Score: 0.681\n",
      "Epoch: 15/30.. Train Loss: 0.919.. Test Loss: 1.026.. Test Accuracy: 0.670.. Test F1 Score: 0.667\n",
      "Epoch: 16/30.. Train Loss: 0.911.. Test Loss: 1.024.. Test Accuracy: 0.694.. Test F1 Score: 0.687\n",
      "Epoch: 17/30.. Train Loss: 0.906.. Test Loss: 1.036.. Test Accuracy: 0.636.. Test F1 Score: 0.645\n",
      "Epoch: 18/30.. Train Loss: 0.903.. Test Loss: 1.038.. Test Accuracy: 0.669.. Test F1 Score: 0.670\n",
      "Epoch: 19/30.. Train Loss: 0.898.. Test Loss: 1.019.. Test Accuracy: 0.686.. Test F1 Score: 0.683\n",
      "Epoch: 20/30.. Train Loss: 0.894.. Test Loss: 1.015.. Test Accuracy: 0.653.. Test F1 Score: 0.644\n",
      "Epoch: 21/30.. Train Loss: 0.891.. Test Loss: 1.032.. Test Accuracy: 0.651.. Test F1 Score: 0.657\n",
      "Epoch: 22/30.. Train Loss: 0.888.. Test Loss: 1.017.. Test Accuracy: 0.682.. Test F1 Score: 0.678\n",
      "Epoch: 23/30.. Train Loss: 0.887.. Test Loss: 1.038.. Test Accuracy: 0.663.. Test F1 Score: 0.652\n",
      "Epoch: 24/30.. Train Loss: 0.882.. Test Loss: 1.034.. Test Accuracy: 0.651.. Test F1 Score: 0.651\n",
      "Epoch: 25/30.. Train Loss: 0.881.. Test Loss: 0.999.. Test Accuracy: 0.660.. Test F1 Score: 0.655\n",
      "Epoch: 26/30.. Train Loss: 0.876.. Test Loss: 1.026.. Test Accuracy: 0.677.. Test F1 Score: 0.676\n",
      "Epoch: 27/30.. Train Loss: 0.871.. Test Loss: 1.071.. Test Accuracy: 0.636.. Test F1 Score: 0.641\n",
      "Epoch: 28/30.. Train Loss: 0.870.. Test Loss: 1.017.. Test Accuracy: 0.645.. Test F1 Score: 0.631\n",
      "Epoch: 29/30.. Train Loss: 0.870.. Test Loss: 1.001.. Test Accuracy: 0.664.. Test F1 Score: 0.658\n",
      "Epoch: 30/30.. Train Loss: 0.867.. Test Loss: 1.024.. Test Accuracy: 0.646.. Test F1 Score: 0.649\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Freezing layers up to conv3\n",
    "for name, param in model.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        break\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layers from conv3 onwards\n",
    "unfreeze = False\n",
    "for name, param in model.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        unfreeze = True\n",
    "    if unfreeze:\n",
    "        param.requires_grad = True\n",
    "\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc2.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(model, train_dataloader, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.653.. Test Loss: 1.385.. Test Accuracy: 0.553.. Test F1 Score: 0.506\n",
      "Epoch: 2/30.. Train Loss: 1.304.. Test Loss: 1.224.. Test Accuracy: 0.631.. Test F1 Score: 0.595\n",
      "Epoch: 3/30.. Train Loss: 1.193.. Test Loss: 1.180.. Test Accuracy: 0.632.. Test F1 Score: 0.608\n",
      "Epoch: 4/30.. Train Loss: 1.134.. Test Loss: 1.133.. Test Accuracy: 0.639.. Test F1 Score: 0.627\n",
      "Epoch: 5/30.. Train Loss: 1.098.. Test Loss: 1.123.. Test Accuracy: 0.618.. Test F1 Score: 0.615\n",
      "Epoch: 6/30.. Train Loss: 1.072.. Test Loss: 1.112.. Test Accuracy: 0.647.. Test F1 Score: 0.621\n",
      "Epoch: 7/30.. Train Loss: 1.051.. Test Loss: 1.095.. Test Accuracy: 0.662.. Test F1 Score: 0.632\n",
      "Epoch: 8/30.. Train Loss: 1.034.. Test Loss: 1.082.. Test Accuracy: 0.674.. Test F1 Score: 0.655\n",
      "Epoch: 9/30.. Train Loss: 1.021.. Test Loss: 1.078.. Test Accuracy: 0.631.. Test F1 Score: 0.631\n",
      "Epoch: 10/30.. Train Loss: 1.008.. Test Loss: 1.065.. Test Accuracy: 0.645.. Test F1 Score: 0.618\n",
      "Epoch: 11/30.. Train Loss: 0.996.. Test Loss: 1.071.. Test Accuracy: 0.641.. Test F1 Score: 0.622\n",
      "Epoch: 12/30.. Train Loss: 0.989.. Test Loss: 1.062.. Test Accuracy: 0.679.. Test F1 Score: 0.660\n",
      "Epoch: 13/30.. Train Loss: 0.982.. Test Loss: 1.087.. Test Accuracy: 0.660.. Test F1 Score: 0.649\n",
      "Epoch: 14/30.. Train Loss: 0.974.. Test Loss: 1.142.. Test Accuracy: 0.603.. Test F1 Score: 0.600\n",
      "Epoch: 15/30.. Train Loss: 0.967.. Test Loss: 1.080.. Test Accuracy: 0.646.. Test F1 Score: 0.620\n",
      "Epoch: 16/30.. Train Loss: 0.962.. Test Loss: 1.074.. Test Accuracy: 0.632.. Test F1 Score: 0.637\n",
      "Epoch: 17/30.. Train Loss: 0.957.. Test Loss: 1.086.. Test Accuracy: 0.621.. Test F1 Score: 0.622\n",
      "Epoch: 18/30.. Train Loss: 0.951.. Test Loss: 1.055.. Test Accuracy: 0.630.. Test F1 Score: 0.625\n",
      "Epoch: 19/30.. Train Loss: 0.946.. Test Loss: 1.074.. Test Accuracy: 0.649.. Test F1 Score: 0.624\n",
      "Epoch: 20/30.. Train Loss: 0.940.. Test Loss: 1.071.. Test Accuracy: 0.633.. Test F1 Score: 0.608\n",
      "Epoch: 21/30.. Train Loss: 0.936.. Test Loss: 1.095.. Test Accuracy: 0.658.. Test F1 Score: 0.652\n",
      "Epoch: 22/30.. Train Loss: 0.934.. Test Loss: 1.095.. Test Accuracy: 0.637.. Test F1 Score: 0.612\n",
      "Epoch: 23/30.. Train Loss: 0.932.. Test Loss: 1.068.. Test Accuracy: 0.644.. Test F1 Score: 0.646\n",
      "Epoch: 24/30.. Train Loss: 0.925.. Test Loss: 1.110.. Test Accuracy: 0.645.. Test F1 Score: 0.624\n",
      "Epoch: 25/30.. Train Loss: 0.925.. Test Loss: 1.058.. Test Accuracy: 0.644.. Test F1 Score: 0.639\n",
      "Epoch: 26/30.. Train Loss: 0.921.. Test Loss: 1.038.. Test Accuracy: 0.656.. Test F1 Score: 0.647\n",
      "Epoch: 27/30.. Train Loss: 0.918.. Test Loss: 1.074.. Test Accuracy: 0.671.. Test F1 Score: 0.675\n",
      "Epoch: 28/30.. Train Loss: 0.915.. Test Loss: 1.065.. Test Accuracy: 0.662.. Test F1 Score: 0.640\n",
      "Epoch: 29/30.. Train Loss: 0.914.. Test Loss: 1.047.. Test Accuracy: 0.660.. Test F1 Score: 0.652\n",
      "Epoch: 30/30.. Train Loss: 0.910.. Test Loss: 1.040.. Test Accuracy: 0.660.. Test F1 Score: 0.653\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Freezing layers up to conv3\n",
    "for name, param in model.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        break\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layers from conv3 onwards\n",
    "unfreeze = False\n",
    "for name, param in model.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        unfreeze = True\n",
    "    if unfreeze:\n",
    "        param.requires_grad = True\n",
    "\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc2.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_75, test_losses_75, test_accuracies_75, test_f1_scores_75 = train_and_test(model, train_dataloader_75, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 0.989.. Test Loss: 1.019.. Test Accuracy: 0.660.. Test F1 Score: 0.658\n",
      "Epoch: 2/30.. Train Loss: 0.621.. Test Loss: 1.132.. Test Accuracy: 0.641.. Test F1 Score: 0.651\n",
      "Epoch: 3/30.. Train Loss: 0.552.. Test Loss: 1.165.. Test Accuracy: 0.596.. Test F1 Score: 0.601\n",
      "Epoch: 4/30.. Train Loss: 0.483.. Test Loss: 1.100.. Test Accuracy: 0.665.. Test F1 Score: 0.665\n",
      "Epoch: 5/30.. Train Loss: 0.444.. Test Loss: 1.162.. Test Accuracy: 0.633.. Test F1 Score: 0.631\n",
      "Epoch: 6/30.. Train Loss: 0.426.. Test Loss: 1.176.. Test Accuracy: 0.655.. Test F1 Score: 0.653\n",
      "Epoch: 7/30.. Train Loss: 0.394.. Test Loss: 1.181.. Test Accuracy: 0.659.. Test F1 Score: 0.665\n",
      "Epoch: 8/30.. Train Loss: 0.376.. Test Loss: 1.230.. Test Accuracy: 0.657.. Test F1 Score: 0.663\n",
      "Epoch: 9/30.. Train Loss: 0.361.. Test Loss: 1.363.. Test Accuracy: 0.658.. Test F1 Score: 0.663\n",
      "Epoch: 10/30.. Train Loss: 0.334.. Test Loss: 1.290.. Test Accuracy: 0.666.. Test F1 Score: 0.672\n",
      "Epoch: 11/30.. Train Loss: 0.328.. Test Loss: 1.290.. Test Accuracy: 0.687.. Test F1 Score: 0.690\n",
      "Epoch: 12/30.. Train Loss: 0.298.. Test Loss: 1.402.. Test Accuracy: 0.666.. Test F1 Score: 0.674\n",
      "Epoch: 13/30.. Train Loss: 0.288.. Test Loss: 1.666.. Test Accuracy: 0.629.. Test F1 Score: 0.633\n",
      "Epoch: 14/30.. Train Loss: 0.277.. Test Loss: 1.535.. Test Accuracy: 0.631.. Test F1 Score: 0.633\n",
      "Epoch: 15/30.. Train Loss: 0.268.. Test Loss: 1.564.. Test Accuracy: 0.660.. Test F1 Score: 0.665\n",
      "Epoch: 16/30.. Train Loss: 0.248.. Test Loss: 1.639.. Test Accuracy: 0.659.. Test F1 Score: 0.665\n",
      "Epoch: 17/30.. Train Loss: 0.241.. Test Loss: 1.833.. Test Accuracy: 0.663.. Test F1 Score: 0.668\n",
      "Epoch: 18/30.. Train Loss: 0.236.. Test Loss: 1.838.. Test Accuracy: 0.636.. Test F1 Score: 0.642\n",
      "Epoch: 19/30.. Train Loss: 0.213.. Test Loss: 1.891.. Test Accuracy: 0.636.. Test F1 Score: 0.641\n",
      "Epoch: 20/30.. Train Loss: 0.228.. Test Loss: 1.896.. Test Accuracy: 0.671.. Test F1 Score: 0.674\n",
      "Epoch: 21/30.. Train Loss: 0.214.. Test Loss: 1.729.. Test Accuracy: 0.673.. Test F1 Score: 0.678\n",
      "Epoch: 22/30.. Train Loss: 0.213.. Test Loss: 1.724.. Test Accuracy: 0.648.. Test F1 Score: 0.653\n",
      "Epoch: 23/30.. Train Loss: 0.187.. Test Loss: 2.012.. Test Accuracy: 0.649.. Test F1 Score: 0.654\n",
      "Epoch: 24/30.. Train Loss: 0.196.. Test Loss: 2.122.. Test Accuracy: 0.637.. Test F1 Score: 0.645\n",
      "Epoch: 25/30.. Train Loss: 0.180.. Test Loss: 2.145.. Test Accuracy: 0.657.. Test F1 Score: 0.667\n",
      "Epoch: 26/30.. Train Loss: 0.176.. Test Loss: 2.517.. Test Accuracy: 0.612.. Test F1 Score: 0.610\n",
      "Epoch: 27/30.. Train Loss: 0.173.. Test Loss: 2.590.. Test Accuracy: 0.634.. Test F1 Score: 0.640\n",
      "Epoch: 28/30.. Train Loss: 0.169.. Test Loss: 2.446.. Test Accuracy: 0.654.. Test F1 Score: 0.657\n",
      "Epoch: 29/30.. Train Loss: 0.162.. Test Loss: 2.542.. Test Accuracy: 0.632.. Test F1 Score: 0.637\n",
      "Epoch: 30/30.. Train Loss: 0.155.. Test Loss: 2.454.. Test Accuracy: 0.636.. Test F1 Score: 0.639\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Freezing layers up to conv3\n",
    "for name, param in model.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        break\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layers from conv3 onwards\n",
    "unfreeze = False\n",
    "for name, param in model.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        unfreeze = True\n",
    "    if unfreeze:\n",
    "        param.requires_grad = True\n",
    "\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_50, test_losses_50, test_accuracies_50, test_f1_scores_50 = train_and_test(model, train_dataloader_50, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 0.987.. Test Loss: 1.550.. Test Accuracy: 0.575.. Test F1 Score: 0.570\n",
      "Epoch: 2/30.. Train Loss: 0.501.. Test Loss: 1.775.. Test Accuracy: 0.512.. Test F1 Score: 0.538\n",
      "Epoch: 3/30.. Train Loss: 0.401.. Test Loss: 1.817.. Test Accuracy: 0.589.. Test F1 Score: 0.612\n",
      "Epoch: 4/30.. Train Loss: 0.347.. Test Loss: 2.180.. Test Accuracy: 0.504.. Test F1 Score: 0.528\n",
      "Epoch: 5/30.. Train Loss: 0.332.. Test Loss: 1.862.. Test Accuracy: 0.562.. Test F1 Score: 0.584\n",
      "Epoch: 6/30.. Train Loss: 0.292.. Test Loss: 2.052.. Test Accuracy: 0.521.. Test F1 Score: 0.525\n",
      "Epoch: 7/30.. Train Loss: 0.284.. Test Loss: 2.180.. Test Accuracy: 0.529.. Test F1 Score: 0.523\n",
      "Epoch: 8/30.. Train Loss: 0.265.. Test Loss: 2.140.. Test Accuracy: 0.505.. Test F1 Score: 0.510\n",
      "Epoch: 9/30.. Train Loss: 0.216.. Test Loss: 2.477.. Test Accuracy: 0.535.. Test F1 Score: 0.549\n",
      "Epoch: 10/30.. Train Loss: 0.247.. Test Loss: 2.248.. Test Accuracy: 0.573.. Test F1 Score: 0.589\n",
      "Epoch: 11/30.. Train Loss: 0.205.. Test Loss: 2.430.. Test Accuracy: 0.557.. Test F1 Score: 0.563\n",
      "Epoch: 12/30.. Train Loss: 0.183.. Test Loss: 2.299.. Test Accuracy: 0.543.. Test F1 Score: 0.555\n",
      "Epoch: 13/30.. Train Loss: 0.175.. Test Loss: 2.745.. Test Accuracy: 0.508.. Test F1 Score: 0.501\n",
      "Epoch: 14/30.. Train Loss: 0.160.. Test Loss: 2.393.. Test Accuracy: 0.545.. Test F1 Score: 0.548\n",
      "Epoch: 15/30.. Train Loss: 0.146.. Test Loss: 3.034.. Test Accuracy: 0.506.. Test F1 Score: 0.513\n",
      "Epoch: 16/30.. Train Loss: 0.159.. Test Loss: 2.794.. Test Accuracy: 0.559.. Test F1 Score: 0.561\n",
      "Epoch: 17/30.. Train Loss: 0.138.. Test Loss: 3.313.. Test Accuracy: 0.533.. Test F1 Score: 0.540\n",
      "Epoch: 18/30.. Train Loss: 0.126.. Test Loss: 3.197.. Test Accuracy: 0.519.. Test F1 Score: 0.515\n",
      "Epoch: 19/30.. Train Loss: 0.124.. Test Loss: 3.117.. Test Accuracy: 0.535.. Test F1 Score: 0.536\n",
      "Epoch: 20/30.. Train Loss: 0.115.. Test Loss: 3.638.. Test Accuracy: 0.516.. Test F1 Score: 0.512\n",
      "Epoch: 21/30.. Train Loss: 0.118.. Test Loss: 3.550.. Test Accuracy: 0.507.. Test F1 Score: 0.520\n",
      "Epoch: 22/30.. Train Loss: 0.116.. Test Loss: 3.822.. Test Accuracy: 0.504.. Test F1 Score: 0.483\n",
      "Epoch: 23/30.. Train Loss: 0.105.. Test Loss: 3.626.. Test Accuracy: 0.495.. Test F1 Score: 0.485\n",
      "Epoch: 24/30.. Train Loss: 0.089.. Test Loss: 3.795.. Test Accuracy: 0.526.. Test F1 Score: 0.524\n",
      "Epoch: 25/30.. Train Loss: 0.099.. Test Loss: 4.414.. Test Accuracy: 0.489.. Test F1 Score: 0.478\n",
      "Epoch: 26/30.. Train Loss: 0.130.. Test Loss: 3.541.. Test Accuracy: 0.549.. Test F1 Score: 0.566\n",
      "Epoch: 27/30.. Train Loss: 0.094.. Test Loss: 4.289.. Test Accuracy: 0.494.. Test F1 Score: 0.502\n",
      "Epoch: 28/30.. Train Loss: 0.081.. Test Loss: 4.050.. Test Accuracy: 0.495.. Test F1 Score: 0.508\n",
      "Epoch: 29/30.. Train Loss: 0.072.. Test Loss: 4.387.. Test Accuracy: 0.516.. Test F1 Score: 0.504\n",
      "Epoch: 30/30.. Train Loss: 0.068.. Test Loss: 4.023.. Test Accuracy: 0.523.. Test F1 Score: 0.530\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Freezing layers up to conv3\n",
    "for name, param in model.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        break\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layers from conv3 onwards\n",
    "unfreeze = False\n",
    "for name, param in model.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        unfreeze = True\n",
    "    if unfreeze:\n",
    "        param.requires_grad = True\n",
    "\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_25, test_losses_25, test_accuracies_25, test_f1_scores_25 = train_and_test(model, train_dataloader_25, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.283.. Test Loss: 2.248.. Test Accuracy: 0.410.. Test F1 Score: 0.464\n",
      "Epoch: 2/30.. Train Loss: 0.432.. Test Loss: 2.290.. Test Accuracy: 0.450.. Test F1 Score: 0.478\n",
      "Epoch: 3/30.. Train Loss: 0.315.. Test Loss: 3.315.. Test Accuracy: 0.316.. Test F1 Score: 0.345\n",
      "Epoch: 4/30.. Train Loss: 0.250.. Test Loss: 2.807.. Test Accuracy: 0.357.. Test F1 Score: 0.358\n",
      "Epoch: 5/30.. Train Loss: 0.201.. Test Loss: 3.039.. Test Accuracy: 0.401.. Test F1 Score: 0.443\n",
      "Epoch: 6/30.. Train Loss: 0.169.. Test Loss: 3.396.. Test Accuracy: 0.375.. Test F1 Score: 0.387\n",
      "Epoch: 7/30.. Train Loss: 0.162.. Test Loss: 2.783.. Test Accuracy: 0.417.. Test F1 Score: 0.429\n",
      "Epoch: 8/30.. Train Loss: 0.130.. Test Loss: 3.568.. Test Accuracy: 0.421.. Test F1 Score: 0.411\n",
      "Epoch: 9/30.. Train Loss: 0.130.. Test Loss: 3.146.. Test Accuracy: 0.439.. Test F1 Score: 0.433\n",
      "Epoch: 10/30.. Train Loss: 0.127.. Test Loss: 3.088.. Test Accuracy: 0.389.. Test F1 Score: 0.397\n",
      "Epoch: 11/30.. Train Loss: 0.120.. Test Loss: 3.590.. Test Accuracy: 0.367.. Test F1 Score: 0.394\n",
      "Epoch: 12/30.. Train Loss: 0.103.. Test Loss: 4.492.. Test Accuracy: 0.368.. Test F1 Score: 0.352\n",
      "Epoch: 13/30.. Train Loss: 0.090.. Test Loss: 3.578.. Test Accuracy: 0.413.. Test F1 Score: 0.411\n",
      "Epoch: 14/30.. Train Loss: 0.085.. Test Loss: 4.373.. Test Accuracy: 0.364.. Test F1 Score: 0.395\n",
      "Epoch: 15/30.. Train Loss: 0.105.. Test Loss: 4.499.. Test Accuracy: 0.355.. Test F1 Score: 0.347\n",
      "Epoch: 16/30.. Train Loss: 0.075.. Test Loss: 4.388.. Test Accuracy: 0.353.. Test F1 Score: 0.360\n",
      "Epoch: 17/30.. Train Loss: 0.076.. Test Loss: 4.770.. Test Accuracy: 0.347.. Test F1 Score: 0.364\n",
      "Epoch: 18/30.. Train Loss: 0.058.. Test Loss: 5.854.. Test Accuracy: 0.268.. Test F1 Score: 0.308\n",
      "Epoch: 19/30.. Train Loss: 0.105.. Test Loss: 5.166.. Test Accuracy: 0.361.. Test F1 Score: 0.392\n",
      "Epoch: 20/30.. Train Loss: 0.071.. Test Loss: 4.738.. Test Accuracy: 0.427.. Test F1 Score: 0.422\n",
      "Epoch: 21/30.. Train Loss: 0.057.. Test Loss: 4.715.. Test Accuracy: 0.371.. Test F1 Score: 0.369\n",
      "Epoch: 22/30.. Train Loss: 0.061.. Test Loss: 4.948.. Test Accuracy: 0.370.. Test F1 Score: 0.383\n",
      "Epoch: 23/30.. Train Loss: 0.043.. Test Loss: 4.993.. Test Accuracy: 0.406.. Test F1 Score: 0.421\n",
      "Epoch: 24/30.. Train Loss: 0.054.. Test Loss: 5.442.. Test Accuracy: 0.380.. Test F1 Score: 0.381\n",
      "Epoch: 25/30.. Train Loss: 0.050.. Test Loss: 5.568.. Test Accuracy: 0.370.. Test F1 Score: 0.383\n",
      "Epoch: 26/30.. Train Loss: 0.087.. Test Loss: 5.599.. Test Accuracy: 0.344.. Test F1 Score: 0.355\n",
      "Epoch: 27/30.. Train Loss: 0.076.. Test Loss: 5.398.. Test Accuracy: 0.387.. Test F1 Score: 0.415\n",
      "Epoch: 28/30.. Train Loss: 0.069.. Test Loss: 5.185.. Test Accuracy: 0.376.. Test F1 Score: 0.356\n",
      "Epoch: 29/30.. Train Loss: 0.047.. Test Loss: 5.321.. Test Accuracy: 0.407.. Test F1 Score: 0.393\n",
      "Epoch: 30/30.. Train Loss: 0.043.. Test Loss: 5.346.. Test Accuracy: 0.444.. Test F1 Score: 0.431\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Freezing layers up to conv3\n",
    "for name, param in model.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        break\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layers from conv3 onwards\n",
    "unfreeze = False\n",
    "for name, param in model.named_parameters():\n",
    "    if 'conv3' in name:\n",
    "        unfreeze = True\n",
    "    if unfreeze:\n",
    "        param.requires_grad = True\n",
    "\n",
    "model.fc2 = nn.Linear(in_features=model.fc2.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_10, test_losses_10, test_accuracies_10, test_f1_scores_10 = train_and_test(model, train_dataloader_10, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune TCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.165.. Test Loss: 0.970.. Test Accuracy: 0.691.. Test F1 Score: 0.691\n",
      "Epoch: 2/30.. Train Loss: 0.901.. Test Loss: 0.918.. Test Accuracy: 0.680.. Test F1 Score: 0.668\n",
      "Epoch: 3/30.. Train Loss: 0.865.. Test Loss: 0.968.. Test Accuracy: 0.661.. Test F1 Score: 0.664\n",
      "Epoch: 4/30.. Train Loss: 0.852.. Test Loss: 0.917.. Test Accuracy: 0.692.. Test F1 Score: 0.691\n",
      "Epoch: 5/30.. Train Loss: 0.836.. Test Loss: 0.958.. Test Accuracy: 0.631.. Test F1 Score: 0.642\n",
      "Epoch: 6/30.. Train Loss: 0.828.. Test Loss: 0.935.. Test Accuracy: 0.683.. Test F1 Score: 0.679\n",
      "Epoch: 7/30.. Train Loss: 0.823.. Test Loss: 0.947.. Test Accuracy: 0.637.. Test F1 Score: 0.640\n",
      "Epoch: 8/30.. Train Loss: 0.820.. Test Loss: 0.958.. Test Accuracy: 0.688.. Test F1 Score: 0.678\n",
      "Epoch: 9/30.. Train Loss: 0.808.. Test Loss: 0.917.. Test Accuracy: 0.657.. Test F1 Score: 0.653\n",
      "Epoch: 10/30.. Train Loss: 0.819.. Test Loss: 0.931.. Test Accuracy: 0.682.. Test F1 Score: 0.677\n",
      "Epoch: 11/30.. Train Loss: 0.815.. Test Loss: 0.938.. Test Accuracy: 0.671.. Test F1 Score: 0.661\n",
      "Epoch: 12/30.. Train Loss: 0.812.. Test Loss: 0.930.. Test Accuracy: 0.648.. Test F1 Score: 0.644\n",
      "Epoch: 13/30.. Train Loss: 0.813.. Test Loss: 0.952.. Test Accuracy: 0.641.. Test F1 Score: 0.634\n",
      "Epoch: 14/30.. Train Loss: 0.809.. Test Loss: 0.940.. Test Accuracy: 0.672.. Test F1 Score: 0.674\n",
      "Epoch: 15/30.. Train Loss: 0.808.. Test Loss: 0.930.. Test Accuracy: 0.653.. Test F1 Score: 0.655\n",
      "Epoch: 16/30.. Train Loss: 0.804.. Test Loss: 0.940.. Test Accuracy: 0.658.. Test F1 Score: 0.662\n",
      "Epoch: 17/30.. Train Loss: 0.804.. Test Loss: 0.966.. Test Accuracy: 0.692.. Test F1 Score: 0.689\n",
      "Epoch: 18/30.. Train Loss: 0.807.. Test Loss: 0.957.. Test Accuracy: 0.671.. Test F1 Score: 0.663\n",
      "Epoch: 19/30.. Train Loss: 0.800.. Test Loss: 0.945.. Test Accuracy: 0.694.. Test F1 Score: 0.689\n",
      "Epoch: 20/30.. Train Loss: 0.809.. Test Loss: 0.971.. Test Accuracy: 0.650.. Test F1 Score: 0.656\n",
      "Epoch: 21/30.. Train Loss: 0.801.. Test Loss: 0.961.. Test Accuracy: 0.684.. Test F1 Score: 0.687\n",
      "Epoch: 22/30.. Train Loss: 0.806.. Test Loss: 0.973.. Test Accuracy: 0.670.. Test F1 Score: 0.667\n",
      "Epoch: 23/30.. Train Loss: 0.803.. Test Loss: 0.938.. Test Accuracy: 0.674.. Test F1 Score: 0.672\n",
      "Epoch: 24/30.. Train Loss: 0.797.. Test Loss: 0.962.. Test Accuracy: 0.646.. Test F1 Score: 0.649\n",
      "Epoch: 25/30.. Train Loss: 0.804.. Test Loss: 0.955.. Test Accuracy: 0.682.. Test F1 Score: 0.685\n",
      "Epoch: 26/30.. Train Loss: 0.802.. Test Loss: 0.981.. Test Accuracy: 0.678.. Test F1 Score: 0.684\n",
      "Epoch: 27/30.. Train Loss: 0.801.. Test Loss: 0.946.. Test Accuracy: 0.656.. Test F1 Score: 0.658\n",
      "Epoch: 28/30.. Train Loss: 0.800.. Test Loss: 0.954.. Test Accuracy: 0.671.. Test F1 Score: 0.673\n",
      "Epoch: 29/30.. Train Loss: 0.806.. Test Loss: 0.943.. Test Accuracy: 0.668.. Test F1 Score: 0.669\n",
      "Epoch: 30/30.. Train Loss: 0.798.. Test Loss: 0.974.. Test Accuracy: 0.680.. Test F1 Score: 0.681\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 3  # Assuming 3 input channels (x, y, z axes of the accelerometer)\n",
    "num_channels = [64, 128, 256]  # Example channel sizes for each layer\n",
    "kernel_size = 8  # Kernel size for temporal convolutions\n",
    "\n",
    "model = TCN(num_inputs, num_channels, kernel_size, num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "pretrained_model_path = './models/tcn_join_20231218-2014.pt'\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(model, train_dataloader, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.279.. Test Loss: 1.011.. Test Accuracy: 0.650.. Test F1 Score: 0.634\n",
      "Epoch: 2/30.. Train Loss: 0.964.. Test Loss: 0.951.. Test Accuracy: 0.669.. Test F1 Score: 0.659\n",
      "Epoch: 3/30.. Train Loss: 0.908.. Test Loss: 0.929.. Test Accuracy: 0.667.. Test F1 Score: 0.665\n",
      "Epoch: 4/30.. Train Loss: 0.887.. Test Loss: 0.925.. Test Accuracy: 0.647.. Test F1 Score: 0.638\n",
      "Epoch: 5/30.. Train Loss: 0.879.. Test Loss: 0.955.. Test Accuracy: 0.669.. Test F1 Score: 0.650\n",
      "Epoch: 6/30.. Train Loss: 0.860.. Test Loss: 0.939.. Test Accuracy: 0.684.. Test F1 Score: 0.672\n",
      "Epoch: 7/30.. Train Loss: 0.859.. Test Loss: 0.920.. Test Accuracy: 0.672.. Test F1 Score: 0.668\n",
      "Epoch: 8/30.. Train Loss: 0.851.. Test Loss: 0.947.. Test Accuracy: 0.681.. Test F1 Score: 0.672\n",
      "Epoch: 9/30.. Train Loss: 0.847.. Test Loss: 0.910.. Test Accuracy: 0.665.. Test F1 Score: 0.661\n",
      "Epoch: 10/30.. Train Loss: 0.841.. Test Loss: 0.938.. Test Accuracy: 0.651.. Test F1 Score: 0.636\n",
      "Epoch: 11/30.. Train Loss: 0.847.. Test Loss: 0.920.. Test Accuracy: 0.663.. Test F1 Score: 0.658\n",
      "Epoch: 12/30.. Train Loss: 0.839.. Test Loss: 0.925.. Test Accuracy: 0.665.. Test F1 Score: 0.663\n",
      "Epoch: 13/30.. Train Loss: 0.835.. Test Loss: 0.918.. Test Accuracy: 0.677.. Test F1 Score: 0.667\n",
      "Epoch: 14/30.. Train Loss: 0.831.. Test Loss: 0.937.. Test Accuracy: 0.661.. Test F1 Score: 0.654\n",
      "Epoch: 15/30.. Train Loss: 0.839.. Test Loss: 0.934.. Test Accuracy: 0.664.. Test F1 Score: 0.661\n",
      "Epoch: 16/30.. Train Loss: 0.831.. Test Loss: 0.926.. Test Accuracy: 0.662.. Test F1 Score: 0.659\n",
      "Epoch: 17/30.. Train Loss: 0.833.. Test Loss: 0.939.. Test Accuracy: 0.656.. Test F1 Score: 0.644\n",
      "Epoch: 18/30.. Train Loss: 0.833.. Test Loss: 0.925.. Test Accuracy: 0.664.. Test F1 Score: 0.664\n",
      "Epoch: 19/30.. Train Loss: 0.827.. Test Loss: 0.929.. Test Accuracy: 0.663.. Test F1 Score: 0.658\n",
      "Epoch: 20/30.. Train Loss: 0.834.. Test Loss: 0.958.. Test Accuracy: 0.658.. Test F1 Score: 0.657\n",
      "Epoch: 21/30.. Train Loss: 0.830.. Test Loss: 0.977.. Test Accuracy: 0.658.. Test F1 Score: 0.670\n",
      "Epoch: 22/30.. Train Loss: 0.831.. Test Loss: 0.940.. Test Accuracy: 0.655.. Test F1 Score: 0.654\n",
      "Epoch: 23/30.. Train Loss: 0.830.. Test Loss: 0.949.. Test Accuracy: 0.665.. Test F1 Score: 0.664\n",
      "Epoch: 24/30.. Train Loss: 0.821.. Test Loss: 0.943.. Test Accuracy: 0.666.. Test F1 Score: 0.667\n",
      "Epoch: 25/30.. Train Loss: 0.822.. Test Loss: 0.948.. Test Accuracy: 0.642.. Test F1 Score: 0.646\n",
      "Epoch: 26/30.. Train Loss: 0.827.. Test Loss: 0.947.. Test Accuracy: 0.659.. Test F1 Score: 0.657\n",
      "Epoch: 27/30.. Train Loss: 0.828.. Test Loss: 0.927.. Test Accuracy: 0.684.. Test F1 Score: 0.681\n",
      "Epoch: 28/30.. Train Loss: 0.821.. Test Loss: 0.964.. Test Accuracy: 0.657.. Test F1 Score: 0.664\n",
      "Epoch: 29/30.. Train Loss: 0.822.. Test Loss: 0.971.. Test Accuracy: 0.673.. Test F1 Score: 0.675\n",
      "Epoch: 30/30.. Train Loss: 0.822.. Test Loss: 0.964.. Test Accuracy: 0.666.. Test F1 Score: 0.666\n"
     ]
    }
   ],
   "source": [
    "model = TCN(num_inputs, num_channels, kernel_size, num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_75, test_losses_75, test_accuracies_75, test_f1_scores_75 = train_and_test(model, train_dataloader_75, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.311.. Test Loss: 1.031.. Test Accuracy: 0.689.. Test F1 Score: 0.667\n",
      "Epoch: 2/30.. Train Loss: 0.924.. Test Loss: 0.996.. Test Accuracy: 0.643.. Test F1 Score: 0.636\n",
      "Epoch: 3/30.. Train Loss: 0.853.. Test Loss: 0.948.. Test Accuracy: 0.654.. Test F1 Score: 0.652\n",
      "Epoch: 4/30.. Train Loss: 0.820.. Test Loss: 0.944.. Test Accuracy: 0.688.. Test F1 Score: 0.689\n",
      "Epoch: 5/30.. Train Loss: 0.800.. Test Loss: 0.945.. Test Accuracy: 0.683.. Test F1 Score: 0.684\n",
      "Epoch: 6/30.. Train Loss: 0.791.. Test Loss: 0.952.. Test Accuracy: 0.680.. Test F1 Score: 0.683\n",
      "Epoch: 7/30.. Train Loss: 0.777.. Test Loss: 0.969.. Test Accuracy: 0.667.. Test F1 Score: 0.672\n",
      "Epoch: 8/30.. Train Loss: 0.772.. Test Loss: 0.985.. Test Accuracy: 0.653.. Test F1 Score: 0.660\n",
      "Epoch: 9/30.. Train Loss: 0.776.. Test Loss: 0.952.. Test Accuracy: 0.679.. Test F1 Score: 0.682\n",
      "Epoch: 10/30.. Train Loss: 0.761.. Test Loss: 0.948.. Test Accuracy: 0.682.. Test F1 Score: 0.681\n",
      "Epoch: 11/30.. Train Loss: 0.751.. Test Loss: 0.957.. Test Accuracy: 0.676.. Test F1 Score: 0.675\n",
      "Epoch: 12/30.. Train Loss: 0.750.. Test Loss: 0.992.. Test Accuracy: 0.655.. Test F1 Score: 0.656\n",
      "Epoch: 13/30.. Train Loss: 0.748.. Test Loss: 0.960.. Test Accuracy: 0.688.. Test F1 Score: 0.690\n",
      "Epoch: 14/30.. Train Loss: 0.743.. Test Loss: 0.988.. Test Accuracy: 0.665.. Test F1 Score: 0.668\n",
      "Epoch: 15/30.. Train Loss: 0.748.. Test Loss: 0.978.. Test Accuracy: 0.684.. Test F1 Score: 0.686\n",
      "Epoch: 16/30.. Train Loss: 0.745.. Test Loss: 1.028.. Test Accuracy: 0.668.. Test F1 Score: 0.671\n",
      "Epoch: 17/30.. Train Loss: 0.745.. Test Loss: 1.018.. Test Accuracy: 0.664.. Test F1 Score: 0.664\n",
      "Epoch: 18/30.. Train Loss: 0.740.. Test Loss: 0.997.. Test Accuracy: 0.685.. Test F1 Score: 0.689\n",
      "Epoch: 19/30.. Train Loss: 0.740.. Test Loss: 1.015.. Test Accuracy: 0.657.. Test F1 Score: 0.662\n",
      "Epoch: 20/30.. Train Loss: 0.736.. Test Loss: 1.021.. Test Accuracy: 0.660.. Test F1 Score: 0.666\n",
      "Epoch: 21/30.. Train Loss: 0.728.. Test Loss: 0.996.. Test Accuracy: 0.668.. Test F1 Score: 0.666\n",
      "Epoch: 22/30.. Train Loss: 0.738.. Test Loss: 1.049.. Test Accuracy: 0.632.. Test F1 Score: 0.634\n",
      "Epoch: 23/30.. Train Loss: 0.738.. Test Loss: 1.042.. Test Accuracy: 0.670.. Test F1 Score: 0.669\n",
      "Epoch: 24/30.. Train Loss: 0.728.. Test Loss: 1.027.. Test Accuracy: 0.664.. Test F1 Score: 0.666\n",
      "Epoch: 25/30.. Train Loss: 0.726.. Test Loss: 1.048.. Test Accuracy: 0.651.. Test F1 Score: 0.654\n",
      "Epoch: 26/30.. Train Loss: 0.725.. Test Loss: 1.051.. Test Accuracy: 0.658.. Test F1 Score: 0.661\n",
      "Epoch: 27/30.. Train Loss: 0.728.. Test Loss: 1.055.. Test Accuracy: 0.655.. Test F1 Score: 0.659\n",
      "Epoch: 28/30.. Train Loss: 0.733.. Test Loss: 1.047.. Test Accuracy: 0.676.. Test F1 Score: 0.676\n",
      "Epoch: 29/30.. Train Loss: 0.733.. Test Loss: 1.050.. Test Accuracy: 0.665.. Test F1 Score: 0.670\n",
      "Epoch: 30/30.. Train Loss: 0.727.. Test Loss: 1.038.. Test Accuracy: 0.656.. Test F1 Score: 0.659\n"
     ]
    }
   ],
   "source": [
    "model = TCN(num_inputs, num_channels, kernel_size, num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_50, test_losses_50, test_accuracies_50, test_f1_scores_50 = train_and_test(model, train_dataloader_50, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.579.. Test Loss: 1.195.. Test Accuracy: 0.613.. Test F1 Score: 0.604\n",
      "Epoch: 2/30.. Train Loss: 0.987.. Test Loss: 1.081.. Test Accuracy: 0.637.. Test F1 Score: 0.626\n",
      "Epoch: 3/30.. Train Loss: 0.804.. Test Loss: 1.076.. Test Accuracy: 0.639.. Test F1 Score: 0.641\n",
      "Epoch: 4/30.. Train Loss: 0.730.. Test Loss: 1.078.. Test Accuracy: 0.653.. Test F1 Score: 0.656\n",
      "Epoch: 5/30.. Train Loss: 0.681.. Test Loss: 1.107.. Test Accuracy: 0.627.. Test F1 Score: 0.630\n",
      "Epoch: 6/30.. Train Loss: 0.659.. Test Loss: 1.083.. Test Accuracy: 0.632.. Test F1 Score: 0.637\n",
      "Epoch: 7/30.. Train Loss: 0.623.. Test Loss: 1.131.. Test Accuracy: 0.616.. Test F1 Score: 0.619\n",
      "Epoch: 8/30.. Train Loss: 0.616.. Test Loss: 1.100.. Test Accuracy: 0.642.. Test F1 Score: 0.648\n",
      "Epoch: 9/30.. Train Loss: 0.600.. Test Loss: 1.175.. Test Accuracy: 0.633.. Test F1 Score: 0.639\n",
      "Epoch: 10/30.. Train Loss: 0.594.. Test Loss: 1.145.. Test Accuracy: 0.622.. Test F1 Score: 0.630\n",
      "Epoch: 11/30.. Train Loss: 0.588.. Test Loss: 1.130.. Test Accuracy: 0.645.. Test F1 Score: 0.652\n",
      "Epoch: 12/30.. Train Loss: 0.568.. Test Loss: 1.127.. Test Accuracy: 0.641.. Test F1 Score: 0.646\n",
      "Epoch: 13/30.. Train Loss: 0.559.. Test Loss: 1.127.. Test Accuracy: 0.628.. Test F1 Score: 0.632\n",
      "Epoch: 14/30.. Train Loss: 0.556.. Test Loss: 1.132.. Test Accuracy: 0.626.. Test F1 Score: 0.632\n",
      "Epoch: 15/30.. Train Loss: 0.550.. Test Loss: 1.133.. Test Accuracy: 0.648.. Test F1 Score: 0.655\n",
      "Epoch: 16/30.. Train Loss: 0.545.. Test Loss: 1.181.. Test Accuracy: 0.630.. Test F1 Score: 0.635\n",
      "Epoch: 17/30.. Train Loss: 0.551.. Test Loss: 1.186.. Test Accuracy: 0.615.. Test F1 Score: 0.617\n",
      "Epoch: 18/30.. Train Loss: 0.544.. Test Loss: 1.180.. Test Accuracy: 0.625.. Test F1 Score: 0.625\n",
      "Epoch: 19/30.. Train Loss: 0.534.. Test Loss: 1.133.. Test Accuracy: 0.633.. Test F1 Score: 0.637\n",
      "Epoch: 20/30.. Train Loss: 0.538.. Test Loss: 1.167.. Test Accuracy: 0.617.. Test F1 Score: 0.623\n",
      "Epoch: 21/30.. Train Loss: 0.530.. Test Loss: 1.203.. Test Accuracy: 0.629.. Test F1 Score: 0.634\n",
      "Epoch: 22/30.. Train Loss: 0.524.. Test Loss: 1.218.. Test Accuracy: 0.642.. Test F1 Score: 0.650\n",
      "Epoch: 23/30.. Train Loss: 0.517.. Test Loss: 1.210.. Test Accuracy: 0.630.. Test F1 Score: 0.632\n",
      "Epoch: 24/30.. Train Loss: 0.524.. Test Loss: 1.178.. Test Accuracy: 0.627.. Test F1 Score: 0.631\n",
      "Epoch: 25/30.. Train Loss: 0.521.. Test Loss: 1.231.. Test Accuracy: 0.623.. Test F1 Score: 0.628\n",
      "Epoch: 26/30.. Train Loss: 0.518.. Test Loss: 1.199.. Test Accuracy: 0.636.. Test F1 Score: 0.643\n",
      "Epoch: 27/30.. Train Loss: 0.511.. Test Loss: 1.259.. Test Accuracy: 0.628.. Test F1 Score: 0.630\n",
      "Epoch: 28/30.. Train Loss: 0.504.. Test Loss: 1.221.. Test Accuracy: 0.608.. Test F1 Score: 0.612\n",
      "Epoch: 29/30.. Train Loss: 0.513.. Test Loss: 1.242.. Test Accuracy: 0.647.. Test F1 Score: 0.655\n",
      "Epoch: 30/30.. Train Loss: 0.526.. Test Loss: 1.255.. Test Accuracy: 0.612.. Test F1 Score: 0.606\n"
     ]
    }
   ],
   "source": [
    "model = TCN(num_inputs, num_channels, kernel_size, num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_25, test_losses_25, test_accuracies_25, test_f1_scores_25 = train_and_test(model, train_dataloader_25, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.686.. Test Loss: 1.330.. Test Accuracy: 0.555.. Test F1 Score: 0.545\n",
      "Epoch: 2/30.. Train Loss: 1.041.. Test Loss: 1.219.. Test Accuracy: 0.569.. Test F1 Score: 0.570\n",
      "Epoch: 3/30.. Train Loss: 0.830.. Test Loss: 1.155.. Test Accuracy: 0.557.. Test F1 Score: 0.560\n",
      "Epoch: 4/30.. Train Loss: 0.699.. Test Loss: 1.194.. Test Accuracy: 0.543.. Test F1 Score: 0.540\n",
      "Epoch: 5/30.. Train Loss: 0.643.. Test Loss: 1.153.. Test Accuracy: 0.563.. Test F1 Score: 0.566\n",
      "Epoch: 6/30.. Train Loss: 0.584.. Test Loss: 1.179.. Test Accuracy: 0.554.. Test F1 Score: 0.565\n",
      "Epoch: 7/30.. Train Loss: 0.537.. Test Loss: 1.280.. Test Accuracy: 0.542.. Test F1 Score: 0.552\n",
      "Epoch: 8/30.. Train Loss: 0.528.. Test Loss: 1.185.. Test Accuracy: 0.571.. Test F1 Score: 0.578\n",
      "Epoch: 9/30.. Train Loss: 0.507.. Test Loss: 1.223.. Test Accuracy: 0.561.. Test F1 Score: 0.572\n",
      "Epoch: 10/30.. Train Loss: 0.476.. Test Loss: 1.272.. Test Accuracy: 0.561.. Test F1 Score: 0.571\n",
      "Epoch: 11/30.. Train Loss: 0.470.. Test Loss: 1.214.. Test Accuracy: 0.578.. Test F1 Score: 0.587\n",
      "Epoch: 12/30.. Train Loss: 0.458.. Test Loss: 1.251.. Test Accuracy: 0.568.. Test F1 Score: 0.575\n",
      "Epoch: 13/30.. Train Loss: 0.440.. Test Loss: 1.292.. Test Accuracy: 0.563.. Test F1 Score: 0.563\n",
      "Epoch: 14/30.. Train Loss: 0.438.. Test Loss: 1.331.. Test Accuracy: 0.555.. Test F1 Score: 0.563\n",
      "Epoch: 15/30.. Train Loss: 0.431.. Test Loss: 1.293.. Test Accuracy: 0.557.. Test F1 Score: 0.569\n",
      "Epoch: 16/30.. Train Loss: 0.414.. Test Loss: 1.291.. Test Accuracy: 0.581.. Test F1 Score: 0.587\n",
      "Epoch: 17/30.. Train Loss: 0.429.. Test Loss: 1.450.. Test Accuracy: 0.547.. Test F1 Score: 0.558\n",
      "Epoch: 18/30.. Train Loss: 0.406.. Test Loss: 1.291.. Test Accuracy: 0.573.. Test F1 Score: 0.584\n",
      "Epoch: 19/30.. Train Loss: 0.395.. Test Loss: 1.302.. Test Accuracy: 0.574.. Test F1 Score: 0.584\n",
      "Epoch: 20/30.. Train Loss: 0.396.. Test Loss: 1.307.. Test Accuracy: 0.575.. Test F1 Score: 0.582\n",
      "Epoch: 21/30.. Train Loss: 0.398.. Test Loss: 1.334.. Test Accuracy: 0.572.. Test F1 Score: 0.582\n",
      "Epoch: 22/30.. Train Loss: 0.387.. Test Loss: 1.403.. Test Accuracy: 0.549.. Test F1 Score: 0.553\n",
      "Epoch: 23/30.. Train Loss: 0.401.. Test Loss: 1.380.. Test Accuracy: 0.563.. Test F1 Score: 0.572\n",
      "Epoch: 24/30.. Train Loss: 0.380.. Test Loss: 1.320.. Test Accuracy: 0.580.. Test F1 Score: 0.588\n",
      "Epoch: 25/30.. Train Loss: 0.386.. Test Loss: 1.370.. Test Accuracy: 0.581.. Test F1 Score: 0.588\n",
      "Epoch: 26/30.. Train Loss: 0.368.. Test Loss: 1.414.. Test Accuracy: 0.557.. Test F1 Score: 0.567\n",
      "Epoch: 27/30.. Train Loss: 0.376.. Test Loss: 1.444.. Test Accuracy: 0.555.. Test F1 Score: 0.565\n",
      "Epoch: 28/30.. Train Loss: 0.354.. Test Loss: 1.436.. Test Accuracy: 0.564.. Test F1 Score: 0.572\n",
      "Epoch: 29/30.. Train Loss: 0.372.. Test Loss: 1.459.. Test Accuracy: 0.568.. Test F1 Score: 0.572\n",
      "Epoch: 30/30.. Train Loss: 0.360.. Test Loss: 1.496.. Test Accuracy: 0.554.. Test F1 Score: 0.566\n"
     ]
    }
   ],
   "source": [
    "model = TCN(num_inputs, num_channels, kernel_size, num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_10, test_losses_10, test_accuracies_10, test_f1_scores_10 = train_and_test(model, train_dataloader_10, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune TCN Last Temporal Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 0.992.. Test Loss: 0.960.. Test Accuracy: 0.656.. Test F1 Score: 0.660\n",
      "Epoch: 2/30.. Train Loss: 0.813.. Test Loss: 0.910.. Test Accuracy: 0.706.. Test F1 Score: 0.703\n",
      "Epoch: 3/30.. Train Loss: 0.777.. Test Loss: 0.956.. Test Accuracy: 0.694.. Test F1 Score: 0.688\n",
      "Epoch: 4/30.. Train Loss: 0.751.. Test Loss: 0.954.. Test Accuracy: 0.667.. Test F1 Score: 0.668\n",
      "Epoch: 5/30.. Train Loss: 0.733.. Test Loss: 0.974.. Test Accuracy: 0.696.. Test F1 Score: 0.695\n",
      "Epoch: 6/30.. Train Loss: 0.723.. Test Loss: 0.938.. Test Accuracy: 0.682.. Test F1 Score: 0.681\n",
      "Epoch: 7/30.. Train Loss: 0.715.. Test Loss: 0.956.. Test Accuracy: 0.672.. Test F1 Score: 0.669\n",
      "Epoch: 8/30.. Train Loss: 0.709.. Test Loss: 0.935.. Test Accuracy: 0.685.. Test F1 Score: 0.687\n",
      "Epoch: 9/30.. Train Loss: 0.694.. Test Loss: 0.919.. Test Accuracy: 0.737.. Test F1 Score: 0.734\n",
      "Epoch: 10/30.. Train Loss: 0.690.. Test Loss: 1.045.. Test Accuracy: 0.679.. Test F1 Score: 0.677\n",
      "Epoch: 11/30.. Train Loss: 0.682.. Test Loss: 1.022.. Test Accuracy: 0.660.. Test F1 Score: 0.663\n",
      "Epoch: 12/30.. Train Loss: 0.673.. Test Loss: 0.960.. Test Accuracy: 0.688.. Test F1 Score: 0.688\n",
      "Epoch: 13/30.. Train Loss: 0.666.. Test Loss: 0.978.. Test Accuracy: 0.685.. Test F1 Score: 0.689\n",
      "Epoch: 14/30.. Train Loss: 0.664.. Test Loss: 0.938.. Test Accuracy: 0.683.. Test F1 Score: 0.683\n",
      "Epoch: 15/30.. Train Loss: 0.660.. Test Loss: 0.931.. Test Accuracy: 0.705.. Test F1 Score: 0.706\n",
      "Epoch: 16/30.. Train Loss: 0.642.. Test Loss: 1.039.. Test Accuracy: 0.672.. Test F1 Score: 0.673\n",
      "Epoch: 17/30.. Train Loss: 0.639.. Test Loss: 0.961.. Test Accuracy: 0.679.. Test F1 Score: 0.682\n",
      "Epoch: 18/30.. Train Loss: 0.641.. Test Loss: 0.999.. Test Accuracy: 0.685.. Test F1 Score: 0.687\n",
      "Epoch: 19/30.. Train Loss: 0.638.. Test Loss: 0.946.. Test Accuracy: 0.710.. Test F1 Score: 0.710\n",
      "Epoch: 20/30.. Train Loss: 0.633.. Test Loss: 0.911.. Test Accuracy: 0.714.. Test F1 Score: 0.713\n",
      "Epoch: 21/30.. Train Loss: 0.632.. Test Loss: 0.974.. Test Accuracy: 0.677.. Test F1 Score: 0.679\n",
      "Epoch: 22/30.. Train Loss: 0.623.. Test Loss: 1.005.. Test Accuracy: 0.688.. Test F1 Score: 0.689\n",
      "Epoch: 23/30.. Train Loss: 0.620.. Test Loss: 0.948.. Test Accuracy: 0.706.. Test F1 Score: 0.707\n",
      "Epoch: 24/30.. Train Loss: 0.622.. Test Loss: 0.981.. Test Accuracy: 0.670.. Test F1 Score: 0.671\n",
      "Epoch: 25/30.. Train Loss: 0.612.. Test Loss: 1.024.. Test Accuracy: 0.673.. Test F1 Score: 0.679\n",
      "Epoch: 26/30.. Train Loss: 0.607.. Test Loss: 0.975.. Test Accuracy: 0.688.. Test F1 Score: 0.689\n",
      "Epoch: 27/30.. Train Loss: 0.610.. Test Loss: 1.048.. Test Accuracy: 0.673.. Test F1 Score: 0.678\n",
      "Epoch: 28/30.. Train Loss: 0.606.. Test Loss: 1.018.. Test Accuracy: 0.688.. Test F1 Score: 0.689\n",
      "Epoch: 29/30.. Train Loss: 0.599.. Test Loss: 0.980.. Test Accuracy: 0.694.. Test F1 Score: 0.697\n",
      "Epoch: 30/30.. Train Loss: 0.602.. Test Loss: 1.054.. Test Accuracy: 0.681.. Test F1 Score: 0.684\n"
     ]
    }
   ],
   "source": [
    "model = TCN(num_inputs, num_channels, kernel_size, num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
    "\n",
    "# Freezing all layers initially\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layers from the last TemporalBlock's conv2 onwards\n",
    "num_levels = len(model.tcn)  # Number of TemporalBlocks in your TCN\n",
    "for i, block in enumerate(model.tcn):\n",
    "    if i == num_levels - 1:  # Check if it's the last TemporalBlock\n",
    "        # Unfreeze the conv2 layer and any subsequent layers within this block\n",
    "        unfreeze = False\n",
    "        for name, param in block.named_parameters():\n",
    "            if 'conv2' in name:\n",
    "                unfreeze = True\n",
    "            if unfreeze:\n",
    "                param.requires_grad = True\n",
    "\n",
    "# Unfreeze the classification layer\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(model, train_dataloader, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.032.. Test Loss: 0.972.. Test Accuracy: 0.674.. Test F1 Score: 0.666\n",
      "Epoch: 2/30.. Train Loss: 0.852.. Test Loss: 1.154.. Test Accuracy: 0.676.. Test F1 Score: 0.674\n",
      "Epoch: 3/30.. Train Loss: 0.826.. Test Loss: 0.969.. Test Accuracy: 0.682.. Test F1 Score: 0.675\n",
      "Epoch: 4/30.. Train Loss: 0.801.. Test Loss: 0.976.. Test Accuracy: 0.666.. Test F1 Score: 0.655\n",
      "Epoch: 5/30.. Train Loss: 0.778.. Test Loss: 1.054.. Test Accuracy: 0.659.. Test F1 Score: 0.660\n",
      "Epoch: 6/30.. Train Loss: 0.766.. Test Loss: 0.991.. Test Accuracy: 0.654.. Test F1 Score: 0.651\n",
      "Epoch: 7/30.. Train Loss: 0.756.. Test Loss: 0.972.. Test Accuracy: 0.678.. Test F1 Score: 0.675\n",
      "Epoch: 8/30.. Train Loss: 0.733.. Test Loss: 1.048.. Test Accuracy: 0.658.. Test F1 Score: 0.661\n",
      "Epoch: 9/30.. Train Loss: 0.734.. Test Loss: 1.081.. Test Accuracy: 0.659.. Test F1 Score: 0.660\n",
      "Epoch: 10/30.. Train Loss: 0.720.. Test Loss: 1.027.. Test Accuracy: 0.667.. Test F1 Score: 0.671\n",
      "Epoch: 11/30.. Train Loss: 0.715.. Test Loss: 0.961.. Test Accuracy: 0.669.. Test F1 Score: 0.662\n",
      "Epoch: 12/30.. Train Loss: 0.707.. Test Loss: 0.982.. Test Accuracy: 0.684.. Test F1 Score: 0.687\n",
      "Epoch: 13/30.. Train Loss: 0.695.. Test Loss: 0.988.. Test Accuracy: 0.689.. Test F1 Score: 0.689\n",
      "Epoch: 14/30.. Train Loss: 0.690.. Test Loss: 1.032.. Test Accuracy: 0.669.. Test F1 Score: 0.661\n",
      "Epoch: 15/30.. Train Loss: 0.689.. Test Loss: 1.033.. Test Accuracy: 0.675.. Test F1 Score: 0.676\n",
      "Epoch: 16/30.. Train Loss: 0.680.. Test Loss: 1.089.. Test Accuracy: 0.659.. Test F1 Score: 0.653\n",
      "Epoch: 17/30.. Train Loss: 0.676.. Test Loss: 1.020.. Test Accuracy: 0.679.. Test F1 Score: 0.677\n",
      "Epoch: 18/30.. Train Loss: 0.665.. Test Loss: 1.057.. Test Accuracy: 0.677.. Test F1 Score: 0.681\n",
      "Epoch: 19/30.. Train Loss: 0.664.. Test Loss: 1.103.. Test Accuracy: 0.653.. Test F1 Score: 0.647\n",
      "Epoch: 20/30.. Train Loss: 0.659.. Test Loss: 1.117.. Test Accuracy: 0.681.. Test F1 Score: 0.682\n",
      "Epoch: 21/30.. Train Loss: 0.643.. Test Loss: 1.017.. Test Accuracy: 0.690.. Test F1 Score: 0.690\n",
      "Epoch: 22/30.. Train Loss: 0.639.. Test Loss: 1.059.. Test Accuracy: 0.685.. Test F1 Score: 0.686\n",
      "Epoch: 23/30.. Train Loss: 0.634.. Test Loss: 1.079.. Test Accuracy: 0.700.. Test F1 Score: 0.697\n",
      "Epoch: 24/30.. Train Loss: 0.635.. Test Loss: 1.077.. Test Accuracy: 0.670.. Test F1 Score: 0.670\n",
      "Epoch: 25/30.. Train Loss: 0.635.. Test Loss: 1.152.. Test Accuracy: 0.691.. Test F1 Score: 0.692\n",
      "Epoch: 26/30.. Train Loss: 0.625.. Test Loss: 1.069.. Test Accuracy: 0.673.. Test F1 Score: 0.674\n",
      "Epoch: 27/30.. Train Loss: 0.625.. Test Loss: 1.114.. Test Accuracy: 0.695.. Test F1 Score: 0.695\n",
      "Epoch: 28/30.. Train Loss: 0.616.. Test Loss: 1.081.. Test Accuracy: 0.695.. Test F1 Score: 0.697\n",
      "Epoch: 29/30.. Train Loss: 0.612.. Test Loss: 1.075.. Test Accuracy: 0.685.. Test F1 Score: 0.684\n",
      "Epoch: 30/30.. Train Loss: 0.620.. Test Loss: 1.174.. Test Accuracy: 0.663.. Test F1 Score: 0.667\n"
     ]
    }
   ],
   "source": [
    "model = TCN(num_inputs, num_channels, kernel_size, num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
    "\n",
    "# Freezing all layers initially\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layers from the last TemporalBlock's conv2 onwards\n",
    "num_levels = len(model.tcn)  # Number of TemporalBlocks in your TCN\n",
    "for i, block in enumerate(model.tcn):\n",
    "    if i == num_levels - 1:  # Check if it's the last TemporalBlock\n",
    "        # Unfreeze the conv2 layer and any subsequent layers within this block\n",
    "        unfreeze = False\n",
    "        for name, param in block.named_parameters():\n",
    "            if 'conv2' in name:\n",
    "                unfreeze = True\n",
    "            if unfreeze:\n",
    "                param.requires_grad = True\n",
    "\n",
    "# Unfreeze the classification layer\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_75, test_losses_75, test_accuracies_75, test_f1_scores_75 = train_and_test(model, train_dataloader_75, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.009.. Test Loss: 1.042.. Test Accuracy: 0.653.. Test F1 Score: 0.649\n",
      "Epoch: 2/30.. Train Loss: 0.792.. Test Loss: 0.957.. Test Accuracy: 0.644.. Test F1 Score: 0.644\n",
      "Epoch: 3/30.. Train Loss: 0.749.. Test Loss: 1.005.. Test Accuracy: 0.649.. Test F1 Score: 0.648\n",
      "Epoch: 4/30.. Train Loss: 0.713.. Test Loss: 0.981.. Test Accuracy: 0.677.. Test F1 Score: 0.681\n",
      "Epoch: 5/30.. Train Loss: 0.693.. Test Loss: 1.052.. Test Accuracy: 0.647.. Test F1 Score: 0.647\n",
      "Epoch: 6/30.. Train Loss: 0.675.. Test Loss: 1.044.. Test Accuracy: 0.664.. Test F1 Score: 0.664\n",
      "Epoch: 7/30.. Train Loss: 0.674.. Test Loss: 1.084.. Test Accuracy: 0.664.. Test F1 Score: 0.668\n",
      "Epoch: 8/30.. Train Loss: 0.650.. Test Loss: 1.125.. Test Accuracy: 0.660.. Test F1 Score: 0.664\n",
      "Epoch: 9/30.. Train Loss: 0.639.. Test Loss: 1.056.. Test Accuracy: 0.681.. Test F1 Score: 0.682\n",
      "Epoch: 10/30.. Train Loss: 0.636.. Test Loss: 1.050.. Test Accuracy: 0.674.. Test F1 Score: 0.678\n",
      "Epoch: 11/30.. Train Loss: 0.620.. Test Loss: 1.066.. Test Accuracy: 0.658.. Test F1 Score: 0.663\n",
      "Epoch: 12/30.. Train Loss: 0.613.. Test Loss: 1.050.. Test Accuracy: 0.674.. Test F1 Score: 0.673\n",
      "Epoch: 13/30.. Train Loss: 0.608.. Test Loss: 1.153.. Test Accuracy: 0.667.. Test F1 Score: 0.672\n",
      "Epoch: 14/30.. Train Loss: 0.600.. Test Loss: 1.097.. Test Accuracy: 0.660.. Test F1 Score: 0.663\n",
      "Epoch: 15/30.. Train Loss: 0.601.. Test Loss: 1.204.. Test Accuracy: 0.657.. Test F1 Score: 0.658\n",
      "Epoch: 16/30.. Train Loss: 0.585.. Test Loss: 0.934.. Test Accuracy: 0.679.. Test F1 Score: 0.678\n",
      "Epoch: 17/30.. Train Loss: 0.583.. Test Loss: 1.106.. Test Accuracy: 0.674.. Test F1 Score: 0.676\n",
      "Epoch: 18/30.. Train Loss: 0.576.. Test Loss: 1.188.. Test Accuracy: 0.674.. Test F1 Score: 0.675\n",
      "Epoch: 19/30.. Train Loss: 0.574.. Test Loss: 1.150.. Test Accuracy: 0.668.. Test F1 Score: 0.673\n",
      "Epoch: 20/30.. Train Loss: 0.582.. Test Loss: 0.970.. Test Accuracy: 0.675.. Test F1 Score: 0.675\n",
      "Epoch: 21/30.. Train Loss: 0.574.. Test Loss: 1.180.. Test Accuracy: 0.662.. Test F1 Score: 0.666\n",
      "Epoch: 22/30.. Train Loss: 0.570.. Test Loss: 1.186.. Test Accuracy: 0.680.. Test F1 Score: 0.682\n",
      "Epoch: 23/30.. Train Loss: 0.567.. Test Loss: 1.273.. Test Accuracy: 0.655.. Test F1 Score: 0.659\n",
      "Epoch: 24/30.. Train Loss: 0.565.. Test Loss: 1.160.. Test Accuracy: 0.670.. Test F1 Score: 0.674\n",
      "Epoch: 25/30.. Train Loss: 0.558.. Test Loss: 1.185.. Test Accuracy: 0.668.. Test F1 Score: 0.671\n",
      "Epoch: 26/30.. Train Loss: 0.555.. Test Loss: 1.233.. Test Accuracy: 0.659.. Test F1 Score: 0.665\n",
      "Epoch: 27/30.. Train Loss: 0.554.. Test Loss: 1.032.. Test Accuracy: 0.654.. Test F1 Score: 0.661\n",
      "Epoch: 28/30.. Train Loss: 0.538.. Test Loss: 1.154.. Test Accuracy: 0.663.. Test F1 Score: 0.666\n",
      "Epoch: 29/30.. Train Loss: 0.540.. Test Loss: 1.256.. Test Accuracy: 0.650.. Test F1 Score: 0.650\n",
      "Epoch: 30/30.. Train Loss: 0.552.. Test Loss: 1.232.. Test Accuracy: 0.677.. Test F1 Score: 0.679\n"
     ]
    }
   ],
   "source": [
    "model = TCN(num_inputs, num_channels, kernel_size, num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
    "\n",
    "# Freezing all layers initially\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layers from the last TemporalBlock's conv2 onwards\n",
    "num_levels = len(model.tcn)  # Number of TemporalBlocks in your TCN\n",
    "for i, block in enumerate(model.tcn):\n",
    "    if i == num_levels - 1:  # Check if it's the last TemporalBlock\n",
    "        # Unfreeze the conv2 layer and any subsequent layers within this block\n",
    "        unfreeze = False\n",
    "        for name, param in block.named_parameters():\n",
    "            if 'conv2' in name:\n",
    "                unfreeze = True\n",
    "            if unfreeze:\n",
    "                param.requires_grad = True\n",
    "\n",
    "# Unfreeze the classification layer\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_50, test_losses_50, test_accuracies_50, test_f1_scores_50 = train_and_test(model, train_dataloader_50, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.076.. Test Loss: 1.299.. Test Accuracy: 0.594.. Test F1 Score: 0.564\n",
      "Epoch: 2/30.. Train Loss: 0.642.. Test Loss: 1.222.. Test Accuracy: 0.625.. Test F1 Score: 0.625\n",
      "Epoch: 3/30.. Train Loss: 0.576.. Test Loss: 1.268.. Test Accuracy: 0.638.. Test F1 Score: 0.640\n",
      "Epoch: 4/30.. Train Loss: 0.523.. Test Loss: 1.342.. Test Accuracy: 0.634.. Test F1 Score: 0.634\n",
      "Epoch: 5/30.. Train Loss: 0.490.. Test Loss: 1.283.. Test Accuracy: 0.653.. Test F1 Score: 0.660\n",
      "Epoch: 6/30.. Train Loss: 0.498.. Test Loss: 1.380.. Test Accuracy: 0.640.. Test F1 Score: 0.642\n",
      "Epoch: 7/30.. Train Loss: 0.466.. Test Loss: 1.318.. Test Accuracy: 0.622.. Test F1 Score: 0.626\n",
      "Epoch: 8/30.. Train Loss: 0.470.. Test Loss: 1.408.. Test Accuracy: 0.642.. Test F1 Score: 0.650\n",
      "Epoch: 9/30.. Train Loss: 0.444.. Test Loss: 1.453.. Test Accuracy: 0.619.. Test F1 Score: 0.617\n",
      "Epoch: 10/30.. Train Loss: 0.434.. Test Loss: 1.547.. Test Accuracy: 0.643.. Test F1 Score: 0.641\n",
      "Epoch: 11/30.. Train Loss: 0.433.. Test Loss: 1.778.. Test Accuracy: 0.532.. Test F1 Score: 0.522\n",
      "Epoch: 12/30.. Train Loss: 0.424.. Test Loss: 1.514.. Test Accuracy: 0.624.. Test F1 Score: 0.622\n",
      "Epoch: 13/30.. Train Loss: 0.406.. Test Loss: 1.720.. Test Accuracy: 0.631.. Test F1 Score: 0.635\n",
      "Epoch: 14/30.. Train Loss: 0.413.. Test Loss: 1.590.. Test Accuracy: 0.615.. Test F1 Score: 0.628\n",
      "Epoch: 15/30.. Train Loss: 0.398.. Test Loss: 1.698.. Test Accuracy: 0.638.. Test F1 Score: 0.647\n",
      "Epoch: 16/30.. Train Loss: 0.405.. Test Loss: 1.591.. Test Accuracy: 0.639.. Test F1 Score: 0.647\n",
      "Epoch: 17/30.. Train Loss: 0.407.. Test Loss: 1.678.. Test Accuracy: 0.636.. Test F1 Score: 0.631\n",
      "Epoch: 18/30.. Train Loss: 0.380.. Test Loss: 1.626.. Test Accuracy: 0.621.. Test F1 Score: 0.629\n",
      "Epoch: 19/30.. Train Loss: 0.393.. Test Loss: 1.698.. Test Accuracy: 0.631.. Test F1 Score: 0.635\n",
      "Epoch: 20/30.. Train Loss: 0.375.. Test Loss: 1.919.. Test Accuracy: 0.607.. Test F1 Score: 0.607\n",
      "Epoch: 21/30.. Train Loss: 0.369.. Test Loss: 1.869.. Test Accuracy: 0.608.. Test F1 Score: 0.600\n",
      "Epoch: 22/30.. Train Loss: 0.383.. Test Loss: 1.772.. Test Accuracy: 0.604.. Test F1 Score: 0.605\n",
      "Epoch: 23/30.. Train Loss: 0.369.. Test Loss: 1.814.. Test Accuracy: 0.606.. Test F1 Score: 0.605\n",
      "Epoch: 24/30.. Train Loss: 0.354.. Test Loss: 2.043.. Test Accuracy: 0.592.. Test F1 Score: 0.608\n",
      "Epoch: 25/30.. Train Loss: 0.358.. Test Loss: 2.013.. Test Accuracy: 0.602.. Test F1 Score: 0.606\n",
      "Epoch: 26/30.. Train Loss: 0.354.. Test Loss: 1.804.. Test Accuracy: 0.620.. Test F1 Score: 0.631\n",
      "Epoch: 27/30.. Train Loss: 0.356.. Test Loss: 1.842.. Test Accuracy: 0.650.. Test F1 Score: 0.656\n",
      "Epoch: 28/30.. Train Loss: 0.350.. Test Loss: 1.952.. Test Accuracy: 0.625.. Test F1 Score: 0.634\n",
      "Epoch: 29/30.. Train Loss: 0.352.. Test Loss: 2.024.. Test Accuracy: 0.626.. Test F1 Score: 0.632\n",
      "Epoch: 30/30.. Train Loss: 0.362.. Test Loss: 1.854.. Test Accuracy: 0.650.. Test F1 Score: 0.653\n"
     ]
    }
   ],
   "source": [
    "model = TCN(num_inputs, num_channels, kernel_size, num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
    "\n",
    "# Freezing all layers initially\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layers from the last TemporalBlock's conv2 onwards\n",
    "num_levels = len(model.tcn)  # Number of TemporalBlocks in your TCN\n",
    "for i, block in enumerate(model.tcn):\n",
    "    if i == num_levels - 1:  # Check if it's the last TemporalBlock\n",
    "        # Unfreeze the conv2 layer and any subsequent layers within this block\n",
    "        unfreeze = False\n",
    "        for name, param in block.named_parameters():\n",
    "            if 'conv2' in name:\n",
    "                unfreeze = True\n",
    "            if unfreeze:\n",
    "                param.requires_grad = True\n",
    "\n",
    "# Unfreeze the classification layer\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_25, test_losses_25, test_accuracies_25, test_f1_scores_25 = train_and_test(model, train_dataloader_25, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 1.226.. Test Loss: 1.270.. Test Accuracy: 0.549.. Test F1 Score: 0.528\n",
      "Epoch: 2/30.. Train Loss: 0.569.. Test Loss: 1.321.. Test Accuracy: 0.569.. Test F1 Score: 0.574\n",
      "Epoch: 3/30.. Train Loss: 0.486.. Test Loss: 1.474.. Test Accuracy: 0.558.. Test F1 Score: 0.557\n",
      "Epoch: 4/30.. Train Loss: 0.429.. Test Loss: 1.639.. Test Accuracy: 0.567.. Test F1 Score: 0.569\n",
      "Epoch: 5/30.. Train Loss: 0.395.. Test Loss: 1.596.. Test Accuracy: 0.556.. Test F1 Score: 0.557\n",
      "Epoch: 6/30.. Train Loss: 0.379.. Test Loss: 1.351.. Test Accuracy: 0.596.. Test F1 Score: 0.596\n",
      "Epoch: 7/30.. Train Loss: 0.364.. Test Loss: 1.639.. Test Accuracy: 0.623.. Test F1 Score: 0.620\n",
      "Epoch: 8/30.. Train Loss: 0.354.. Test Loss: 1.767.. Test Accuracy: 0.558.. Test F1 Score: 0.566\n",
      "Epoch: 9/30.. Train Loss: 0.337.. Test Loss: 1.644.. Test Accuracy: 0.555.. Test F1 Score: 0.558\n",
      "Epoch: 10/30.. Train Loss: 0.315.. Test Loss: 2.005.. Test Accuracy: 0.567.. Test F1 Score: 0.573\n",
      "Epoch: 11/30.. Train Loss: 0.304.. Test Loss: 1.885.. Test Accuracy: 0.564.. Test F1 Score: 0.572\n",
      "Epoch: 12/30.. Train Loss: 0.289.. Test Loss: 2.124.. Test Accuracy: 0.590.. Test F1 Score: 0.590\n",
      "Epoch: 13/30.. Train Loss: 0.299.. Test Loss: 1.747.. Test Accuracy: 0.571.. Test F1 Score: 0.573\n",
      "Epoch: 14/30.. Train Loss: 0.284.. Test Loss: 1.744.. Test Accuracy: 0.599.. Test F1 Score: 0.602\n",
      "Epoch: 15/30.. Train Loss: 0.274.. Test Loss: 2.199.. Test Accuracy: 0.536.. Test F1 Score: 0.552\n",
      "Epoch: 16/30.. Train Loss: 0.260.. Test Loss: 1.981.. Test Accuracy: 0.604.. Test F1 Score: 0.607\n",
      "Epoch: 17/30.. Train Loss: 0.279.. Test Loss: 2.185.. Test Accuracy: 0.554.. Test F1 Score: 0.562\n",
      "Epoch: 18/30.. Train Loss: 0.228.. Test Loss: 2.442.. Test Accuracy: 0.573.. Test F1 Score: 0.575\n",
      "Epoch: 19/30.. Train Loss: 0.246.. Test Loss: 2.151.. Test Accuracy: 0.566.. Test F1 Score: 0.567\n",
      "Epoch: 20/30.. Train Loss: 0.245.. Test Loss: 2.496.. Test Accuracy: 0.553.. Test F1 Score: 0.554\n",
      "Epoch: 21/30.. Train Loss: 0.270.. Test Loss: 2.250.. Test Accuracy: 0.547.. Test F1 Score: 0.537\n",
      "Epoch: 22/30.. Train Loss: 0.256.. Test Loss: 2.305.. Test Accuracy: 0.544.. Test F1 Score: 0.559\n",
      "Epoch: 23/30.. Train Loss: 0.264.. Test Loss: 2.237.. Test Accuracy: 0.493.. Test F1 Score: 0.493\n",
      "Epoch: 24/30.. Train Loss: 0.233.. Test Loss: 2.401.. Test Accuracy: 0.499.. Test F1 Score: 0.491\n",
      "Epoch: 25/30.. Train Loss: 0.223.. Test Loss: 3.016.. Test Accuracy: 0.540.. Test F1 Score: 0.539\n",
      "Epoch: 26/30.. Train Loss: 0.191.. Test Loss: 2.547.. Test Accuracy: 0.589.. Test F1 Score: 0.592\n",
      "Epoch: 27/30.. Train Loss: 0.199.. Test Loss: 2.787.. Test Accuracy: 0.532.. Test F1 Score: 0.524\n",
      "Epoch: 28/30.. Train Loss: 0.201.. Test Loss: 2.919.. Test Accuracy: 0.501.. Test F1 Score: 0.503\n",
      "Epoch: 29/30.. Train Loss: 0.212.. Test Loss: 3.302.. Test Accuracy: 0.534.. Test F1 Score: 0.534\n",
      "Epoch: 30/30.. Train Loss: 0.205.. Test Loss: 2.489.. Test Accuracy: 0.510.. Test F1 Score: 0.516\n"
     ]
    }
   ],
   "source": [
    "model = TCN(num_inputs, num_channels, kernel_size, num_classes=4)\n",
    "\n",
    "#load pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
    "\n",
    "# Freezing all layers initially\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layers from the last TemporalBlock's conv2 onwards\n",
    "num_levels = len(model.tcn)  # Number of TemporalBlocks in your TCN\n",
    "for i, block in enumerate(model.tcn):\n",
    "    if i == num_levels - 1:  # Check if it's the last TemporalBlock\n",
    "        # Unfreeze the conv2 layer and any subsequent layers within this block\n",
    "        unfreeze = False\n",
    "        for name, param in block.named_parameters():\n",
    "            if 'conv2' in name:\n",
    "                unfreeze = True\n",
    "            if unfreeze:\n",
    "                param.requires_grad = True\n",
    "\n",
    "# Unfreeze the classification layer\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses_10, test_losses_10, test_accuracies_10, test_f1_scores_10 = train_and_test(model, train_dataloader_10, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 0.770.. Test Loss: 1.092.. Test Accuracy: 0.646.. Test F1 Score: 0.660\n",
      "Epoch: 2/30.. Train Loss: 0.535.. Test Loss: 1.169.. Test Accuracy: 0.675.. Test F1 Score: 0.681\n",
      "Epoch: 3/30.. Train Loss: 0.455.. Test Loss: 1.168.. Test Accuracy: 0.639.. Test F1 Score: 0.646\n",
      "Epoch: 4/30.. Train Loss: 0.409.. Test Loss: 1.129.. Test Accuracy: 0.689.. Test F1 Score: 0.690\n",
      "Epoch: 5/30.. Train Loss: 0.370.. Test Loss: 1.112.. Test Accuracy: 0.654.. Test F1 Score: 0.658\n",
      "Epoch: 6/30.. Train Loss: 0.343.. Test Loss: 1.271.. Test Accuracy: 0.659.. Test F1 Score: 0.658\n",
      "Epoch: 7/30.. Train Loss: 0.307.. Test Loss: 1.493.. Test Accuracy: 0.617.. Test F1 Score: 0.613\n",
      "Epoch: 8/30.. Train Loss: 0.271.. Test Loss: 1.406.. Test Accuracy: 0.670.. Test F1 Score: 0.670\n",
      "Epoch: 9/30.. Train Loss: 0.270.. Test Loss: 1.394.. Test Accuracy: 0.627.. Test F1 Score: 0.634\n",
      "Epoch: 10/30.. Train Loss: 0.245.. Test Loss: 1.680.. Test Accuracy: 0.638.. Test F1 Score: 0.643\n",
      "Epoch: 11/30.. Train Loss: 0.216.. Test Loss: 1.643.. Test Accuracy: 0.670.. Test F1 Score: 0.671\n",
      "Epoch: 12/30.. Train Loss: 0.229.. Test Loss: 1.664.. Test Accuracy: 0.624.. Test F1 Score: 0.627\n",
      "Epoch: 13/30.. Train Loss: 0.204.. Test Loss: 1.763.. Test Accuracy: 0.659.. Test F1 Score: 0.661\n",
      "Epoch: 14/30.. Train Loss: 0.201.. Test Loss: 1.937.. Test Accuracy: 0.637.. Test F1 Score: 0.639\n",
      "Epoch: 15/30.. Train Loss: 0.187.. Test Loss: 1.890.. Test Accuracy: 0.697.. Test F1 Score: 0.703\n",
      "Epoch: 16/30.. Train Loss: 0.193.. Test Loss: 2.238.. Test Accuracy: 0.675.. Test F1 Score: 0.680\n",
      "Epoch: 17/30.. Train Loss: 0.173.. Test Loss: 2.100.. Test Accuracy: 0.623.. Test F1 Score: 0.623\n",
      "Epoch: 18/30.. Train Loss: 0.170.. Test Loss: 2.348.. Test Accuracy: 0.611.. Test F1 Score: 0.611\n",
      "Epoch: 19/30.. Train Loss: 0.156.. Test Loss: 2.612.. Test Accuracy: 0.615.. Test F1 Score: 0.613\n",
      "Epoch: 20/30.. Train Loss: 0.161.. Test Loss: 2.193.. Test Accuracy: 0.691.. Test F1 Score: 0.692\n",
      "Epoch: 21/30.. Train Loss: 0.158.. Test Loss: 2.433.. Test Accuracy: 0.608.. Test F1 Score: 0.615\n",
      "Epoch: 22/30.. Train Loss: 0.156.. Test Loss: 2.477.. Test Accuracy: 0.660.. Test F1 Score: 0.659\n",
      "Epoch: 23/30.. Train Loss: 0.149.. Test Loss: 2.591.. Test Accuracy: 0.631.. Test F1 Score: 0.632\n",
      "Epoch: 24/30.. Train Loss: 0.171.. Test Loss: 2.872.. Test Accuracy: 0.644.. Test F1 Score: 0.644\n",
      "Epoch: 25/30.. Train Loss: 0.129.. Test Loss: 3.069.. Test Accuracy: 0.604.. Test F1 Score: 0.610\n",
      "Epoch: 26/30.. Train Loss: 0.138.. Test Loss: 2.549.. Test Accuracy: 0.644.. Test F1 Score: 0.649\n",
      "Epoch: 27/30.. Train Loss: 0.134.. Test Loss: 3.355.. Test Accuracy: 0.619.. Test F1 Score: 0.619\n",
      "Epoch: 28/30.. Train Loss: 0.140.. Test Loss: 3.618.. Test Accuracy: 0.585.. Test F1 Score: 0.582\n",
      "Epoch: 29/30.. Train Loss: 0.124.. Test Loss: 3.245.. Test Accuracy: 0.639.. Test F1 Score: 0.645\n",
      "Epoch: 30/30.. Train Loss: 0.124.. Test Loss: 3.158.. Test Accuracy: 0.614.. Test F1 Score: 0.618\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(model, train_dataloader, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 0.806.. Test Loss: 1.149.. Test Accuracy: 0.646.. Test F1 Score: 0.650\n",
      "Epoch: 2/30.. Train Loss: 0.558.. Test Loss: 1.087.. Test Accuracy: 0.620.. Test F1 Score: 0.649\n",
      "Epoch: 3/30.. Train Loss: 0.464.. Test Loss: 1.488.. Test Accuracy: 0.589.. Test F1 Score: 0.589\n",
      "Epoch: 4/30.. Train Loss: 0.409.. Test Loss: 1.528.. Test Accuracy: 0.613.. Test F1 Score: 0.621\n",
      "Epoch: 5/30.. Train Loss: 0.377.. Test Loss: 1.395.. Test Accuracy: 0.621.. Test F1 Score: 0.634\n",
      "Epoch: 6/30.. Train Loss: 0.333.. Test Loss: 1.558.. Test Accuracy: 0.604.. Test F1 Score: 0.611\n",
      "Epoch: 7/30.. Train Loss: 0.308.. Test Loss: 1.413.. Test Accuracy: 0.671.. Test F1 Score: 0.679\n",
      "Epoch: 8/30.. Train Loss: 0.283.. Test Loss: 1.537.. Test Accuracy: 0.601.. Test F1 Score: 0.603\n",
      "Epoch: 9/30.. Train Loss: 0.263.. Test Loss: 1.491.. Test Accuracy: 0.659.. Test F1 Score: 0.662\n",
      "Epoch: 10/30.. Train Loss: 0.238.. Test Loss: 2.041.. Test Accuracy: 0.590.. Test F1 Score: 0.591\n",
      "Epoch: 11/30.. Train Loss: 0.217.. Test Loss: 1.922.. Test Accuracy: 0.620.. Test F1 Score: 0.633\n",
      "Epoch: 12/30.. Train Loss: 0.220.. Test Loss: 2.267.. Test Accuracy: 0.580.. Test F1 Score: 0.582\n",
      "Epoch: 13/30.. Train Loss: 0.206.. Test Loss: 2.306.. Test Accuracy: 0.594.. Test F1 Score: 0.602\n",
      "Epoch: 14/30.. Train Loss: 0.192.. Test Loss: 2.353.. Test Accuracy: 0.569.. Test F1 Score: 0.572\n",
      "Epoch: 15/30.. Train Loss: 0.206.. Test Loss: 2.710.. Test Accuracy: 0.588.. Test F1 Score: 0.594\n",
      "Epoch: 16/30.. Train Loss: 0.180.. Test Loss: 2.879.. Test Accuracy: 0.582.. Test F1 Score: 0.599\n",
      "Epoch: 17/30.. Train Loss: 0.177.. Test Loss: 2.631.. Test Accuracy: 0.604.. Test F1 Score: 0.609\n",
      "Epoch: 18/30.. Train Loss: 0.153.. Test Loss: 2.630.. Test Accuracy: 0.581.. Test F1 Score: 0.586\n",
      "Epoch: 19/30.. Train Loss: 0.154.. Test Loss: 2.488.. Test Accuracy: 0.637.. Test F1 Score: 0.649\n",
      "Epoch: 20/30.. Train Loss: 0.171.. Test Loss: 2.843.. Test Accuracy: 0.603.. Test F1 Score: 0.612\n",
      "Epoch: 21/30.. Train Loss: 0.163.. Test Loss: 3.030.. Test Accuracy: 0.557.. Test F1 Score: 0.565\n",
      "Epoch: 22/30.. Train Loss: 0.154.. Test Loss: 2.699.. Test Accuracy: 0.582.. Test F1 Score: 0.592\n",
      "Epoch: 23/30.. Train Loss: 0.139.. Test Loss: 2.636.. Test Accuracy: 0.637.. Test F1 Score: 0.644\n",
      "Epoch: 24/30.. Train Loss: 0.165.. Test Loss: 3.027.. Test Accuracy: 0.572.. Test F1 Score: 0.590\n",
      "Epoch: 25/30.. Train Loss: 0.146.. Test Loss: 2.738.. Test Accuracy: 0.570.. Test F1 Score: 0.584\n",
      "Epoch: 26/30.. Train Loss: 0.129.. Test Loss: 3.062.. Test Accuracy: 0.576.. Test F1 Score: 0.585\n",
      "Epoch: 27/30.. Train Loss: 0.134.. Test Loss: 3.543.. Test Accuracy: 0.573.. Test F1 Score: 0.582\n",
      "Epoch: 28/30.. Train Loss: 0.141.. Test Loss: 2.914.. Test Accuracy: 0.589.. Test F1 Score: 0.598\n",
      "Epoch: 29/30.. Train Loss: 0.118.. Test Loss: 2.774.. Test Accuracy: 0.629.. Test F1 Score: 0.646\n",
      "Epoch: 30/30.. Train Loss: 0.121.. Test Loss: 3.351.. Test Accuracy: 0.571.. Test F1 Score: 0.578\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(model, train_dataloader_75, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 0.794.. Test Loss: 1.206.. Test Accuracy: 0.666.. Test F1 Score: 0.678\n",
      "Epoch: 2/30.. Train Loss: 0.550.. Test Loss: 1.212.. Test Accuracy: 0.618.. Test F1 Score: 0.629\n",
      "Epoch: 3/30.. Train Loss: 0.458.. Test Loss: 1.299.. Test Accuracy: 0.636.. Test F1 Score: 0.638\n",
      "Epoch: 4/30.. Train Loss: 0.408.. Test Loss: 1.058.. Test Accuracy: 0.665.. Test F1 Score: 0.674\n",
      "Epoch: 5/30.. Train Loss: 0.367.. Test Loss: 1.487.. Test Accuracy: 0.629.. Test F1 Score: 0.636\n",
      "Epoch: 6/30.. Train Loss: 0.321.. Test Loss: 1.470.. Test Accuracy: 0.655.. Test F1 Score: 0.664\n",
      "Epoch: 7/30.. Train Loss: 0.288.. Test Loss: 1.351.. Test Accuracy: 0.677.. Test F1 Score: 0.681\n",
      "Epoch: 8/30.. Train Loss: 0.261.. Test Loss: 1.667.. Test Accuracy: 0.644.. Test F1 Score: 0.649\n",
      "Epoch: 9/30.. Train Loss: 0.240.. Test Loss: 1.883.. Test Accuracy: 0.637.. Test F1 Score: 0.643\n",
      "Epoch: 10/30.. Train Loss: 0.238.. Test Loss: 1.898.. Test Accuracy: 0.645.. Test F1 Score: 0.650\n",
      "Epoch: 11/30.. Train Loss: 0.199.. Test Loss: 2.285.. Test Accuracy: 0.630.. Test F1 Score: 0.633\n",
      "Epoch: 12/30.. Train Loss: 0.184.. Test Loss: 2.162.. Test Accuracy: 0.614.. Test F1 Score: 0.614\n",
      "Epoch: 13/30.. Train Loss: 0.169.. Test Loss: 2.666.. Test Accuracy: 0.596.. Test F1 Score: 0.595\n",
      "Epoch: 14/30.. Train Loss: 0.154.. Test Loss: 2.661.. Test Accuracy: 0.625.. Test F1 Score: 0.631\n",
      "Epoch: 15/30.. Train Loss: 0.168.. Test Loss: 2.349.. Test Accuracy: 0.635.. Test F1 Score: 0.636\n",
      "Epoch: 16/30.. Train Loss: 0.195.. Test Loss: 2.535.. Test Accuracy: 0.625.. Test F1 Score: 0.627\n",
      "Epoch: 17/30.. Train Loss: 0.132.. Test Loss: 2.495.. Test Accuracy: 0.634.. Test F1 Score: 0.638\n",
      "Epoch: 18/30.. Train Loss: 0.119.. Test Loss: 2.488.. Test Accuracy: 0.610.. Test F1 Score: 0.618\n",
      "Epoch: 19/30.. Train Loss: 0.126.. Test Loss: 2.609.. Test Accuracy: 0.642.. Test F1 Score: 0.646\n",
      "Epoch: 20/30.. Train Loss: 0.146.. Test Loss: 2.347.. Test Accuracy: 0.657.. Test F1 Score: 0.660\n",
      "Epoch: 21/30.. Train Loss: 0.114.. Test Loss: 3.433.. Test Accuracy: 0.628.. Test F1 Score: 0.630\n",
      "Epoch: 22/30.. Train Loss: 0.117.. Test Loss: 3.520.. Test Accuracy: 0.608.. Test F1 Score: 0.610\n",
      "Epoch: 23/30.. Train Loss: 0.152.. Test Loss: 3.703.. Test Accuracy: 0.595.. Test F1 Score: 0.594\n",
      "Epoch: 24/30.. Train Loss: 0.131.. Test Loss: 3.258.. Test Accuracy: 0.621.. Test F1 Score: 0.627\n",
      "Epoch: 25/30.. Train Loss: 0.107.. Test Loss: 3.124.. Test Accuracy: 0.605.. Test F1 Score: 0.609\n",
      "Epoch: 26/30.. Train Loss: 0.106.. Test Loss: 3.237.. Test Accuracy: 0.621.. Test F1 Score: 0.626\n",
      "Epoch: 27/30.. Train Loss: 0.117.. Test Loss: 3.295.. Test Accuracy: 0.602.. Test F1 Score: 0.605\n",
      "Epoch: 28/30.. Train Loss: 0.094.. Test Loss: 3.183.. Test Accuracy: 0.629.. Test F1 Score: 0.632\n",
      "Epoch: 29/30.. Train Loss: 0.137.. Test Loss: 3.505.. Test Accuracy: 0.617.. Test F1 Score: 0.618\n",
      "Epoch: 30/30.. Train Loss: 0.091.. Test Loss: 3.283.. Test Accuracy: 0.639.. Test F1 Score: 0.643\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(model, train_dataloader_50, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 0.754.. Test Loss: 2.096.. Test Accuracy: 0.476.. Test F1 Score: 0.500\n",
      "Epoch: 2/30.. Train Loss: 0.407.. Test Loss: 2.064.. Test Accuracy: 0.495.. Test F1 Score: 0.492\n",
      "Epoch: 3/30.. Train Loss: 0.324.. Test Loss: 1.827.. Test Accuracy: 0.481.. Test F1 Score: 0.510\n",
      "Epoch: 4/30.. Train Loss: 0.277.. Test Loss: 2.476.. Test Accuracy: 0.484.. Test F1 Score: 0.476\n",
      "Epoch: 5/30.. Train Loss: 0.224.. Test Loss: 2.454.. Test Accuracy: 0.489.. Test F1 Score: 0.500\n",
      "Epoch: 6/30.. Train Loss: 0.204.. Test Loss: 2.612.. Test Accuracy: 0.512.. Test F1 Score: 0.512\n",
      "Epoch: 7/30.. Train Loss: 0.166.. Test Loss: 2.579.. Test Accuracy: 0.506.. Test F1 Score: 0.509\n",
      "Epoch: 8/30.. Train Loss: 0.147.. Test Loss: 2.816.. Test Accuracy: 0.535.. Test F1 Score: 0.543\n",
      "Epoch: 9/30.. Train Loss: 0.129.. Test Loss: 2.867.. Test Accuracy: 0.517.. Test F1 Score: 0.514\n",
      "Epoch: 10/30.. Train Loss: 0.137.. Test Loss: 3.252.. Test Accuracy: 0.528.. Test F1 Score: 0.520\n",
      "Epoch: 11/30.. Train Loss: 0.146.. Test Loss: 2.999.. Test Accuracy: 0.536.. Test F1 Score: 0.539\n",
      "Epoch: 12/30.. Train Loss: 0.142.. Test Loss: 3.117.. Test Accuracy: 0.505.. Test F1 Score: 0.504\n",
      "Epoch: 13/30.. Train Loss: 0.111.. Test Loss: 3.799.. Test Accuracy: 0.543.. Test F1 Score: 0.537\n",
      "Epoch: 14/30.. Train Loss: 0.087.. Test Loss: 3.927.. Test Accuracy: 0.544.. Test F1 Score: 0.550\n",
      "Epoch: 15/30.. Train Loss: 0.080.. Test Loss: 4.418.. Test Accuracy: 0.529.. Test F1 Score: 0.529\n",
      "Epoch: 16/30.. Train Loss: 0.066.. Test Loss: 4.747.. Test Accuracy: 0.489.. Test F1 Score: 0.472\n",
      "Epoch: 17/30.. Train Loss: 0.078.. Test Loss: 3.929.. Test Accuracy: 0.524.. Test F1 Score: 0.525\n",
      "Epoch: 18/30.. Train Loss: 0.111.. Test Loss: 3.540.. Test Accuracy: 0.518.. Test F1 Score: 0.516\n",
      "Epoch: 19/30.. Train Loss: 0.105.. Test Loss: 3.912.. Test Accuracy: 0.546.. Test F1 Score: 0.552\n",
      "Epoch: 20/30.. Train Loss: 0.102.. Test Loss: 4.064.. Test Accuracy: 0.515.. Test F1 Score: 0.506\n",
      "Epoch: 21/30.. Train Loss: 0.059.. Test Loss: 4.302.. Test Accuracy: 0.523.. Test F1 Score: 0.509\n",
      "Epoch: 22/30.. Train Loss: 0.052.. Test Loss: 4.583.. Test Accuracy: 0.571.. Test F1 Score: 0.568\n",
      "Epoch: 23/30.. Train Loss: 0.051.. Test Loss: 5.941.. Test Accuracy: 0.523.. Test F1 Score: 0.499\n",
      "Epoch: 24/30.. Train Loss: 0.050.. Test Loss: 4.696.. Test Accuracy: 0.539.. Test F1 Score: 0.539\n",
      "Epoch: 25/30.. Train Loss: 0.047.. Test Loss: 5.391.. Test Accuracy: 0.526.. Test F1 Score: 0.518\n",
      "Epoch: 26/30.. Train Loss: 0.044.. Test Loss: 5.258.. Test Accuracy: 0.526.. Test F1 Score: 0.519\n",
      "Epoch: 27/30.. Train Loss: 0.083.. Test Loss: 6.244.. Test Accuracy: 0.467.. Test F1 Score: 0.454\n",
      "Epoch: 28/30.. Train Loss: 0.183.. Test Loss: 4.351.. Test Accuracy: 0.481.. Test F1 Score: 0.470\n",
      "Epoch: 29/30.. Train Loss: 0.058.. Test Loss: 4.613.. Test Accuracy: 0.520.. Test F1 Score: 0.513\n",
      "Epoch: 30/30.. Train Loss: 0.048.. Test Loss: 4.985.. Test Accuracy: 0.516.. Test F1 Score: 0.503\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(model, train_dataloader_25, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Train Loss: 0.796.. Test Loss: 4.178.. Test Accuracy: 0.257.. Test F1 Score: 0.307\n",
      "Epoch: 2/30.. Train Loss: 0.301.. Test Loss: 2.993.. Test Accuracy: 0.392.. Test F1 Score: 0.444\n",
      "Epoch: 3/30.. Train Loss: 0.234.. Test Loss: 4.040.. Test Accuracy: 0.241.. Test F1 Score: 0.282\n",
      "Epoch: 4/30.. Train Loss: 0.182.. Test Loss: 3.626.. Test Accuracy: 0.285.. Test F1 Score: 0.328\n",
      "Epoch: 5/30.. Train Loss: 0.148.. Test Loss: 4.120.. Test Accuracy: 0.352.. Test F1 Score: 0.386\n",
      "Epoch: 6/30.. Train Loss: 0.097.. Test Loss: 4.417.. Test Accuracy: 0.341.. Test F1 Score: 0.382\n",
      "Epoch: 7/30.. Train Loss: 0.115.. Test Loss: 4.299.. Test Accuracy: 0.309.. Test F1 Score: 0.352\n",
      "Epoch: 8/30.. Train Loss: 0.091.. Test Loss: 4.793.. Test Accuracy: 0.347.. Test F1 Score: 0.372\n",
      "Epoch: 9/30.. Train Loss: 0.089.. Test Loss: 4.677.. Test Accuracy: 0.311.. Test F1 Score: 0.342\n",
      "Epoch: 10/30.. Train Loss: 0.085.. Test Loss: 5.984.. Test Accuracy: 0.326.. Test F1 Score: 0.367\n",
      "Epoch: 11/30.. Train Loss: 0.071.. Test Loss: 5.311.. Test Accuracy: 0.275.. Test F1 Score: 0.303\n",
      "Epoch: 12/30.. Train Loss: 0.045.. Test Loss: 5.030.. Test Accuracy: 0.359.. Test F1 Score: 0.382\n",
      "Epoch: 13/30.. Train Loss: 0.041.. Test Loss: 6.134.. Test Accuracy: 0.309.. Test F1 Score: 0.341\n",
      "Epoch: 14/30.. Train Loss: 0.106.. Test Loss: 4.317.. Test Accuracy: 0.375.. Test F1 Score: 0.389\n",
      "Epoch: 15/30.. Train Loss: 0.133.. Test Loss: 5.739.. Test Accuracy: 0.302.. Test F1 Score: 0.316\n",
      "Epoch: 16/30.. Train Loss: 0.051.. Test Loss: 6.419.. Test Accuracy: 0.276.. Test F1 Score: 0.294\n",
      "Epoch: 17/30.. Train Loss: 0.032.. Test Loss: 6.152.. Test Accuracy: 0.352.. Test F1 Score: 0.358\n",
      "Epoch: 18/30.. Train Loss: 0.028.. Test Loss: 6.594.. Test Accuracy: 0.337.. Test F1 Score: 0.355\n",
      "Epoch: 19/30.. Train Loss: 0.018.. Test Loss: 7.027.. Test Accuracy: 0.335.. Test F1 Score: 0.357\n",
      "Epoch: 20/30.. Train Loss: 0.020.. Test Loss: 7.024.. Test Accuracy: 0.338.. Test F1 Score: 0.354\n",
      "Epoch: 21/30.. Train Loss: 0.023.. Test Loss: 7.218.. Test Accuracy: 0.334.. Test F1 Score: 0.348\n",
      "Epoch: 22/30.. Train Loss: 0.048.. Test Loss: 7.116.. Test Accuracy: 0.336.. Test F1 Score: 0.349\n",
      "Epoch: 23/30.. Train Loss: 0.032.. Test Loss: 7.224.. Test Accuracy: 0.347.. Test F1 Score: 0.363\n",
      "Epoch: 24/30.. Train Loss: 0.017.. Test Loss: 7.825.. Test Accuracy: 0.334.. Test F1 Score: 0.349\n",
      "Epoch: 25/30.. Train Loss: 0.013.. Test Loss: 8.026.. Test Accuracy: 0.330.. Test F1 Score: 0.344\n",
      "Epoch: 26/30.. Train Loss: 0.047.. Test Loss: 6.026.. Test Accuracy: 0.383.. Test F1 Score: 0.379\n",
      "Epoch: 27/30.. Train Loss: 0.036.. Test Loss: 7.420.. Test Accuracy: 0.330.. Test F1 Score: 0.359\n",
      "Epoch: 28/30.. Train Loss: 0.032.. Test Loss: 6.200.. Test Accuracy: 0.323.. Test F1 Score: 0.358\n",
      "Epoch: 29/30.. Train Loss: 0.031.. Test Loss: 7.107.. Test Accuracy: 0.340.. Test F1 Score: 0.343\n",
      "Epoch: 30/30.. Train Loss: 0.013.. Test Loss: 7.316.. Test Accuracy: 0.342.. Test F1 Score: 0.354\n"
     ]
    }
   ],
   "source": [
    "model = CNNFeatureExtractor(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train and test model\n",
    "num_epochs = 30\n",
    "train_losses, test_losses, test_accuracies, test_f1_scores = train_and_test(model, train_dataloader_10, test_dataloader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
