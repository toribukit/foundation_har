{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.interpolate import CubicSpline\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "BATCH_SIZE = 128\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>activity</th>\n",
       "      <th>activity_label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.306563</td>\n",
       "      <td>9.196875</td>\n",
       "      <td>-1.22625</td>\n",
       "      <td>null_class</td>\n",
       "      <td>null_class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.306563</td>\n",
       "      <td>9.196875</td>\n",
       "      <td>-1.22625</td>\n",
       "      <td>null_class</td>\n",
       "      <td>null_class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.306563</td>\n",
       "      <td>9.196875</td>\n",
       "      <td>-1.22625</td>\n",
       "      <td>null_class</td>\n",
       "      <td>null_class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.306563</td>\n",
       "      <td>9.196875</td>\n",
       "      <td>-1.22625</td>\n",
       "      <td>null_class</td>\n",
       "      <td>null_class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.306563</td>\n",
       "      <td>9.196875</td>\n",
       "      <td>-1.22625</td>\n",
       "      <td>null_class</td>\n",
       "      <td>null_class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id     acc_x     acc_y    acc_z    activity activity_label_2\n",
       "0           0  0.306563  9.196875 -1.22625  null_class       null_class\n",
       "1           0  0.306563  9.196875 -1.22625  null_class       null_class\n",
       "2           0  0.306563  9.196875 -1.22625  null_class       null_class\n",
       "3           0  0.306563  9.196875 -1.22625  null_class       null_class\n",
       "4           0  0.306563  9.196875 -1.22625  null_class       null_class"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data without header\n",
    "data1 = pd.read_csv('./ISWC21_data_plus_raw/wetlab_data.csv')\n",
    "# add header\n",
    "data1.columns = ['subject_id', 'acc_x', 'acc_y', 'acc_z', 'activity', 'activity_label_2']\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3163679, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove activity label 2 column\n",
    "data1 = data1.drop(['activity_label_2'], axis=1)\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subjects:  22\n"
     ]
    }
   ],
   "source": [
    "#count number of unique subjects\n",
    "print(\"Number of unique subjects: \", data1['subject_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.57434</td>\n",
       "      <td>-2.02733</td>\n",
       "      <td>1.34506</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.56479</td>\n",
       "      <td>-1.99597</td>\n",
       "      <td>1.39345</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.55122</td>\n",
       "      <td>-1.98445</td>\n",
       "      <td>1.41139</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.51335</td>\n",
       "      <td>-1.97557</td>\n",
       "      <td>1.42615</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.52959</td>\n",
       "      <td>-1.98187</td>\n",
       "      <td>1.45395</td>\n",
       "      <td>climbing_up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id    acc_x    acc_y    acc_z     activity\n",
       "0           0 -9.57434 -2.02733  1.34506  climbing_up\n",
       "1           0 -9.56479 -1.99597  1.39345  climbing_up\n",
       "2           0 -9.55122 -1.98445  1.41139  climbing_up\n",
       "3           0 -9.51335 -1.97557  1.42615  climbing_up\n",
       "4           0 -9.52959 -1.98187  1.45395  climbing_up"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data without header\n",
    "data2 = pd.read_csv('./ISWC21_data_plus_raw/rwhar_data.csv', header=None)\n",
    "# add header\n",
    "data2.columns = ['subject_id', 'acc_x', 'acc_y', 'acc_z', 'activity']\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200803, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subjects:  15\n"
     ]
    }
   ],
   "source": [
    "#count number of unique subjects\n",
    "print(\"Number of unique subjects: \", data2['subject_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.443056</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>null_class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.440278</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>null_class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.451389</td>\n",
       "      <td>0.043056</td>\n",
       "      <td>0.876389</td>\n",
       "      <td>null_class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.456944</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>null_class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.447222</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>null_class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id     acc_x     acc_y     acc_z    activity\n",
       "0           0  0.443056  0.037500  0.888889  null_class\n",
       "1           0  0.440278  0.041667  0.880556  null_class\n",
       "2           0  0.451389  0.043056  0.876389  null_class\n",
       "3           0  0.456944  0.034722  0.888889  null_class\n",
       "4           0  0.447222  0.036111  0.888889  null_class"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data without header\n",
    "data3 = pd.read_csv('./ISWC21_data_plus_raw/sbhar_data.csv', header=None)\n",
    "# add header\n",
    "data3.columns = ['subject_id', 'acc_x', 'acc_y', 'acc_z', 'activity']\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1122772, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subjects:  30\n"
     ]
    }
   ],
   "source": [
    "#count number of unique subjects\n",
    "print(\"Number of unique subjects: \", data3['subject_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique subjects:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n"
     ]
    }
   ],
   "source": [
    "#print all of the unique subjects\n",
    "print(\"Unique subjects: \", data3['subject_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert subject_id to int\n",
    "data3['subject_id'] = data3['subject_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join all data in one dataframe row-wise\n",
    "# data = pd.concat([data1, data2, data3], ignore_index=True, axis=0)\n",
    "data = data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1122772, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check null values in subject_id column\n",
    "data['subject_id'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subjects:  [ 4 11  3 15  7 29]\n",
      "Train data shape:  (907785, 5)\n",
      "Test data shape:  (214987, 5)\n"
     ]
    }
   ],
   "source": [
    "#split train and test data\n",
    "#randomly select 20% of subjects for test data\n",
    "test_subjects = data['subject_id'].unique()\n",
    "test_subjects = np.random.choice(test_subjects, size=int(0.2*len(test_subjects)), replace=False)\n",
    "# test_subjects = [27 24  5  4 16  1]\n",
    "print(\"Test subjects: \", test_subjects)\n",
    "\n",
    "#split data into train and test\n",
    "train_data = data[~data['subject_id'].isin(test_subjects)]\n",
    "test_data = data[data['subject_id'].isin(test_subjects)]\n",
    "print(\"Train data shape: \", train_data.shape)\n",
    "print(\"Test data shape: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z normalization with respect to train data\n",
    "train_data_mean = train_data[['acc_x', 'acc_y', 'acc_z']].mean()\n",
    "train_data_std = train_data[['acc_x', 'acc_y', 'acc_z']].std()\n",
    "# Normalize Training Data\n",
    "train_data.loc[:, ['acc_x', 'acc_y', 'acc_z']] = (train_data[['acc_x', 'acc_y', 'acc_z']] - train_data_mean) / train_data_std\n",
    "\n",
    "# Normalize Test Data with Training Statistics\n",
    "test_data.loc[:, ['acc_x', 'acc_y', 'acc_z']] = (test_data[['acc_x', 'acc_y', 'acc_z']] - train_data_mean) / train_data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for sliding window\n",
    "\n",
    "def sliding_window_samples(data, samples_per_window, overlap_ratio):\n",
    "    \"\"\"\n",
    "    Return a sliding window measured in number of samples over a data array.\n",
    "\n",
    "    :param data: input array, can be numpy or pandas dataframe\n",
    "    :param samples_per_window: window length as number of samples\n",
    "    :param overlap_ratio: overlap is meant as percentage and should be an integer value\n",
    "    :return: tuple of windows and indices\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    indices = []\n",
    "    curr = 0\n",
    "    win_len = int(samples_per_window)\n",
    "    if overlap_ratio is not None:\n",
    "        overlapping_elements = int((overlap_ratio / 100) * (win_len))\n",
    "        if overlapping_elements >= win_len:\n",
    "            print('Number of overlapping elements exceeds window size.')\n",
    "            return\n",
    "    while curr < len(data) - win_len:\n",
    "        windows.append(data[curr:curr + win_len])\n",
    "        indices.append([curr, curr + win_len])\n",
    "        curr = curr + win_len - overlapping_elements\n",
    "    try:\n",
    "        result_windows = np.array(windows)\n",
    "        result_indices = np.array(indices)\n",
    "    except:\n",
    "        result_windows = np.empty(shape=(len(windows), win_len, data.shape[1]), dtype=object)\n",
    "        result_indices = np.array(indices)\n",
    "        for i in range(0, len(windows)):\n",
    "            result_windows[i] = windows[i]\n",
    "            result_indices[i] = indices[i]\n",
    "    return result_windows, result_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train window dataset (8 sec with 50% overlap): (4537, 400, 5)\n",
      "shape of test window dataset (8 sec with 50% overlap): (1073, 400, 5)\n"
     ]
    }
   ],
   "source": [
    "sampling_rate = 50\n",
    "time_window = 8\n",
    "window_size = sampling_rate * time_window\n",
    "overlap_ratio = 50\n",
    "\n",
    "train_window_data, _ = sliding_window_samples(train_data, window_size, overlap_ratio)\n",
    "print(f\"shape of train window dataset ({time_window} sec with {overlap_ratio}% overlap): {train_window_data.shape}\")\n",
    "\n",
    "test_window_data, _ = sliding_window_samples(test_data, window_size, overlap_ratio)\n",
    "print(f\"shape of test window dataset ({time_window} sec with {overlap_ratio}% overlap): {test_window_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, -0.9374415776332142, 0.1511316569299629, 2.2058765963654703,\n",
       "        'null_class'],\n",
       "       [0, -0.9444299648514514, 0.16221732187678917, 2.1831314363879004,\n",
       "        'null_class'],\n",
       "       [0, -0.9164765383070843, 0.16591254352573132, 2.1717588563991153,\n",
       "        'null_class'],\n",
       "       ...,\n",
       "       [0, 0.43577345253585653, -0.8096260526491502,\n",
       "        -0.19373279410209546, 'standing'],\n",
       "       [0, 0.4252911163656642, -0.8170165121178687, -0.19373279410209546,\n",
       "        'standing'],\n",
       "       [0, 0.4252911163656642, -0.8170165121178687, -0.19373279410209546,\n",
       "        'standing']], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_window_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the label column\n",
    "train_window_data = train_window_data[:, :, :-1]\n",
    "# train_window_data = train_window_data[:, :, :-1]\n",
    "#remove the subject column\n",
    "train_window_data = train_window_data[:, :, 1:]\n",
    "\n",
    "test_window_data = test_window_data[:, :, :-1]\n",
    "test_window_data = test_window_data[:, :, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_window_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_window_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jitter(data, noise_factor=0.05):\n",
    "    jitter = noise_factor * np.random.randn(*data.shape)\n",
    "    return data + jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data, min_scale=0.5, max_scale=1.5):\n",
    "    scaling_factor = np.random.uniform(min_scale, max_scale)\n",
    "    return data * scaling_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_data(data):\n",
    "    # Invert the sign of the data to simulate sensor rotation\n",
    "    return -data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negate_data(data):\n",
    "    return -data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontal_flip(data):\n",
    "    # This function now correctly handles 2D data arrays\n",
    "    return data[::-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_data(data, num_segments=4):\n",
    "    segment_length = data.shape[0] // num_segments  # Adjusted to the first dimension for 2D data\n",
    "    permuted_indices = np.random.permutation(num_segments)\n",
    "    return np.concatenate(\n",
    "        [data[segment_length * idx:segment_length * (idx + 1), :] for idx in permuted_indices], axis=0)  # Concatenating along the first axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "\n",
    "def time_warp(data, warp_factor_range=(0.8, 1.2)):\n",
    "    sequence_length, num_channels = data.shape\n",
    "    original_time_points = np.linspace(0, 1, sequence_length)\n",
    "    warp_factor = np.random.uniform(*warp_factor_range)\n",
    "    \n",
    "    # Generate new time points based on the warp factor\n",
    "    warped_time_points = np.linspace(0, warp_factor, sequence_length)\n",
    "\n",
    "    warped_data = np.zeros_like(data)\n",
    "    for j in range(num_channels):\n",
    "        # Interpolate each channel\n",
    "        interpolation = interp1d(original_time_points, data[:, j], \n",
    "                                 kind='linear', fill_value=\"extrapolate\")\n",
    "        warped_data[:, j] = interpolation(warped_time_points)\n",
    "\n",
    "    return warped_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_channels(data):\n",
    "    # Assuming data is 2D with shape (sequence_length, num_channels)\n",
    "    shuffled_indices = np.random.permutation(data.shape[1])  # Shuffle along the second dimension\n",
    "    return data[:, shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TPN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TPN, self).__init__()\n",
    "        self.trunk = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=..., out_channels=32, kernel_size=24, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=16, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv1d(in_channels=64, out_channels=96, kernel_size=8, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.AdaptiveMaxPool1d(output_size=1)\n",
    "        )\n",
    "\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(96, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 1),\n",
    "                nn.Sigmoid()\n",
    "            ) for _ in range(8)  # 8 heads for 8 different transformations\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.trunk(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully-connected layer\n",
    "        outputs = [head(x) for head in self.heads]\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize lists to store datasets\n",
    "train_dataset = [[] for _ in range(8)]\n",
    "\n",
    "# Loop over all training data\n",
    "for data in train_window_data:\n",
    "    # loop over all transformations\n",
    "    # print(f\"shape of data: {data.shape}\")\n",
    "    for j in range(8):\n",
    "        # Original data with label 0\n",
    "        train_dataset[j].append((data, 0))\n",
    "        # Apply transformation based on j and save it in the transformed_data variable\n",
    "        if j == 0:\n",
    "            transformed_data = add_jitter(data)\n",
    "        elif j == 1:\n",
    "            transformed_data = scale_data(data)\n",
    "        elif j == 2:\n",
    "            transformed_data = rotate_data(data)\n",
    "        elif j == 3:\n",
    "            transformed_data = negate_data(data)\n",
    "        elif j == 4:\n",
    "            transformed_data = horizontal_flip(data)\n",
    "        elif j == 5:\n",
    "            transformed_data = permute_data(data)\n",
    "        elif j == 6:\n",
    "            transformed_data = time_warp(data)\n",
    "        elif j == 7:\n",
    "            transformed_data = shuffle_channels(data)\n",
    "        # Append the transformed data with label 1\n",
    "        train_dataset[j].append((transformed_data, 1))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "for j in range(8):\n",
    "    data, labels = zip(*train_dataset[j])\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    train_dataset[j] = (data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training dataset 0: (9074, 400, 3)\n",
      "shape of training dataset 1: (9074, 400, 3)\n",
      "shape of training dataset 2: (9074, 400, 3)\n",
      "shape of training dataset 3: (9074, 400, 3)\n",
      "shape of training dataset 4: (9074, 400, 3)\n",
      "shape of training dataset 5: (9074, 400, 3)\n",
      "shape of training dataset 6: (9074, 400, 3)\n",
      "shape of training dataset 7: (9074, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of all training datasets\n",
    "for j in range(8):\n",
    "    print(f\"shape of training dataset {j}: {train_dataset[j][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution of training dataset 0: (array([0, 1]), array([4537, 4537], dtype=int64))\n",
      "Class distribution of training dataset 1: (array([0, 1]), array([4537, 4537], dtype=int64))\n",
      "Class distribution of training dataset 2: (array([0, 1]), array([4537, 4537], dtype=int64))\n",
      "Class distribution of training dataset 3: (array([0, 1]), array([4537, 4537], dtype=int64))\n",
      "Class distribution of training dataset 4: (array([0, 1]), array([4537, 4537], dtype=int64))\n",
      "Class distribution of training dataset 5: (array([0, 1]), array([4537, 4537], dtype=int64))\n",
      "Class distribution of training dataset 6: (array([0, 1]), array([4537, 4537], dtype=int64))\n",
      "Class distribution of training dataset 7: (array([0, 1]), array([4537, 4537], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# print the class distribution of all training datasets\n",
    "for j in range(8):\n",
    "    print(f\"Class distribution of training dataset {j}: {np.unique(train_dataset[j][1], return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lists to store datasets for test data\n",
    "test_dataset = [[] for _ in range(8)]\n",
    "\n",
    "# loop over all test data\n",
    "for data in test_window_data:\n",
    "    # loop over all transformations\n",
    "    for j in range(8):\n",
    "        # Original data with label 0\n",
    "        test_dataset[j].append((data, 0))\n",
    "        # Apply transformation based on j and save it in the transformed_data variable\n",
    "        if j == 0:\n",
    "            transformed_data = add_jitter(data)\n",
    "        elif j == 1:\n",
    "            transformed_data = scale_data(data)\n",
    "        elif j == 2:\n",
    "            transformed_data = rotate_data(data)\n",
    "        elif j == 3:\n",
    "            transformed_data = negate_data(data)\n",
    "        elif j == 4:\n",
    "            transformed_data = horizontal_flip(data)\n",
    "        elif j == 5:\n",
    "            transformed_data = permute_data(data)\n",
    "        elif j == 6:\n",
    "            transformed_data = time_warp(data)\n",
    "        elif j == 7:\n",
    "            transformed_data = shuffle_channels(data)\n",
    "        # Append the transformed data with label 1\n",
    "        test_dataset[j].append((transformed_data, 1))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "for j in range(8):\n",
    "    data, labels = zip(*test_dataset[j])\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    test_dataset[j] = (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of test dataset 0: (2146, 400, 3)\n",
      "shape of test dataset 1: (2146, 400, 3)\n",
      "shape of test dataset 2: (2146, 400, 3)\n",
      "shape of test dataset 3: (2146, 400, 3)\n",
      "shape of test dataset 4: (2146, 400, 3)\n",
      "shape of test dataset 5: (2146, 400, 3)\n",
      "shape of test dataset 6: (2146, 400, 3)\n",
      "shape of test dataset 7: (2146, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of all test datasets\n",
    "for j in range(8):\n",
    "    print(f\"shape of test dataset {j}: {test_dataset[j][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution of test dataset 0: (array([0, 1]), array([1073, 1073], dtype=int64))\n",
      "Class distribution of test dataset 1: (array([0, 1]), array([1073, 1073], dtype=int64))\n",
      "Class distribution of test dataset 2: (array([0, 1]), array([1073, 1073], dtype=int64))\n",
      "Class distribution of test dataset 3: (array([0, 1]), array([1073, 1073], dtype=int64))\n",
      "Class distribution of test dataset 4: (array([0, 1]), array([1073, 1073], dtype=int64))\n",
      "Class distribution of test dataset 5: (array([0, 1]), array([1073, 1073], dtype=int64))\n",
      "Class distribution of test dataset 6: (array([0, 1]), array([1073, 1073], dtype=int64))\n",
      "Class distribution of test dataset 7: (array([0, 1]), array([1073, 1073], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# print the class distribution of all test datasets\n",
    "for j in range(8):\n",
    "    print(f\"Class distribution of test dataset {j}: {np.unique(test_dataset[j][1], return_counts=True)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
