{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pandas import read_csv\n",
    "from numpy import dstack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from swiss_library import dataset_loader, custom_normalize, custom_norm_transform, SWISS_dataset, Downstream_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./UCI HAR Dataset/\"\n",
    "save_dir = \"./swiss/uci_har/\"\n",
    "val_size = 0.2\n",
    "seed = 42\n",
    "pre_batch_size = 512\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub\n",
    "\n",
    "\n",
    "train_acc_x = np.loadtxt(f'{data_dir}/train/Inertial Signals/body_acc_x_train.txt')\n",
    "train_acc_y = np.loadtxt(f'{data_dir}/train/Inertial Signals/body_acc_y_train.txt')\n",
    "train_acc_z = np.loadtxt(f'{data_dir}/train/Inertial Signals/body_acc_z_train.txt')\n",
    "train_gyro_x = np.loadtxt(f'{data_dir}/train/Inertial Signals/body_gyro_x_train.txt')\n",
    "train_gyro_y = np.loadtxt(f'{data_dir}/train/Inertial Signals/body_gyro_y_train.txt')\n",
    "train_gyro_z = np.loadtxt(f'{data_dir}/train/Inertial Signals/body_gyro_z_train.txt')\n",
    "train_tot_acc_x = np.loadtxt(f'{data_dir}/train/Inertial Signals/total_acc_x_train.txt')\n",
    "train_tot_acc_y = np.loadtxt(f'{data_dir}/train/Inertial Signals/total_acc_y_train.txt')\n",
    "train_tot_acc_z = np.loadtxt(f'{data_dir}/train/Inertial Signals/total_acc_z_train.txt')\n",
    "subject_train = np.loadtxt(f'{data_dir}/train/subject_train.txt')\n",
    "\n",
    "test_acc_x = np.loadtxt(f'{data_dir}/test/Inertial Signals/body_acc_x_test.txt')\n",
    "test_acc_y = np.loadtxt(f'{data_dir}/test/Inertial Signals/body_acc_y_test.txt')\n",
    "test_acc_z = np.loadtxt(f'{data_dir}/test/Inertial Signals/body_acc_z_test.txt')\n",
    "test_gyro_x = np.loadtxt(f'{data_dir}/test/Inertial Signals/body_gyro_x_test.txt')\n",
    "test_gyro_y = np.loadtxt(f'{data_dir}/test/Inertial Signals/body_gyro_y_test.txt')\n",
    "test_gyro_z = np.loadtxt(f'{data_dir}/test/Inertial Signals/body_gyro_z_test.txt')\n",
    "test_tot_acc_x = np.loadtxt(f'{data_dir}/test/Inertial Signals/total_acc_x_test.txt')\n",
    "test_tot_acc_y = np.loadtxt(f'{data_dir}/test/Inertial Signals/total_acc_y_test.txt')\n",
    "test_tot_acc_z = np.loadtxt(f'{data_dir}/test/Inertial Signals/total_acc_z_test.txt')\n",
    "subject_test = np.loadtxt(f'{data_dir}/test/subject_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking channels together data\n",
    "train_data = np.stack((train_acc_x, train_acc_y, train_acc_z,\n",
    "                       train_gyro_x, train_gyro_y, train_gyro_z,\n",
    "                       train_tot_acc_x, train_tot_acc_y, train_tot_acc_z), axis=1)\n",
    "X_test = np.stack((test_acc_x, test_acc_y, test_acc_z,\n",
    "                      test_gyro_x, test_gyro_y, test_gyro_z,\n",
    "                      test_tot_acc_x, test_tot_acc_y, test_tot_acc_z), axis=1)\n",
    "# labels\n",
    "train_labels = np.loadtxt(f'{data_dir}/train/y_train.txt')\n",
    "train_labels -= np.min(train_labels)\n",
    "y_test = np.loadtxt(f'{data_dir}/test/y_test.txt')\n",
    "y_test -= np.min(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5881, 9, 128), (1471, 9, 128), (5881,), (1471,), (5881,), (1471,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting data into train and validation for data, labels and subjects\n",
    "X_train, X_val, y_train, y_val, subject_train, subject_val = train_test_split(train_data, train_labels, subject_train, test_size=val_size, random_state=seed)\n",
    "\n",
    "# print shapes\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape, subject_train.shape, subject_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 9, 128), (2947,), (2947,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, subject_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train Loader] Train observations : 5881\n",
      "[Train Loader] Train labels : 5881\n",
      "[Train Loader] Train volunteers : 21\n",
      "[Validation Loader] Validation observations : 1471\n",
      "[Validation Loader] Validation labels : 1471\n",
      "[Validation Loader] Validation volunteers : 21\n",
      "[Test Loader] Test observations : 2947\n",
      "[Test Loader] Test labels : 2947\n",
      "[Test Loader] Test volunteers : 9\n"
     ]
    }
   ],
   "source": [
    "train_data, tr_obs, tr_v = dataset_loader(X_train, y_train, subject_train, 'Train')\n",
    "val_data, val_obs, val_v = dataset_loader(X_val, y_val, subject_val, 'Validation')\n",
    "test_data, te_obs, te_v = dataset_loader(X_test, y_test, subject_test, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['x'], means, stds = custom_normalize(train_data['x'])\n",
    "val_data['x'] = custom_norm_transform(val_data['x'], means, stds)\n",
    "test_data['x'] = custom_norm_transform(test_data['x'], means, stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5881, 9, 128]),\n",
       " torch.Size([1471, 9, 128]),\n",
       " torch.Size([2947, 9, 128]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shapes of train_data[x]\n",
    "train_data['x'].shape, val_data['x'].shape, test_data['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total obs : 10299 / Train : Valid : Test = 5881 : 1471 : 2947\n",
      "train volunteers : [1, 3, 5, 6, 7, 8, 11, 14, 15, 16, 17, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30]\n",
      "valid volunteers : [1, 3, 5, 6, 7, 8, 11, 14, 15, 16, 17, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30]\n",
      "test volunteers : [2, 4, 9, 10, 12, 13, 18, 20, 24]\n"
     ]
    }
   ],
   "source": [
    "total_obs = tr_obs+val_obs+te_obs\n",
    "print(f\"Total obs : {total_obs} / Train : Valid : Test = {tr_obs} : {val_obs} : {te_obs}\")\n",
    "print(f'train volunteers : {tr_v}')\n",
    "print(f'valid volunteers : {val_v}')\n",
    "print(f'test volunteers : {te_v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_set = SWISS_dataset(train_data, mask_type='random', masking_rate=0.1)\n",
    "train_set = Downstream_dataset(train_data)\n",
    "valid_set = Downstream_dataset(val_data)\n",
    "test_set = Downstream_dataset(test_data)\n",
    "\n",
    "pretrain_loader = DataLoader(pretrain_set, batch_size=pre_batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for swiss pretrainer\n",
    "pretrain_dict = {\n",
    "    'gru_hid_dim': 32,\n",
    "    'gru_input_size': 11,\n",
    "    'gru_layers': 1,\n",
    "    'gru_dropout': 0.2,\n",
    "    'bidirectional': True,\n",
    "    'num_signals': 9, # different for each dataset\n",
    "    'emb_dim': 32,\n",
    "    'emb_dropout': 0.0,\n",
    "    'depth': 2,\n",
    "    'heads': 2,\n",
    "    'head_dim': 0,\n",
    "    'transformer_mlp_dim': 0,\n",
    "    'dropout': 0.2,\n",
    "    'signal_emb': True,\n",
    "    'proj_hiddim': 512,\n",
    "    'proj_dim': 256,\n",
    "}\n",
    "\n",
    "pretrain_dict['head_dim'] = int(pretrain_dict['emb_dim']/pretrain_dict['heads'])\n",
    "pretrain_dict['transformer_mlp_dim'] = pretrain_dict['emb_dim']*4\n",
    "pretrain_dict['gru_hid_dim'] = pretrain_dict['emb_dim']\n",
    "pretrain_dict['gru_emb_dim'] = pretrain_dict['emb_dim']\n",
    "if pretrain_dict['gru_layers'] == 1:\n",
    "    pretrain_dict['gru_dropout'] = 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
